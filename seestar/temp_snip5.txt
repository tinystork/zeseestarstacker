                            and len(item_result_tuple) == 6
                            and item_result_tuple[0] is not None
                        ):
                            if self.reproject_between_batches:
                                # --- NEW incremental reprojection on *stacked* batches ---
                                # store only the components expected by
                                # ``_stack_batch`` (data, header, scores,
                                # wcs_object, valid_mask)
                                # _stack_batch expects (data, header, scores, wcs, valid_mask)
                                # item_result_tuple structure is
                                # (data, header, scores, wcs, matrix_M, valid_mask)
                                current_batch_items_with_masks_for_stack_batch.append(
                                    (
                                        item_result_tuple[0],
                                        item_result_tuple[1],
                                        item_result_tuple[2],
                                        item_result_tuple[3],
                                        item_result_tuple[5],
                                    )
                                )
                                self._current_batch_paths.append(file_path)

                                if self.batch_size == 0:
                                    trigger = float("inf")
                                elif self.batch_size == 1 and getattr(
                                    self, "chunk_size", None
                                ):
                                    trigger = getattr(self, "chunk_size")
                                else:
                                    trigger = max(1, self.batch_size)
                                if (
                                    len(current_batch_items_with_masks_for_stack_batch)
                                    >= trigger
                                ):
                                    self.stacked_batches_count += 1
                                    num_in_batch = len(
                                        current_batch_items_with_masks_for_stack_batch
                                    )

                                    # 1. Stack the batch (classic SUM/W)
                                    stacked_np, hdr, wht_2d = self._stack_batch(
