"""
Module de gestion de file d'attente pour le traitement des images astronomiques.
G√®re l'alignement et l'empilement incr√©mental par LOTS dans un thread s√©par√©.
(Version R√©vis√©e 13: Correction finale avec pr√©-solving global et aper√ßu dynamique)

Auto-Tune CPU/I-O : ajuste ``thread_fraction`` et ``max_reproj_workers``
via :class:`seestar.queuep.autotuner.CpuIoAutoTuner`.
"""

import logging

logger = logging.getLogger(__name__)

# --- AJOUTEZ CES DEUX LIGNES POUR LE DEBUG CRITIQUE ---


# --- FIN AJOUT CRITIQUE ---


# --- Standard Library Imports ---
from astropy.io import fits
from astropy.wcs import WCS
import glob, os, gc
import math
import multiprocessing
from queue import Queue, Empty  # Essentiel pour la classe
import shutil
from ..tools.file_ops import move_to_stacked
import tempfile
import threading  # Essentiel pour la classe (Lock)
import time
import traceback
from pathlib import Path


import sys
import asyncio
import concurrent.futures
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
from functools import partial
import warnings

from seestar.queuep.autotuner import CpuIoAutoTuner

logger.debug("Imports standard OK.")


# --- Third-Party Library Imports ---
from ..core.background import (
    subtract_background_2d,
    _PHOTOUTILS_AVAILABLE as _PHOTOUTILS_BG_SUB_AVAILABLE,
)
import astroalign as aa
import cv2
import numpy as np
from astropy.coordinates import SkyCoord, concatenate as skycoord_concatenate, Angle
from typing import Literal
from astropy import units as u
from astropy.wcs import FITSFixedWarning
from ccdproc import combine as ccdproc_combine
from astropy.nddata import CCDData
from ..enhancement.stack_enhancement import apply_edge_crop
from astropy.wcs.utils import proj_plane_pixel_scales
from scipy.spatial import ConvexHull
from seestar.gui.settings import SettingsManager

from ..core.reprojection import reproject_to_reference_wcs
from ..core.incremental_reprojection import (
    reproject_and_combine,
    reproject_and_coadd_batch,
)
from ..core.normalization import (
    _normalize_images_linear_fit,
    _normalize_images_sky_mean,
)
from seestar.core.stack_methods import (
    _stack_mean,
    _stack_median,
    _stack_kappa_sigma,
    _stack_linear_fit_clip,
    _stack_winsorized_sigma,
)
from ..core.weights import (
    _calculate_image_weights_noise_variance,
    _calculate_image_weights_noise_fwhm,
)

logger.debug("Imports tiers (numpy, cv2, astropy, ccdproc) OK.")

# ----------------------------------------------------------------------
# Pool size helper for CPU reprojection
# ----------------------------------------------------------------------


def _suggest_pool_size(ratio: float = 0.5) -> int:
    """Return an appropriate number of workers for the process pool."""
    try:
        n_cpu = len(os.sched_getaffinity(0))
    except AttributeError:
        n_cpu = multiprocessing.cpu_count()
    return max(1, int(n_cpu * ratio))


def _reproject_worker(
    fits_path: str,
    ref_wcs_header: fits.Header,
    shape_out: tuple,
    use_gpu: bool = False,
):
    """Worker function used by the process pool for reprojection."""
    os.environ["OMP_NUM_THREADS"] = "1"

    data = fits.getdata(fits_path, memmap=False)

    if use_gpu:
        import cupy as cp
        from cupyx.scipy.ndimage import map_coordinates

        data_gpu = cp.asarray(data, dtype=cp.float32)
        # Coordinates should be precomputed on the CPU and passed to the worker.
        # Here we simply build a basic identity grid as a placeholder.
        yy, xx = cp.meshgrid(
            cp.arange(shape_out[0], dtype=cp.float32),
            cp.arange(shape_out[1], dtype=cp.float32),
            indexing="ij",
        )
        coords_gpu = cp.stack([yy, xx])
        reproj_gpu = map_coordinates(
            data_gpu, coords_gpu, order=1, mode="constant", cval=0.0
        )
        reproj = cp.asnumpy(reproj_gpu)
        footprint = cp.asnumpy(reproj_gpu != 0).astype(np.float32)
    else:
        from seestar.enhancement.reproject_utils import reproject_interp

        reproj, footprint = reproject_interp(
            (data, None), WCS(ref_wcs_header), shape_out, parallel=False
        )

    return reproj.astype(np.float32), footprint.astype(np.float32)


def _stack_worker(args):
    """Worker for heavy stacking computations."""
    (
        mode,
        images,
        weights,
        kappa_low,
        kappa_high,
        winsor_limits,
        apply_rewinsor,
    ) = args
    os.environ["OMP_NUM_THREADS"] = "1"

    from seestar.core.stack_methods import (
        _stack_mean,
        _stack_median,
        _stack_kappa_sigma,
        _stack_linear_fit_clip,
        _stack_winsorized_sigma,
    )

    if mode == "winsorized-sigma":
        return _stack_winsorized_sigma(
            images,
            weights,
            kappa=max(kappa_low, kappa_high),
            winsor_limits=winsor_limits,
            apply_rewinsor=apply_rewinsor,
        )
    elif mode == "kappa-sigma":
        return _stack_kappa_sigma(
            images,
            weights,
            sigma_low=kappa_low,
            sigma_high=kappa_high,
        )
    elif mode == "linear_fit_clip":
        return _stack_linear_fit_clip(images, weights)
    elif mode == "median":
        return _stack_median(images, weights)
    else:
        return _stack_mean(images, weights)


# --- Optional Third-Party Imports (with availability flags) ---
try:
    # On importe juste Drizzle ici, car la CLASSE est utilis√©e dans les m√©thodes
    from drizzle.resample import Drizzle

    _OO_DRIZZLE_AVAILABLE = True
    logger.debug("Import drizzle.resample.Drizzle OK.")
except ImportError as e_driz_cls:
    _OO_DRIZZLE_AVAILABLE = False
    Drizzle = None  # D√©finir comme None si indisponible
    logger.error("√âchec import drizzle.resample.Drizzle: %s", e_driz_cls)


# --- Core/Internal Imports (Needed for __init__ or core logic) ---
try:
    from ..core.hot_pixels import detect_and_correct_hot_pixels
except ImportError as e:
    logger.error("√âchec import detect_and_correct_hot_pixels: %s", e)
    raise
try:
    from ..core.image_processing import (
        load_and_validate_fits,
        debayer_image,
        save_fits_image,
        save_preview_image,
    )
except ImportError as e:
    logger.error("√âchec import image_processing: %s", e)
    raise
try:
    from ..core.utils import estimate_batch_size
except ImportError as e:
    logger.error("√âchec import utils: %s", e)
    raise
try:
    from ..enhancement.color_correction import ChromaticBalancer
except ImportError as e_cb:
    logger.error("√âchec import ChromaticBalancer: %s", e_cb)
    raise

# --- Imports INTERNES √† d√©placer en IMPORTS TARDIFS (si utilis√©s uniquement dans des m√©thodes sp√©cifiques) ---
# Ces modules/fonctions sont g√©r√©s par des appels conditionnels ou try/except dans les m√©thodes o√π ils sont utilis√©s.
# from ..enhancement.drizzle_integration import _load_drizzle_temp_file, DrizzleProcessor, _create_wcs_from_header
# from ..alignment.astrometry_solver import solve_image_wcs
# from ..enhancement.mosaic_processor import process_mosaic_from_aligned_files
# from ..enhancement.stack_enhancement import StackEnhancer # Cette classe n'est pas utilis√©e ici

# --- Configuration des Avertissements ---
warnings.filterwarnings("ignore", category=FITSFixedWarning)
logger.debug("Configuration warnings OK.")
# --- FIN Imports ---
# --- NEW GLOBAL VERSION STRING CONSTANT (ajout√©e √† la fin de queue_manager.py) ---
# Assurez-vous d'ajouter cette ligne aussi √† l'ext√©rieur de la classe, tout en haut du fichier, comme je l'ai sugg√©r√© pr√©c√©demment.
# Global version string to make sure it's always the same
GLOBAL_DRZ_BATCH_VERSION_STRING_ULTRA_DEBUG = (
    "V_DRIZ_INCR_ULTRA_DEBUG_20250611_FINAL_ATTEMPT"
)

# --- Internal Project Imports (Core Modules ABSOLUMENT n√©cessaires pour la classe/init) ---
# Core Alignment (Instanci√© dans __init__)
try:
    from ..core.alignment import SeestarAligner

    logger.debug("Import SeestarAligner OK.")
except ImportError as e:
    logger.error("√âchec import SeestarAligner: %s", e)
    raise
# Core Hot Pixels (Utilis√© dans _worker -> _process_file)
try:
    from ..core.hot_pixels import detect_and_correct_hot_pixels

    logger.debug("Import detect_and_correct_hot_pixels OK.")
except ImportError as e:
    logger.error("√âchec import detect_and_correct_hot_pixels: %s", e)
    raise
# Core Image Processing (Utilis√© PARTOUT)
try:
    from ..core.image_processing import (
        load_and_validate_fits,
        debayer_image,
        save_fits_image,
        save_preview_image,
    )

    logger.debug("Imports image_processing OK.")
except ImportError as e:
    logger.error("√âchec import image_processing: %s", e)
    raise
# --- IMPORT POUR L'ALIGNEUR LOCAL ---
try:
    from ..core import SeestarLocalAligner  # Devrait √™tre FastSeestarAligner alias√©

    _LOCAL_ALIGNER_AVAILABLE = True
    logger.debug("Import SeestarLocalAligner (local CV) OK.")
except ImportError:
    _LOCAL_ALIGNER_AVAILABLE = False
    SeestarLocalAligner = (
        None  # D√©finir pour que le code ne plante pas √† l'instanciation
    )
    logger.warning(
        "SeestarLocalAligner (local CV) non importable. Alignement mosa√Øque local d√©sactiv√©."
    )
# ---  ---


# Core Utils (Utilis√© PARTOUT)
try:
    from ..core.utils import estimate_batch_size

    logger.debug("Imports utils OK.")
except ImportError as e:
    logger.error("√âchec import utils: %s", e)
    raise
# Enhancement Color Correction (Instanci√© dans __init__)
try:
    from ..enhancement.color_correction import ChromaticBalancer

    logger.debug("Import ChromaticBalancer OK.")
except ImportError as e:
    logger.error("√âchec import ChromaticBalancer: %s", e)
    raise

try:
    from ..enhancement.stack_enhancement import feather_by_weight_map  # NOUVEL IMPORT

    _FEATHERING_AVAILABLE = True
    logger.debug("Import feather_by_weight_map depuis stack_enhancement OK.")
except ImportError as e_feather:
    _FEATHERING_AVAILABLE = False
    logger.error(
        "√âchec import feather_by_weight_map depuis stack_enhancement: %s",
        e_feather,
    )
    # D√©finir une fonction factice pour que le code ne plante pas si l'import √©choue
    # lors des appels ult√©rieurs, bien qu'on v√©rifiera _FEATHERING_AVAILABLE.


def feather_by_weight_map(img, wht, blur_px=256, eps=1e-6):
    logger.error("Fonction feather_by_weight_map non disponible (√©chec import).")
    return img  # Retourner l'image originale


def renormalize_fits(
    fits_path: str,
    method: Literal["none", "max", "n_images"],
    n_images: int,
) -> None:
    """In-place renormalises a drizzle FITS stack."""
    log = logging.getLogger(__name__)
    m = (method or "none").lower()
    if m not in {"none", "max", "n_images"}:
        log.debug(f"renormalize_fits: unknown method '{method}', fallback to 'none'")
        m = "none"
    if m == "none":
        return
    try:
        with fits.open(fits_path, mode="update", memmap=False) as hdul:
            orig_dtype = hdul[0].data.dtype
            data = hdul[0].data.astype(np.float32)
            hdr = hdul[0].header
            wht = None
            wht_orig_dtype = None
            if (
                len(hdul) > 1
                and hdul[1].header.get("EXTNAME", "").strip().upper() == "WHT"
            ):
                wht_orig_dtype = hdul[1].data.dtype
                wht = hdul[1].data.astype(np.float32)
            if wht is not None:
                wht_max = float(np.max(wht)) if wht.size else 1.0
                wht_mean = float(np.mean(wht)) if wht.size else 1.0
            else:
                wht_max = float(hdr.get("DRZWHT_MAX", 1.0))
                wht_mean = float(hdr.get("DRZWHT_MEAN", 1.0))
            if m == "max":
                s = 1.0 / max(wht_max, 1.0)
            else:  # "n_images"
                denom = max(wht_mean, 1e-9)
                s = float(n_images) / denom
            data *= s
            if wht is not None:
                wht *= s
            if np.issubdtype(orig_dtype, np.integer):
                hdul[0].data = np.round(data).astype(orig_dtype)
            else:
                hdul[0].data = data.astype(orig_dtype)
            if wht is not None:
                if np.issubdtype(wht_orig_dtype, np.integer):
                    hdul[1].data = np.round(wht).astype(wht_orig_dtype)
                else:
                    hdul[1].data = wht.astype(wht_orig_dtype)
            hdr["RENORM"] = (s, "Flux renormalisation factor")
            hdr["RENORMMD"] = (m, "Renormalisation method")
            hdul.flush()
        log.debug(
            f"renormalize_fits: method={m} factor={s:.4g} applied to {os.path.basename(fits_path)}"
        )
    except Exception:
        log.exception("renormalize_fits failed")
        raise


try:
    from ..enhancement.stack_enhancement import apply_low_wht_mask  # NOUVEL IMPORT

    _LOW_WHT_MASK_AVAILABLE = True
    logger.debug("Import apply_low_wht_mask depuis stack_enhancement OK.")
except ImportError as e_low_wht:
    _LOW_WHT_MASK_AVAILABLE = False
    logger.error(
        "√âchec import apply_low_wht_mask: %s",
        e_low_wht,
    )

    def apply_low_wht_mask(
        img, wht, percentile=5, soften_px=128, progress_callback=None
    ):  # Factice
        if progress_callback:
            progress_callback(
                "   [LowWHTMask] ERREUR: Fonction apply_low_wht_mask non disponible (√©chec import).",
                None,
            )
        else:
            logger.error("Fonction apply_low_wht_mask non disponible (√©chec import).")
        return img


# --- Optional Third-Party Imports (Post-processing related) ---
# Ces imports sont tent√©s globalement. Des flags indiquent leur disponibilit√©.
_PHOTOUTILS_BG_SUB_AVAILABLE = False
try:
    from ..core.background import subtract_background_2d

    _PHOTOUTILS_BG_SUB_AVAILABLE = True
    logger.debug("Import subtract_background_2d (Photutils) OK.")
except ImportError as e:
    subtract_background_2d = None  # Fonction factice
    logger.warning("√âchec import subtract_background_2d (Photutils): %s", e)

_BN_AVAILABLE = False  # Neutralisation de fond globale
try:
    from ..tools.stretch import neutralize_background_automatic

    _BN_AVAILABLE = True
    logger.debug("Import neutralize_background_automatic OK.")
except ImportError as e:
    neutralize_background_automatic = None  # Fonction factice
    logger.warning("√âchec import neutralize_background_automatic: %s", e)

_SCNR_AVAILABLE = False  # SCNR Final
try:
    from ..enhancement.color_correction import apply_scnr

    _SCNR_AVAILABLE = True
    logger.debug("Import apply_scnr OK.")
except ImportError as e:
    apply_scnr = None  # Fonction factice
    logger.warning("√âchec import apply_scnr: %s", e)

_CROP_AVAILABLE = False  # Rognage Final
try:
    from ..enhancement.stack_enhancement import apply_edge_crop

    _CROP_AVAILABLE = True
    logger.debug("Import apply_edge_crop OK.")
except ImportError as e:
    apply_edge_crop = None  # Fonction factice
    logger.warning("√âchec import apply_edge_crop: %s", e)

# --- Imports INTERNES √† d√©placer en IMPORTS TARDIFS ---
# Ces modules seront import√©s seulement quand les m√©thodes sp√©cifiques sont appel√©es
# pour √©viter les d√©pendances circulaires au chargement initial.


from ..alignment.astrometry_solver import (
    AstrometrySolver,
    solve_image_wcs,
)  # D√©plac√© vers _worker/_process_file


# --- Configuration des Avertissements ---
warnings.filterwarnings("ignore", category=FITSFixedWarning)
logger.debug("Configuration warnings OK.")
# --- FIN Imports ---


class SeestarQueuedStacker:
    """
    Classe pour l'empilement des images Seestar avec file d'attente et traitement par lots.
    G√®re l'alignement et l'empilement dans un thread s√©par√©.
    Ajout de la pond√©ration bas√©e sur la qualit√© (SNR, Nombre d'√©toiles).
    """

    logger.debug("Lecture de la d√©finition de la classe SeestarQueuedStacker...")

    def _configure_global_threads(self, fraction: float) -> None:
        nthreads = max(1, math.floor(os.cpu_count() * fraction))
        for var in [
            "OMP_NUM_THREADS",
            "OPENBLAS_NUM_THREADS",
            "MKL_NUM_THREADS",
            "NUMEXPR_NUM_THREADS",
            "VECLIB_MAXIMUM_THREADS",
        ]:
            os.environ[var] = str(nthreads)
        try:

            from threadpoolctl import threadpool_limits
        except Exception:
            threadpool_limits = None
        if threadpool_limits:
            try:
                threadpool_limits(nthreads)
            except Exception:
                pass

        if "mkl" in sys.modules:
            try:
                sys.modules["mkl"].set_num_threads(nthreads)
            except Exception:
                pass
        try:
            cv2.setNumThreads(nthreads)
        except Exception:
            pass
        self.num_threads = nthreads
        if hasattr(self, "update_progress"):
            self.update_progress(f"Threads limited to {nthreads}")

    def _process_batch_parallel(self, filepaths: list[str]):
        start = time.monotonic()

        with concurrent.futures.ThreadPoolExecutor(max_workers=self.num_threads) as ex:
            results = list(ex.map(self._process_file, filepaths))
        duration = time.monotonic() - start
        msg = f"Processed {len(filepaths)} images in {duration:.2f} s"
        self.update_progress(msg)

        if duration / max(len(filepaths), 1) > 0.01 and self.batch_size > 1:
            self.batch_size = max(1, self.batch_size // 2)
            self.update_progress(f"Batch size reduced to {self.batch_size}")
        return results

    def _prefetch(self, file_paths):
        if self.io_profile != "usb":
            return

        def _read_one(p):
            try:
                with open(p, "rb") as f:
                    f.read(1024)
            except Exception:
                pass

        def _run(files):
            async def _prefetch_async():

                tasks = [asyncio.to_thread(_read_one, fp) for fp in files]
                await asyncio.gather(*tasks)

            asyncio.run(_prefetch_async())

        threading.Thread(
            target=_run,
            args=(list(file_paths),),
            daemon=True,
        ).start()

    # ------------------------------------------------------------------
    # Parallel reprojection of a list of FITS files
    # ------------------------------------------------------------------

    def _process_batches(self, batch_fits_list: list[str]):
        """Reproject and accumulate each FITS file individually."""

        if not batch_fits_list or self.reference_shape is None:
            return

        worker = partial(
            _reproject_worker,
            ref_wcs_header=self.ref_wcs_header,
            shape_out=self.reference_shape,
            use_gpu=self.use_gpu,
        )

        for fits_path in batch_fits_list:
            try:
                data, wht, hdr, input_wcs = self._load_and_prepare_simple(fits_path)
            except Exception:
                continue

            reproj_data, reproj_wht = worker(fits_path)

            # continuous accumulation
            self.cumulative_sum_memmap += reproj_data * reproj_wht[..., None]
            if self.cumulative_wht_memmap.shape != reproj_wht.shape:
                from numpy.lib.format import open_memmap

                self.cumulative_wht_memmap = open_memmap(
                    self.cumulative_wht_path,
                    mode="w+",
                    dtype=np.float32,
                    shape=reproj_wht.shape,
                )
                self.cumulative_wht_memmap[:] = 0.0
            self.cumulative_wht_memmap += reproj_wht
            self.cumulative_sum_memmap.flush()
            self.cumulative_wht_memmap.flush()

            if self.enable_preview:
                self._downsample_preview(reproj_data, reproj_wht)

    # --- DANS LA CLASSE SeestarQueuedStacker DANS seestar/queuep/queue_manager.py ---

    def __init__(
        self,
        gpu: bool = False,
        io_profile: str = "ssd",
        thread_fraction: float = 0.5,
        batch_size: int | None = None,
        settings: SettingsManager | None = None,
        autotune: bool = True,
        *args,
        **kwargs,
    ):
        self.progress_callback = None
        self._configure_global_threads(thread_fraction)
        self.autotuner = CpuIoAutoTuner(self) if autotune else None
        self.io_profile = io_profile
        self.use_cuda = bool(gpu and cv2.cuda.getCudaEnabledDeviceCount() > 0)
        self.use_gpu = bool(gpu)
        self.max_reproj_workers = _suggest_pool_size(0.5)
        self.max_stack_workers = _suggest_pool_size(0.75)
        if batch_size is None:
            self.batch_size = (
                min(4, self.num_threads)
                if io_profile == "usb"
                else self.num_threads * 2
            )
        else:
            self.batch_size = int(batch_size)
        logger.debug(
            "\n==== D√âBUT INITIALISATION SeestarQueuedStacker (AVEC LocalAligner) ===="
        )

        # --- 1. Attributs Critiques et Simples ---
        logger.debug("  -> Initialisation attributs simples et flags...")

        self.processing_active = False
        self.stop_processing = False
        self.processing_error = None
        self.is_mosaic_run = False
        self.drizzle_active_session = False
        self.mosaic_alignment_mode = "local_fast_fallback"
        self.use_wcs_fallback_for_mosaic = True

        self.fa_orb_features = 5000
        self.fa_min_abs_matches = 12
        self.fa_min_ransac_raw = 7
        self.fa_ransac_thresh = 5.0
        self.fa_daofind_fwhm = 3.5
        self.fa_daofind_thr_sig = 4.0
        self.fa_max_stars_descr = 750

        self.mosaic_drizzle_kernel = "square"
        self.mosaic_drizzle_pixfrac = 0.8
        self.mosaic_drizzle_fillval = "0.0"
        self.mosaic_drizzle_wht_threshold = 0.01

        # Inter-batch reprojection flag (Drizzle Standard mode)
        self.inter_batch_reprojection = False

        self.perform_cleanup = True
        self.use_quality_weighting = True
        self.correct_hot_pixels = True
        self.apply_chroma_correction = True
        self.apply_final_scnr = False
        self.normalize_method = "none"
        self.weighting_method = "none"
        # Flag pour d√©tecter un arr√™t demand√© explicitement par l'utilisateur
        self.user_requested_stop = False

        # Info message pour l'utilisateur
        self.warned_unaligned_source_folders = set()

        # NOUVEAU : Initialisation de l'attribut pour la sauvegarde en float32

        self.save_final_as_float32 = False  # Par d√©faut, sauvegarde en uint16 (via conversion dans _save_final_stack)
        logger.debug(
            f"  -> Attribut self.save_final_as_float32 initialis√© √†: {self.save_final_as_float32}"
        )
        self.preserve_linear_output = False
        logger.debug(
            f"  -> Attribut self.preserve_linear_output initialis√© √†: {self.preserve_linear_output}"
        )
        self.max_hq_mem = getattr(settings, "max_hq_mem", 8 * 1024**3)
        self.stack_final_combine = getattr(settings, "stack_final_combine", "mean")
        self.drizzle_renorm_method = "none"
        # Option de reprojection des lots empil√©s interm√©diaires
        self.reproject_between_batches = False
        # Liste des fichiers interm√©diaires en mode Classic avec reprojection
        self.intermediate_classic_batch_files = []

        self.partial_save_interval = 1
        self.stacked_subdir_name = "stacked"
        self.move_stacked = False
        self._current_batch_paths = []
        self.batch_count_path = None
        self._resume_requested = False

        # Master arrays when combining batches with incremental reprojection
        self.master_sum = None
        self.master_coverage = None

        # Backward compatibility attributes removed in favour of
        # ``reproject_between_batches``. They may still appear in old settings
        # files, so we simply ignore them here.

        # --- FIN NOUVEAU ---

        self.progress_callback = None
        self.preview_callback = None
        self.queue = Queue()
        self.folders_lock = threading.Lock()
        self.processing_thread = None
        self.processed_files = set()
        self.additional_folders = []
        self.current_folder = None
        self.output_folder = None
        self.unaligned_folder = None
        self.drizzle_temp_dir = None
        self.output_filename = ""
        self.drizzle_batch_output_dir = None
        self.classic_batch_output_dir = None
        self.final_stacked_path = None
        self.api_key = None
        self.reference_wcs_object = None
        self.reference_header_for_wcs = None
        self.ref_wcs_header = None
        self.reference_pixel_scale_arcsec = None
        self.drizzle_output_wcs = None
        self.drizzle_output_shape_hw = None
        self.fixed_output_wcs = None
        self.fixed_output_shape = None

        self.sum_memmap_path = None
        self.wht_memmap_path = None
        self.cumulative_sum_memmap = None
        self.cumulative_wht_memmap = None
        self.memmap_shape = None
        self.memmap_dtype_sum = np.float32
        self.memmap_dtype_wht = np.float32
        self.enable_preview = False
        logger.debug("  -> Attributs SUM/W (memmap) initialis√©s √† None.")

        # Cumulative weight map across all batches
        from numpy.lib.format import open_memmap

        seestar_root = Path(__file__).resolve().parents[1]
        self.cumulative_wht_path = str(seestar_root / "cumulative_wht.dat")
        H, W = 1, 1
        self.cumulative_wht_memmap = open_memmap(
            self.cumulative_wht_path, mode="w+", dtype=np.float32, shape=(H, W)
        )
        self.cumulative_wht_memmap[:] = 0.0

        # Options pour d√©placement et sauvegarde partiels
        self.partial_save_interval = 1
        self.stacked_subdir_name = "stacked"
        self.batch_count_path = None
        self._current_batch_paths = []
        self.move_stacked = False

        self.use_quality_weighting = False
        self.weight_by_snr = True
        self.weight_by_stars = True
        self.snr_exponent = 1.0
        self.stars_exponent = 0.5
        self.min_weight = 0.01
        self.apply_feathering = False
        self.feather_blur_px = 256

        self.current_batch_data = []
        self.current_stack_header = None
        self.images_in_cumulative_stack = 0
        self.cumulative_drizzle_data = None
        self.total_exposure_seconds = 0.0
        self.intermediate_drizzle_batch_files = []

        # When inter-batch reprojection is enabled we may want to keep the
        # reference WCS fixed after the first successful plate-solve to avoid
        # drifting of the solution between batches. This flag controls that
        # behaviour. When ``True`` the reference WCS is only set once and
        # subsequent solves will not modify it.
        self.freeze_reference_wcs = False
        # Control whether stacked batches are individually solved with ASTAP.
        # This remains ``True`` by default for backwards compatibility.
        self.solve_batches = True

        self.all_input_filepaths = []
        self.reference_shape = None

        # --- NEW ---
        # Store the original reference frame size (H, W) so that reprojection
        # of stacked batches can optionally keep the exact input dimensions.
        self.input_reference_shape_hw = None
        # Flag controlling whether reprojection should enforce the original
        # input size instead of the expanded drizzle size.
        self.keep_input_size_for_reproject = False

        self.incremental_drizzle_objects = []
        logger.debug(
            "  -> Attributs pour Drizzle Incr√©mental (objets) initialis√©s √† liste vide."
        )

        if settings is not None:
            try:
                self.reproject_between_batches = bool(
                    getattr(settings, "reproject_between_batches", False)
                )
                logger.debug(
                    f"  -> Flag reproject_between_batches initialis√© depuis settings: {self.reproject_between_batches}"
                )
                # When using inter-batch reprojection we want to keep the
                # reference WCS stable after the first solve.
                self.freeze_reference_wcs = self.reproject_between_batches
                self.drizzle_renorm_method = str(
                    getattr(settings, "drizzle_renorm", "none")
                )
                logger.debug(
                    f"  -> M√©thode de renormalisation drizzle: {self.drizzle_renorm_method}"
                )
            except Exception:
                logger.debug(
                    "  -> Impossible de lire reproject_between_batches depuis settings. Valeur par d√©faut utilis√©e."
                )

        self.stacking_mode = "kappa-sigma"
        self.kappa = 2.5
        self.batch_size = 10
        self.stack_kappa_low = 2.5
        self.stack_kappa_high = 2.5
        self.winsor_limits = (0.05, 0.05)
        self.stack_final_combine = "mean"
        self.stack_reject_algo = "none"
        self.hot_pixel_threshold = 3.0
        self.neighborhood_size = 5
        self.zoom_percent = 0
        self.bayer_pattern = "GRBG"
        self.drizzle_mode = "Final"
        self.drizzle_scale = 2.0
        self.drizzle_wht_threshold = 0.0
        self.drizzle_kernel = "square"
        self.drizzle_pixfrac = 1.0
        self.drizzle_fillval = "0.0"  # default fill value for Drizzle
        self.final_scnr_target_channel = "green"
        self.final_scnr_amount = 0.8
        self.final_scnr_preserve_luminosity = True

        self.files_in_queue = 0
        self.processed_files_count = 0
        self.aligned_files_count = 0
        self.stacked_batches_count = 0
        self.total_batches_estimated = 0
        self.failed_align_count = 0
        self.failed_stack_count = 0
        self.skipped_files_count = 0
        self.photutils_bn_applied_in_session = False
        self.bn_globale_applied_in_session = False
        self.cb_applied_in_session = False
        self.feathering_applied_in_session = False
        self.low_wht_mask_applied_in_session = False
        self.scnr_applied_in_session = False
        self.crop_applied_in_session = False
        self.photutils_params_used_in_session = {}
        self.last_saved_data_for_preview = None

        logger.debug("  -> Attributs simples et param√®tres par d√©faut initialis√©s.")

        self.local_aligner_instance = None
        self.is_local_alignment_preferred_for_mosaic = True
        logger.debug(
            f"  -> Mosa√Øque: Pr√©f√©rence pour alignement local: {self.is_local_alignment_preferred_for_mosaic}"
        )

        try:
            logger.debug("  -> Instanciation ChromaticBalancer...")
            self.chroma_balancer = ChromaticBalancer(border_size=50, blur_radius=15)
            logger.debug("     ‚úì ChromaticBalancer OK.")
        except Exception as e_cb:
            logger.debug(f"  -> ERREUR ChromaticBalancer: {e_cb}")
            self.chroma_balancer = None

        try:
            logger.debug(
                "  -> Instanciation SeestarAligner (pour alignement g√©n√©ral astroalign)..."
            )
            self.aligner = SeestarAligner()
            self.aligner.use_cuda = self.use_cuda
            logger.debug("     ‚úì SeestarAligner (astroalign) OK.")
        except Exception as e_align:
            logger.debug(f"  -> ERREUR SeestarAligner (astroalign): {e_align}")
            self.aligner = None
            raise

        try:
            logger.debug("  -> Instanciation AstrometrySolver...")
            self.astrometry_solver = AstrometrySolver(
                progress_callback=self.update_progress
            )
            logger.debug("     ‚úì AstrometrySolver instanci√©.")
        except Exception as e_as_solver:
            logger.debug(f"  -> ERREUR AstrometrySolver instantiation: {e_as_solver}")
            self.astrometry_solver = None

        logger.debug(
            "==== FIN INITIALISATION SeestarQueuedStacker (AVEC LocalAligner) ====\n"
        )

        if _LOCAL_ALIGNER_AVAILABLE and SeestarLocalAligner is not None:
            try:
                logger.debug(
                    "  -> Instanciation SeestarLocalAligner (pour mosa√Øque locale si pr√©f√©r√©e)..."
                )
                self.local_aligner_instance = SeestarLocalAligner(debug=True)
                logger.debug("     ‚úì SeestarLocalAligner instanci√©.")
            except Exception as e_local_align_inst:
                logger.debug(
                    f"  -> ERREUR lors de l'instanciation de SeestarLocalAligner: {e_local_align_inst}"
                )
                traceback.print_exc(limit=1)
                self.local_aligner_instance = None
                logger.debug(
                    "     WARN QM: Instanciation de SeestarLocalAligner a √©chou√©. Il ne sera pas utilisable."
                )
        else:
            logger.debug(
                "  -> SeestarLocalAligner n'est pas disponible (import √©chou√© ou classe non d√©finie), instanciation ignor√©e."
            )
            self.local_aligner_instance = None

        logger.debug(
            "==== FIN INITIALISATION SeestarQueuedStacker (AVEC LocalAligner) ====\n"
        )

    ######################################################################################################################################################

    def _move_to_unaligned(self, file_path):
        """
        D√©place un fichier dans un sous-dossier 'unaligned_by_stacker'
        CR√â√â DANS LE DOSSIER D'ORIGINE du fichier.
        Notifie l'utilisateur via update_progress (log sp√©cial) la premi√®re fois
        pour un dossier source.
        Version: V_MoveUnaligned_RobustAdd
        """
        # --- NOUVELLE V√âRIFICATION DE LA PR√âSENCE DU FICHIER EN D√âBUT ---
        if not file_path or not isinstance(file_path, str) or file_path.strip() == "":
            logger.debug(
                f"DEBUG QM [_move_to_unaligned_V_MoveUnaligned_RobustAdd]: Chemin fichier source invalide ou vide: '{file_path}'. Sortie pr√©coce."
            )
            return

        original_folder_abs = os.path.abspath(os.path.dirname(file_path))
        file_basename = os.path.basename(file_path)

        # Ce check doit √™tre fait apr√®s avoir extrait le basename pour un meilleur log
        if not os.path.exists(file_path):
            logger.debug(
                f"DEBUG QM [_move_to_unaligned_V_MoveUnaligned_RobustAdd]: Fichier '{file_basename}' (chemin: '{file_path}') N'EXISTE PAS au d√©but de _move_to_unaligned. Abandon."
            )
            return  # Sortie si le fichier n'existe vraiment pas

        unaligned_subfolder_name = "unaligned_by_stacker"
        destination_folder_for_this_file = os.path.join(
            original_folder_abs, unaligned_subfolder_name
        )

        # --- Notification (message sp√©cial) ---
        # Cette notification se fait toujours si le dossier n'a pas d√©j√† √©t√© averti,
        # avant m√™me de tenter le d√©placement.
        # Le set.add() pour le dossier sera fait plus tard, SEULEMENT si le d√©placement r√©ussit.
        if original_folder_abs not in self.warned_unaligned_source_folders:
            info_msg_for_ui = (
                f"Les fichiers de '{os.path.basename(original_folder_abs)}' qui ne peuvent pas √™tre align√©s "
                f"seront d√©plac√©s dans son sous-dossier : '{unaligned_subfolder_name}'. "
                f"(Ce message appara√Æt une fois par dossier source par session)"
            )
            self.update_progress(f"UNALIGNED_INFO:{info_msg_for_ui}", "WARN")
            # Ne pas ajouter √† warned_unaligned_source_folders ICI, mais plus tard si succ√®s.
        # --- Fin Notification ---

        try:
            # S'assurer que le dossier de destination existe
            os.makedirs(destination_folder_for_this_file, exist_ok=True)

            dest_path = os.path.join(destination_folder_for_this_file, file_basename)

            # G√©rer les conflits de noms si le fichier existe d√©j√† √† destination
            if os.path.exists(dest_path):
                base, ext = os.path.splitext(file_basename)
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                unique_filename = f"{base}_unaligned_{timestamp}{ext}"
                dest_path = os.path.join(
                    destination_folder_for_this_file, unique_filename
                )
                logger.debug(
                    f"DEBUG QM [_move_to_unaligned_V_MoveUnaligned_RobustAdd]: Conflit de nom pour '{file_basename}', renomm√© en '{unique_filename}' dans '{destination_folder_for_this_file}'."
                )

            # --- Logique de d√©placement/copie avec retry et pause ---
            max_retries = 3
            initial_delay_sec = 0.1  # Petite pause initiale
            final_move_copy_success = False

            for attempt in range(max_retries):
                if not os.path.exists(
                    file_path
                ):  # Le fichier peut dispara√Ætre entre les tentatives
                    logger.debug(
                        f"DEBUG QM [_move_to_unaligned_V_MoveUnaligned_RobustAdd]: Fichier '{file_basename}' n'existe plus √† l'essai {attempt+1}. Abandon des tentatives."
                    )
                    break  # Sortir de la boucle si le fichier a disparu

                try:
                    # Ajouter une petite pause pour laisser le syst√®me lib√©rer le fichier
                    if attempt > 0:  # Pause uniquement apr√®s la premi√®re tentative
                        time.sleep(
                            initial_delay_sec * (2 ** (attempt - 1))
                        )  # D√©lai exponentiel
                        logger.debug(
                            f"DEBUG QM [_move_to_unaligned_V_MoveUnaligned_RobustAdd]: R√©-essai {attempt+1}/{max_retries} pour d√©placer '{file_basename}' apr√®s pause..."
                        )

                    # Tenter de d√©placer
                    shutil.move(file_path, dest_path)
                    final_move_copy_success = True
                    break  # Succ√®s, sortir de la boucle

                except (OSError, FileNotFoundError, shutil.Error) as e_move:
                    logger.debug(
                        f"DEBUG QM [_move_to_unaligned_V_MoveUnaligned_RobustAdd]: √âchec d√©placement '{file_basename}' (essai {attempt+1}): {e_move}"
                    )
                    if (
                        attempt == max_retries - 1
                    ):  # Derni√®re tentative √©chou√©e, essayer de copier
                        logger.debug(
                            f"DEBUG QM [_move_to_unaligned_V_MoveUnaligned_RobustAdd]: √âchec d√©placement apr√®s {max_retries} essais. Tentative de copie en dernier recours..."
                        )
                        try:
                            shutil.copy2(file_path, dest_path)
                            logger.debug(
                                f"DEBUG QM [_move_to_unaligned_V_MoveUnaligned_RobustAdd]: Copie de '{file_basename}' r√©ussie en dernier recours."
                            )
                            final_move_copy_success = (
                                True  # Consid√©rer comme succ√®s si la copie marche
                            )
                        except Exception as e_copy:
                            logger.debug(
                                f"DEBUG QM [_move_to_unaligned_V_MoveUnaligned_RobustAdd]: √âchec de la copie de '{file_basename}' aussi : {e_copy}"
                            )
                            final_move_copy_success = False  # La copie a aussi √©chou√©
            # --- Fin Nouvelle logique ---

            if final_move_copy_success:
                self.update_progress(
                    f"   D√©plac√© vers non align√©s: '{file_basename}' (maintenant dans '{unaligned_subfolder_name}' de son dossier source).",
                    "INFO_DETAIL",
                )
                logger.debug(
                    f"DEBUG QM [_move_to_unaligned_V_MoveUnaligned_RobustAdd]: Fichier '{file_basename}' trait√© (d√©plac√©/copi√©) vers '{dest_path}'."
                )

                # NOUVEAU : Ajouter le dossier source au set SEULEMENT si le d√©placement/copie a r√©ussi
                self.warned_unaligned_source_folders.add(original_folder_abs)
                logger.debug(
                    f"DEBUG QM [_move_to_unaligned_V_MoveUnaligned_RobustAdd]: Dossier source '{original_folder_abs}' ajout√© √† warned_unaligned_source_folders."
                )

            else:  # Final_move_copy_success est False
                self.update_progress(
                    f"   ‚ùå √âchec d√©placement/copie fichier non-align√© '{file_basename}'.",
                    "ERROR",
                )
                logger.debug(
                    f"ERREUR QM [_move_to_unaligned_V_MoveUnaligned_RobustAdd]: √âchec d√©finitif d√©placement/copie de '{file_basename}'."
                )

        except Exception as e:
            # G√©rer toute autre exception inattendue lors de la pr√©paration/finalisation
            error_details = (
                f"Erreur g√©n√©rale _move_to_unaligned pour '{file_basename}': {e}"
            )
            logger.debug(
                f"ERREUR QM [_move_to_unaligned_V_MoveUnaligned_RobustAdd]: {error_details}"
            )
            traceback.print_exc(limit=1)
            self.update_progress(
                f"   ‚ùå Erreur inattendue d√©placement/copie fichier non-align√© '{file_basename}': {type(e).__name__}",
                "ERROR",
            )

    #######################################################################################################################################################

    # --- DANS LA CLASSE SeestarQueuedStacker DANS seestar/queuep/queue_manager.py ---

    def initialize(
        self, output_dir, reference_image_shape_hwc_input, enable_preview=False
    ):  # Renomm√© pour clart√©
        """
        Pr√©pare les dossiers, r√©initialise l'√©tat.
        CR√âE/INITIALISE les fichiers memmap pour SUM et WHT (si pas Drizzle Incr√©mental VRAI).
        OU INITIALISE les objets Drizzle persistants (si Drizzle Incr√©mental VRAI).
        Version: V_DrizIncr_StrategyA_Init_MemmapDirFix
        """

        logger.debug(
            f"DEBUG QM [initialize V_DrizIncr_StrategyA_Init_MemmapDirFix]: D√©but avec output_dir='{output_dir}', shape_ref_HWC={reference_image_shape_hwc_input}"
        )
        logger.debug(f"  VALEURS AU D√âBUT DE INITIALIZE:")
        logger.debug(
            f"    -> self.is_mosaic_run: {getattr(self, 'is_mosaic_run', 'Non D√©fini')}"
        )
        logger.debug(
            f"    -> self.drizzle_active_session: {getattr(self, 'drizzle_active_session', 'Non D√©fini')}"
        )
        logger.debug(
            f"    -> self.drizzle_mode: {getattr(self, 'drizzle_mode', 'Non D√©fini')}"
        )

        self.enable_preview = bool(enable_preview)

        # --- Nettoyage et cr√©ation dossiers ---
        try:
            self.output_folder = os.path.abspath(output_dir)
            self.unaligned_folder = os.path.join(self.output_folder, "unaligned_files")
            self.drizzle_temp_dir = os.path.join(
                self.output_folder, "drizzle_temp_inputs"
            )
            self.drizzle_batch_output_dir = os.path.join(
                self.output_folder, "drizzle_batch_outputs"
            )
            self.classic_batch_output_dir = os.path.join(
                self.output_folder, "classic_batch_outputs"
            )

            # D√©finir le chemin du dossier memmap mais ne le cr√©er que si n√©cessaire plus tard
            memmap_dir = os.path.join(self.output_folder, "memmap_accumulators")
            self.sum_memmap_path = os.path.join(memmap_dir, "cumulative_SUM.npy")
            self.wht_memmap_path = os.path.join(memmap_dir, "cumulative_WHT.npy")

            os.makedirs(self.output_folder, exist_ok=True)
            os.makedirs(self.unaligned_folder, exist_ok=True)

            if self.drizzle_active_session or self.is_mosaic_run:
                os.makedirs(self.drizzle_temp_dir, exist_ok=True)
                if self.drizzle_mode == "Final" and not self.is_mosaic_run:
                    os.makedirs(self.drizzle_batch_output_dir, exist_ok=True)

            # La cr√©ation de memmap_dir est d√©plac√©e plus bas, dans la condition o√π elle est utilis√©e.

            if self.perform_cleanup:
                if os.path.isdir(self.drizzle_temp_dir):
                    try:
                        shutil.rmtree(self.drizzle_temp_dir)
                        os.makedirs(self.drizzle_temp_dir, exist_ok=True)
                    except Exception as e:
                        self.update_progress(
                            f"‚ö†Ô∏è Erreur nettoyage {self.drizzle_temp_dir}: {e}"
                        )
                if (
                    os.path.isdir(self.drizzle_batch_output_dir)
                    and self.drizzle_mode == "Final"
                    and not self.is_mosaic_run
                ):  # Nettoyer seulement si utilis√©
                    try:
                        shutil.rmtree(self.drizzle_batch_output_dir)
                        os.makedirs(self.drizzle_batch_output_dir, exist_ok=True)
                    except Exception as e:
                        self.update_progress(
                            f"‚ö†Ô∏è Erreur nettoyage {self.drizzle_batch_output_dir}: {e}"
                        )
                if (
                    os.path.isdir(self.classic_batch_output_dir)
                    and self.reproject_between_batches
                ):
                    try:
                        shutil.rmtree(self.classic_batch_output_dir)
                        os.makedirs(self.classic_batch_output_dir, exist_ok=True)
                    except Exception as e:
                        self.update_progress(
                            f"‚ö†Ô∏è Erreur nettoyage {self.classic_batch_output_dir}: {e}"
                        )
            self.update_progress(f"üóÑÔ∏è Dossiers pr√™ts.")
        except OSError as e:
            self.update_progress(
                f"‚ùå Erreur critique cr√©ation dossiers: {e}", 0
            )  # progress_val 0
            return False

        # --- Validation Shape R√©f√©rence (HWC) ---
        if (
            not isinstance(reference_image_shape_hwc_input, tuple)
            or len(reference_image_shape_hwc_input) != 3
            or reference_image_shape_hwc_input[2] != 3
        ):
            self.update_progress(
                f"‚ùå Erreur interne: Shape r√©f√©rence HWC invalide ({reference_image_shape_hwc_input})."
            )
            return False

        if (
            reference_image_shape_hwc_input[0] <= 0
            or reference_image_shape_hwc_input[1] <= 0
        ):
            self.update_progress(
                f"‚ùå Erreur interne: Dimensions non-positives pour la r√©f√©rence ({reference_image_shape_hwc_input})."
            )
            return False

        current_output_shape_hw_for_accum_or_driz = None

        # --- Logique d'initialisation sp√©cifique au mode ---
        is_true_incremental_drizzle_mode = (
            self.drizzle_active_session
            and self.drizzle_mode == "Incremental"
            and not self.is_mosaic_run
        )

        logger.debug(
            f"  DEBUG QM [initialize]: Valeur calcul√©e de is_true_incremental_drizzle_mode: {is_true_incremental_drizzle_mode}"
        )
        logger.debug(
            f"    -> self.drizzle_active_session √âTAIT: {self.drizzle_active_session}"
        )
        logger.debug(
            f"    -> self.drizzle_mode √âTAIT: '{self.drizzle_mode}' (compar√© √† 'Incremental')"
        )
        logger.debug(
            f"    -> not self.is_mosaic_run √âTAIT: {not self.is_mosaic_run} (self.is_mosaic_run √©tait {self.is_mosaic_run})"
        )

        if is_true_incremental_drizzle_mode:
            logger.debug(
                "DEBUG QM [initialize V_DrizIncr_StrategyA_Init_MemmapDirFix]: Mode Drizzle Incr√©mental VRAI d√©tect√©."
            )
            if self.reference_wcs_object is None:
                self.update_progress(
                    "‚ùå Erreur: WCS de r√©f√©rence manquant pour initialiser la grille Drizzle Incr√©mental.",
                    "ERROR",
                )
                return False
            try:
                ref_shape_hw_for_grid = reference_image_shape_hwc_input[:2]
                if (
                    self.drizzle_output_wcs is None
                    or self.drizzle_output_shape_hw is None
                ):
                    self.drizzle_output_wcs, self.drizzle_output_shape_hw = (
                        self._create_drizzle_output_wcs(
                            self.reference_wcs_object,
                            ref_shape_hw_for_grid,
                            self.drizzle_scale,
                        )
                    )
                    if (
                        self.drizzle_output_wcs is None
                        or self.drizzle_output_shape_hw is None
                    ):
                        raise RuntimeError(
                            "√âchec _create_drizzle_output_wcs pour Drizzle Incr√©mental."
                        )
                current_output_shape_hw_for_accum_or_driz = self.drizzle_output_shape_hw
                logger.debug(
                    f"  -> Grille Drizzle Incr√©mental: Shape={current_output_shape_hw_for_accum_or_driz}, WCS CRVAL={self.drizzle_output_wcs.wcs.crval if self.drizzle_output_wcs.wcs else 'N/A'}"
                )
            except Exception as e_grid:
                self.update_progress(
                    f"‚ùå Erreur cr√©ation grille Drizzle Incr√©mental: {e_grid}", "ERROR"
                )
                return False

            self.update_progress(
                f"üíß Initialisation des objets Drizzle persistants pour mode Incr√©mental (Shape: {current_output_shape_hw_for_accum_or_driz})..."
            )
            self.incremental_drizzle_objects = []
            self.incremental_drizzle_sci_arrays = []  # ‚Üê ajout√©
            self.incremental_drizzle_wht_arrays = []  # ‚Üê ajout√©
            num_channels_driz = 3

            try:
                for _ in range(num_channels_driz):
                    driz_obj = Drizzle(
                        out_shape=current_output_shape_hw_for_accum_or_driz,
                        kernel=self.drizzle_kernel,
                        fillval=str(getattr(self, "drizzle_fillval", "0.0")),
                    )
                    self.incremental_drizzle_sci_arrays.append(driz_obj.out_img)
                    self.incremental_drizzle_wht_arrays.append(driz_obj.out_wht)
                    self.incremental_drizzle_objects.append(driz_obj)

                logger.debug(
                    f"  -> {len(self.incremental_drizzle_objects)} objets Drizzle persistants cr√©√©s pour mode Incr√©mental."
                )
            except Exception as e_driz_obj_init:
                self.update_progress(
                    f"‚ùå Erreur initialisation objets Drizzle persistants: {e_driz_obj_init}",
                    "ERROR",
                )
                traceback.print_exc(limit=1)
                return False

            self.cumulative_sum_memmap = None
            self.cumulative_wht_memmap = None
            self.memmap_shape = None
            logger.debug(
                "  -> Memmaps SUM/WHT d√©sactiv√©s pour Drizzle Incr√©mental VRAI."
            )

        else:  # Mosa√Øque, Drizzle Final standard, ou Stacking Classique
            logger.debug(
                "DEBUG QM [initialize V_DrizIncr_StrategyA_Init_MemmapDirFix]: Mode NON-Drizzle Incr. VRAI. Initialisation Memmaps SUM/W..."
            )

            os.makedirs(memmap_dir, exist_ok=True)
            H, W, C = reference_image_shape_hwc_input

            self.cumulative_sum_memmap = np.lib.format.open_memmap(
                self.sum_memmap_path, mode="w+", dtype=np.float32, shape=(H, W, C)
            )
            self.cumulative_sum_memmap[:] = 0.0

            self.cumulative_wht_memmap = np.lib.format.open_memmap(
                self.wht_memmap_path, mode="w+", dtype=np.float32, shape=(H, W)
            )
            self.cumulative_wht_memmap[:] = 0.0

            # Do not force inter-batch reprojection here. Respect existing
            # configuration loaded from settings or previous state.

            self.memmap_shape = (H, W, C)

            if self.enable_preview:
                self.preview_H = 256
                self.preview_W = 256
                self.preview_sum = np.zeros((self.preview_H, self.preview_W, C), dtype=np.float32)
                self.preview_wht = np.zeros((self.preview_H, self.preview_W), dtype=np.float32)

        # --- R√©initialisations Communes ---
        self.warned_unaligned_source_folders.clear()
        logger.debug(
            "DEBUG QM [initialize V_DrizIncr_StrategyA_Init_MemmapDirFix]: R√©initialisation des autres √©tats..."
        )
        # self.reference_wcs_object est conserv√© s'il a √©t√© d√©fini par start_processing (plate-solving de r√©f)
        self.intermediate_drizzle_batch_files = []

        self.processed_files.clear()
        with self.folders_lock:
            self.additional_folders = []
        self.current_batch_data = []
        self.current_stack_header = None
        self.images_in_cumulative_stack = 0
        self.cumulative_drizzle_data = None
        self.total_exposure_seconds = 0.0
        self.final_stacked_path = None
        self.processing_error = None
        self.files_in_queue = 0
        self.processed_files_count = 0
        self.aligned_files_count = 0
        self.stacked_batches_count = 0
        self.total_batches_estimated = 0
        self.failed_align_count = 0
        self.failed_stack_count = 0
        self.skipped_files_count = 0

        self.photutils_bn_applied_in_session = False
        self.bn_globale_applied_in_session = False
        self.cb_applied_in_session = False
        self.feathering_applied_in_session = False
        self.low_wht_mask_applied_in_session = False
        self.scnr_applied_in_session = False
        self.crop_applied_in_session = False
        self.photutils_params_used_in_session = {}

        while not self.queue.empty():
            try:
                self.queue.get_nowait()
                self.queue.task_done()
            except Exception:
                break

        if hasattr(self, "aligner") and self.aligner:
            self.aligner.stop_processing = False
        logger.debug(
            "DEBUG QM [initialize V_DrizIncr_StrategyA_Init_MemmapDirFix]: Initialisation termin√©e avec succ√®s."
        )
        return True

    ########################################################################################################################################################

    def update_progress(self, message, progress=None):
        message = str(message)
        if self.progress_callback:
            try:
                self.progress_callback(message, progress)
            except Exception as e:
                logger.debug(f"Error in progress callback: {e}")
        else:
            if progress is not None:
                logger.debug(f"[{int(progress)}%] {message}")
            else:
                logger.debug(message)

    def _send_eta_update(self):
        """Compute and send remaining time estimation to the GUI."""
        if not hasattr(self, "_eta_start_time") or self._eta_start_time is None:
            return
        if self.total_batches_estimated > 0 and self.stacked_batches_count > 0:
            elapsed = time.monotonic() - self._eta_start_time
            eta_sec = (elapsed / self.stacked_batches_count) * max(
                self.total_batches_estimated - self.stacked_batches_count, 0
            )
            hours, rem = divmod(int(eta_sec), 3600)
            minutes, seconds = divmod(rem, 60)
            eta_str = f"{hours:02d}:{minutes:02d}:{seconds:02d}"
            self.update_progress(f"ETA_UPDATE:{eta_str}", None)

    ########################################################################################################################################################

    ##########################################################################################################################################################

    def _update_preview(self, force_update=False):
        """Safely calls the preview callback, including stack count and batch info."""
        if self.preview_callback is None or self.current_stack_data is None:
            return
        try:
            data_copy = self.current_stack_data.copy()
            header_copy = (
                self.current_stack_header.copy() if self.current_stack_header else None
            )
            img_count = self.images_in_cumulative_stack
            total_imgs_est = self.files_in_queue
            current_batch = self.stacked_batches_count
            total_batches_est = self.total_batches_estimated
            stack_name = f"Stack ({img_count}/{total_imgs_est} Img | Batch {current_batch}/{total_batches_est if total_batches_est > 0 else '?'})"
            self.preview_callback(
                data_copy,
                header_copy,
                stack_name,
                img_count,
                total_imgs_est,
                current_batch,
                total_batches_est,
            )
        except Exception as e:
            logger.debug(f"Error in preview callback: {e}")
            traceback.print_exc(limit=2)

    ###########################################################################################################################################################

    def _calculate_M_from_wcs(
        self,
        wcs_source: WCS,
        wcs_target: WCS,
        shape_source_hw: tuple,
        num_points_edge: int = 6,
        ransac_thresh_fallback: float = 5.0,
    ):  # << MODIFI√â la valeur par d√©faut √† 5.0
        """
        Calcule la matrice affine M...
        MODIFIED: Augmentation du seuil RANSAC par d√©faut et logs plus d√©taill√©s.
        """
        # Utiliser self.update_progress pour les logs visibles dans l'UI
        self.update_progress(
            f"    [FallbackWCS] Tentative calcul M (Source->Cible). RANSAC Thresh: {ransac_thresh_fallback}px",
            "DEBUG_DETAIL",
        )  # << Log am√©lior√©

        if not (
            wcs_source
            and wcs_source.is_celestial
            and wcs_target
            and wcs_target.is_celestial
        ):
            self.update_progress(
                "      [FallbackWCS] √âchec: WCS source ou cible invalide/non c√©leste.",
                "WARN",
            )
            return None

        h, w = shape_source_hw
        if h < num_points_edge or w < num_points_edge:
            self.update_progress(
                f"      [FallbackWCS] √âchec: Image source trop petite ({w}x{h}) pour grille {num_points_edge}x{num_points_edge}.",
                "WARN",
            )
            return None

        xs = np.linspace(0, w - 1, num_points_edge, dtype=np.float32)
        ys = np.linspace(0, h - 1, num_points_edge, dtype=np.float32)
        xv, yv = np.meshgrid(xs, ys)
        src_pts_pix_flat = np.vstack([xv.ravel(), yv.ravel()]).T

        if len(src_pts_pix_flat) < 3:
            self.update_progress(
                f"      [FallbackWCS] √âchec: Pas assez de points de contr√¥le ({len(src_pts_pix_flat)}).",
                "WARN",
            )
            return None
        self.update_progress(
            f"      [FallbackWCS] {len(src_pts_pix_flat)} points de contr√¥le source g√©n√©r√©s.",
            "DEBUG_DETAIL",
        )

        try:
            sky_coords_ra, sky_coords_dec = wcs_source.all_pix2world(
                src_pts_pix_flat[:, 0], src_pts_pix_flat[:, 1], 0
            )
            if not (
                np.all(np.isfinite(sky_coords_ra))
                and np.all(np.isfinite(sky_coords_dec))
            ):
                self.update_progress(
                    "      [FallbackWCS] √âchec: Coords c√©lestes non finies depuis wcs_source.",
                    "WARN",
                )
                return None

            dst_pts_pix_flat_x, dst_pts_pix_flat_y = wcs_target.all_world2pix(
                sky_coords_ra, sky_coords_dec, 0
            )
            if not (
                np.all(np.isfinite(dst_pts_pix_flat_x))
                and np.all(np.isfinite(dst_pts_pix_flat_y))
            ):
                self.update_progress(
                    "      [FallbackWCS] √âchec: Coords pixels cibles non finies depuis wcs_target.",
                    "WARN",
                )
                return None

            dst_pts_pix_flat = np.column_stack(
                (dst_pts_pix_flat_x, dst_pts_pix_flat_y)
            ).astype(np.float32)
            self.update_progress(
                f"      [FallbackWCS] Points source et destination pr√™ts pour estimation M.",
                "DEBUG_DETAIL",
            )

            src_pts_cv = src_pts_pix_flat.reshape(-1, 1, 2)
            dst_pts_cv = dst_pts_pix_flat.reshape(-1, 1, 2)

            M, inliers_mask = cv2.estimateAffinePartial2D(
                src_pts_cv,
                dst_pts_cv,
                method=cv2.RANSAC,
                ransacReprojThreshold=ransac_thresh_fallback,
                maxIters=1000,
                confidence=0.95,
            )

            if M is None:
                self.update_progress(
                    f"      [FallbackWCS] √âchec: estimateAffinePartial2D n'a pas retourn√© de matrice (avec seuil {ransac_thresh_fallback}px).",
                    "WARN",
                )  # << Log am√©lior√©
                return None

            num_inliers = np.sum(inliers_mask) if inliers_mask is not None else 0
            min_inliers_needed_fallback = max(3, len(src_pts_cv) // 6)

            self.update_progress(
                f"      [FallbackWCS] RANSAC: {num_inliers} inliers / {len(src_pts_cv)} points (seuil {ransac_thresh_fallback}px). Requis: {min_inliers_needed_fallback}.",
                "INFO",
            )  # << Log am√©lior√©

            if num_inliers < min_inliers_needed_fallback:
                self.update_progress(
                    f"      [FallbackWCS] √âchec: Pas assez d'inliers RANSAC.", "WARN"
                )
                return None

            self.update_progress(
                f"      [FallbackWCS] Matrice M calcul√©e avec succ√®s.", "INFO"
            )
            # logger.debug(f"  DEBUG QM [_calculate_M_from_wcs]: Matrice M de fallback WCS calcul√©e:\n{M}") # Garder pour debug console
            return M

        except Exception as e_m_wcs:
            self.update_progress(
                f"      [FallbackWCS] ERREUR: Exception lors du calcul de M: {e_m_wcs}",
                "ERROR",
            )
            # logger.debug(f"ERREUR QM [_calculate_M_from_wcs]: {e_m_wcs}") # Garder pour debug console
            # if self.debug_mode: traceback.print_exc(limit=1) # Supposant un self.debug_mode
            return None

    ##########################################################################################################################################################

    # --- DANS LA CLASSE SeestarQueuedStacker DANS seestar/queuep/queue_manager.py ---

    def _update_preview_sum_w(self, downsample_factor=2):
        """
        Met √† jour l'aper√ßu en utilisant les accumulateurs SUM et WHT.
        Calcule l'image moyenne, applique optionnellement le Low WHT Mask,
        normalise, sous-√©chantillonne et envoie au callback GUI.
        """
        logger.debug(
            "DEBUG QM [_update_preview_sum_w]: Tentative de mise √† jour de l'aper√ßu SUM/W..."
        )

        if self.preview_callback is None:
            logger.debug(
                "DEBUG QM [_update_preview_sum_w]: Callback preview non d√©fini. Sortie."
            )
            return
        if self.cumulative_sum_memmap is None or self.cumulative_wht_memmap is None:
            logger.debug(
                "DEBUG QM [_update_preview_sum_w]: Memmaps SUM ou WHT non initialis√©s. Sortie."
            )
            return

        try:
            logger.debug(
                "DEBUG QM [_update_preview_sum_w]: Lecture des donn√©es depuis memmap..."
            )
            # Lire en float64 pour la division pour maintenir la pr√©cision autant que possible
            current_sum = np.array(
                self.cumulative_sum_memmap, dtype=np.float64
            )  # Shape (H, W, C)
            current_wht_map = np.array(
                self.cumulative_wht_memmap, dtype=np.float64
            )  # Shape (H, W)
            logger.debug(
                f"DEBUG QM [_update_preview_sum_w]: Donn√©es lues. SUM shape={current_sum.shape}, WHT shape={current_wht_map.shape}"
            )

            # Calcul de l'image moyenne (SUM / WHT)
            epsilon = 1e-9  # Pour √©viter division par z√©ro
            wht_for_division = np.maximum(current_wht_map, epsilon)
            # Broadcaster wht_for_division (H,W) pour correspondre √† current_sum (H,W,C)
            wht_broadcasted = wht_for_division[:, :, np.newaxis]

            avg_img_fullres = None
            with np.errstate(divide="ignore", invalid="ignore"):
                avg_img_fullres = current_sum / wht_broadcasted
            avg_img_fullres = np.nan_to_num(
                avg_img_fullres, nan=0.0, posinf=0.0, neginf=0.0
            )
            logger.debug(
                f"DEBUG QM [_update_preview_sum_w]: Image moyenne SUM/W calcul√©e. Shape={avg_img_fullres.shape}"
            )
            logger.debug(
                f"  Range avant normalisation 0-1: [{np.nanmin(avg_img_fullres):.4g}, {np.nanmax(avg_img_fullres):.4g}]"
            )

            # --- NOUVEAU : Feathering et Low WHT Mask pour l'aper√ßu ---
            if hasattr(self, "apply_feathering") and self.apply_feathering:
                if _FEATHERING_AVAILABLE:
                    logger.debug(
                        "DEBUG QM [_update_preview_sum_w]: Application du Feathering pour l'aper√ßu..."
                    )
                    avg_img_fullres = feather_by_weight_map(
                        avg_img_fullres,
                        current_wht_map.astype(np.float32),
                        blur_px=getattr(self, "feather_blur_px", 256),
                    )
                else:
                    logger.debug(
                        "WARN QM [_update_preview_sum_w]: Feathering activ√© mais fonction non disponible."
                    )

            if hasattr(self, "apply_low_wht_mask") and self.apply_low_wht_mask:
                if _LOW_WHT_MASK_AVAILABLE:
                    logger.debug(
                        "DEBUG QM [_update_preview_sum_w]: Application du Low WHT Mask pour l'aper√ßu..."
                    )
                    avg_img_fullres = apply_low_wht_mask(
                        avg_img_fullres,
                        current_wht_map.astype(np.float32),
                        percentile=getattr(self, "low_wht_percentile", 5),
                        soften_px=getattr(self, "low_wht_soften_px", 128),
                        progress_callback=self.update_progress,
                    )
                else:
                    logger.debug(
                        "WARN QM [_update_preview_sum_w]: Low WHT Mask activ√© mais fonction non disponible (√©chec import)."
                    )
            # --- FIN NOUVEAU ---

            # Normalisation finale 0-1 (n√©cessaire si Low WHT Mask n'a pas √©t√© appliqu√©,
            # ou pour re-normaliser si Low WHT Mask a modifi√© la plage de mani√®re inattendue,
            # bien qu'il soit cens√© retourner 0-1). Une double normalisation ne nuit pas ici
            # car la premi√®re (avant mask) √©tait pour la fonction mask, celle-ci est pour l'affichage.
            min_val_final = np.nanmin(avg_img_fullres)
            max_val_final = np.nanmax(avg_img_fullres)
            preview_data_normalized = avg_img_fullres  # Par d√©faut si d√©j√† 0-1
            if max_val_final > min_val_final:
                preview_data_normalized = (avg_img_fullres - min_val_final) / (
                    max_val_final - min_val_final
                )
            elif np.any(np.isfinite(avg_img_fullres)):  # Image constante non nulle
                preview_data_normalized = np.full_like(
                    avg_img_fullres, 0.5
                )  # Image grise
            else:  # Image vide ou tout NaN/Inf
                preview_data_normalized = np.zeros_like(avg_img_fullres)

            preview_data_normalized = np.clip(preview_data_normalized, 0.0, 1.0).astype(
                np.float32
            )
            logger.debug(
                f"DEBUG QM [_update_preview_sum_w]: Image APER√áU normalis√©e finale 0-1. Range: [{np.nanmin(preview_data_normalized):.3f}, {np.nanmax(preview_data_normalized):.3f}]"
            )

            # Sous-√©chantillonnage pour l'affichage
            preview_data_to_send = preview_data_normalized
            if downsample_factor > 1:
                try:
                    h, w = preview_data_normalized.shape[
                        :2
                    ]  # Fonctionne pour N&B (H,W) et Couleur (H,W,C)
                    new_h, new_w = h // downsample_factor, w // downsample_factor
                    if (
                        new_h > 10 and new_w > 10
                    ):  # √âviter de r√©duire √† une taille trop petite
                        # cv2.resize attend (W, H) pour dsize
                        preview_data_to_send = cv2.resize(
                            preview_data_normalized,
                            (new_w, new_h),
                            interpolation=cv2.INTER_AREA,
                        )
                        logger.debug(
                            f"DEBUG QM [_update_preview_sum_w]: Aper√ßu sous-√©chantillonn√© √† {preview_data_to_send.shape}"
                        )
                except Exception as e_resize:
                    logger.debug(
                        f"ERREUR QM [_update_preview_sum_w]: √âchec r√©duction taille APER√áU: {e_resize}"
                    )
                    # Continuer avec l'image pleine r√©solution si le resize √©choue

            # Pr√©paration du header et du nom pour le callback
            header_copy = (
                self.current_stack_header.copy()
                if self.current_stack_header
                else fits.Header()
            )
            # Ajouter/Mettre √† jour les infos de l'aper√ßu dans le header
            header_copy["PREV_SRC"] = (
                "SUM/W Accumulators",
                "Source data for this preview",
            )
            if hasattr(self, "apply_low_wht_mask") and self.apply_low_wht_mask:
                header_copy["PREV_LWM"] = (True, "Low WHT Mask applied to this preview")
                header_copy["PREV_LWMP"] = (
                    getattr(self, "low_wht_percentile", 5),
                    "Low WHT Mask Percentile for preview",
                )
                header_copy["PREV_LWMS"] = (
                    getattr(self, "low_wht_soften_px", 128),
                    "Low WHT Mask SoftenPx for preview",
                )

            img_count = self.images_in_cumulative_stack
            total_imgs_est = self.files_in_queue
            current_batch_num = self.stacked_batches_count
            total_batches_est = self.total_batches_estimated
            stack_name_parts = ["Aper√ßu SUM/W"]
            if hasattr(self, "apply_low_wht_mask") and self.apply_low_wht_mask:
                stack_name_parts.append("LWMask")
            stack_name_parts.append(
                f"({img_count}/{total_imgs_est} Img | Lot {current_batch_num}/{total_batches_est if total_batches_est > 0 else '?'})"
            )
            stack_name = " ".join(stack_name_parts)

            logger.debug(
                f"DEBUG QM [_update_preview_sum_w]: Appel du callback preview avec image APER√áU shape {preview_data_to_send.shape}..."
            )
            self.preview_callback(
                preview_data_to_send,
                header_copy,
                stack_name,
                img_count,
                total_imgs_est,
                current_batch_num,
                total_batches_est,
            )
            logger.debug("DEBUG QM [_update_preview_sum_w]: Callback preview termin√©.")

        except MemoryError as mem_err:
            logger.debug(
                f"ERREUR QM [_update_preview_sum_w]: ERREUR M√âMOIRE - {mem_err}"
            )
            self.update_progress(
                f"‚ùå ERREUR M√âMOIRE pendant la mise √† jour de l'aper√ßu SUM/W."
            )
            traceback.print_exc(limit=1)
        except Exception as e:
            logger.debug(
                f"ERREUR QM [_update_preview_sum_w]: Exception inattendue - {e}"
            )
            self.update_progress(
                f"‚ùå Erreur inattendue pendant la mise √† jour de l'aper√ßu SUM/W: {e}"
            )
            traceback.print_exc(limit=2)

    #############################################################################################################################################################

    def _update_preview_incremental_drizzle(self):
        """
        Met √† jour l'aper√ßu sp√©cifiquement pour le mode Drizzle Incr√©mental.
        Envoie les donn√©es drizzl√©es cumulatives et le header mis √† jour.
        """
        if self.preview_callback is None or self.cumulative_drizzle_data is None:
            # Ne rien faire si pas de callback ou pas de donn√©es drizzle cumulatives
            return

        try:
            # Utiliser les donn√©es et le header cumulatifs Drizzle
            data_to_send = self.cumulative_drizzle_data.copy()
            header_to_send = (
                self.current_stack_header.copy()
                if self.current_stack_header
                else fits.Header()
            )

            # Informations pour l'affichage dans l'aper√ßu
            img_count = (
                self.images_in_cumulative_stack
            )  # Compteur mis √† jour dans _process_incremental_drizzle_batch
            total_imgs_est = self.files_in_queue  # Estimation globale
            current_batch = self.stacked_batches_count  # Le lot qui vient d'√™tre trait√©
            total_batches_est = self.total_batches_estimated

            # Cr√©er un nom pour l'aper√ßu
            stack_name = f"Drizzle Incr ({img_count}/{total_imgs_est} Img | Lot {current_batch}/{total_batches_est if total_batches_est > 0 else '?'})"

            # Appeler le callback du GUI
            self.preview_callback(
                data_to_send,
                header_to_send,
                stack_name,
                img_count,
                total_imgs_est,
                current_batch,
                total_batches_est,
            )
            # logger.debug(f"DEBUG: Preview updated with Incremental Drizzle data (Shape: {data_to_send.shape})") # Optionnel

        except AttributeError:
            # Cas o√π cumulative_drizzle_data ou current_stack_header pourrait √™tre None entre-temps
            logger.debug(
                "Warning: Attribut manquant pour l'aper√ßu Drizzle incr√©mental."
            )
        except Exception as e:
            logger.debug(f"Error in _update_preview_incremental_drizzle: {e}")
            traceback.print_exc(limit=2)

    def _update_preview_master(self):
        """Update preview when using incremental reprojection.

        This version dynamically crops the preview to the region that actually
        contains stacked data to avoid showing large empty borders.
        """
        if (
            self.preview_callback is None
            or self.master_sum is None
            or self.master_coverage is None
        ):
            return

        try:
            # Compute mean stack while protecting against divide by zero
            wht_safe = np.maximum(self.master_coverage, 1e-9)
            avg = self.master_sum / wht_safe[..., None]
            avg = np.nan_to_num(avg, nan=0.0, posinf=0.0, neginf=0.0)

            # --- Dynamic cropping to area with data ---
            rows, cols = np.where(self.master_coverage > 0)
            if rows.size > 0:
                top, bottom = np.min(rows), np.max(rows)
                left, right = np.min(cols), np.max(cols)
                if top < bottom and left < right:
                    avg_cropped = avg[top : bottom + 1, left : right + 1]
                else:
                    avg_cropped = avg
            else:
                avg_cropped = avg

            # Normalise for display
            mn, mx = np.nanmin(avg_cropped), np.nanmax(avg_cropped)
            if np.isfinite(mn) and np.isfinite(mx) and mx > mn:
                norm = (avg_cropped - mn) / (mx - mn)
            else:
                norm = np.zeros_like(avg_cropped, dtype=np.float32)

            self.current_stack_data = np.clip(norm, 0.0, 1.0).astype(np.float32)
            self.current_stack_header = self.current_stack_header or fits.Header()
            self._update_preview()
        except Exception as e:
            logger.debug(f"Error in _update_preview_master: {e}")

    def _downsample_preview(self, data: np.ndarray, wht: np.ndarray) -> None:
        # Preview buffer logic
        pH, pW = self.preview_H, self.preview_W
        H, W, _ = data.shape
        small = data.reshape(pH, H // pH, pW, W // pW, -1).mean(axis=(1, 3))
        w_small = wht.reshape(pH, H // pH, pW, W // pW).sum(axis=(1, 3))
        self.preview_sum += small * w_small[..., None]
        self.preview_wht += w_small

    def get_preview_image(self) -> np.ndarray:
        w_safe = np.maximum(self.preview_wht, 1e-6)[..., None]
        return (self.preview_sum / w_safe).astype(np.float32)

    #########################################################################################################################################################

    def _create_drizzle_output_wcs(self, ref_wcs, ref_shape_2d, scale_factor):
        """
        Cr√©e le WCS et la shape (H,W) pour l'image Drizzle de sortie.
        Inspir√© de full_drizzle.py corrig√© pour conserver le m√™me centre ciel.

        Args
        ----
        ref_wcs : astropy.wcs.WCS
            WCS de r√©f√©rence (doit √™tre c√©leste et avoir pixel_shape).
        ref_shape_2d : tuple(int, int)
            (H, W) de l'image de r√©f√©rence.
        scale_factor : float
            Facteur d'√©chantillonnage Drizzle (>1 = sur-√©chantillonner).

        Returns
        -------
        (output_wcs, output_shape_hw)  o√π output_shape_hw = (H, W)
        """
        # ------------------ 0. V√©rifications ------------------
        if not ref_wcs or not ref_wcs.is_celestial:
            raise ValueError("R√©f√©rence WCS invalide ou non c√©leste pour Drizzle.")
        if ref_wcs.pixel_shape is None:
            raise ValueError("R√©f√©rence WCS n'a pas de pixel_shape d√©fini.")
        if len(ref_shape_2d) != 2:
            raise ValueError(f"R√©f√©rence shape 2D (H,W) attendu, re√ßu {ref_shape_2d}")

        if self.fixed_output_wcs is not None and self.fixed_output_shape is not None:
            return self.fixed_output_wcs, self.fixed_output_shape

        # ------------------ 1. Dimensions de sortie ------------------
        h_in, w_in = ref_shape_2d
        out_h = int(round(h_in * scale_factor))
        out_w = int(round(w_in * scale_factor))
        out_h = max(1, out_h)
        out_w = max(1, out_w)
        out_shape_hw = (out_h, out_w)

        logger.debug(
            f"[DrizzleWCS] Scale={scale_factor}  -->  shape in={ref_shape_2d}  ->  out={out_shape_hw}"
        )

        # ------------------ 2. Construction d'un WCS sans rotation ------------------
        out_wcs = WCS(naxis=2)
        out_wcs.wcs.crval = list(ref_wcs.wcs.crval)
        out_wcs.wcs.crpix = (
            np.asarray(ref_wcs.wcs.crpix, dtype=float) * scale_factor
        ).tolist()

        ref_scale_arcsec = self.reference_pixel_scale_arcsec
        if ref_scale_arcsec is None:
            try:
                ref_scale_deg = np.mean(np.abs(proj_plane_pixel_scales(ref_wcs)))
                ref_scale_arcsec = ref_scale_deg * 3600.0
            except Exception:
                ref_scale_arcsec = 1.0

        final_scale_deg = (ref_scale_arcsec / scale_factor) / 3600.0
        out_wcs.wcs.cd = np.array([[-final_scale_deg, 0.0], [0.0, final_scale_deg]])
        out_wcs.wcs.ctype = ["RA---TAN", "DEC--TAN"]
        out_wcs.pixel_shape = (out_w, out_h)
        try:
            out_wcs._naxis1 = out_w
            out_wcs._naxis2 = out_h
        except AttributeError:
            pass

        self.fixed_output_wcs = out_wcs
        self.fixed_output_shape = out_shape_hw
        logger.debug(f"[DrizzleWCS] Output WCS OK  (shape={out_shape_hw})")
        return out_wcs, out_shape_hw

    def _calculate_fixed_orientation_grid(self, ref_wcs, scale_factor: float = 1.0):
        """Return a WCS derived from ``ref_wcs`` with no rotation."""
        if not ref_wcs or not ref_wcs.is_celestial or ref_wcs.pixel_shape is None:
            return None, None
        try:
            ref_h = int(ref_wcs.pixel_shape[1])
            ref_w = int(ref_wcs.pixel_shape[0])
        except Exception:
            return None, None

        out_h = max(1, int(round(ref_h * scale_factor)))
        out_w = max(1, int(round(ref_w * scale_factor)))
        out_shape_hw = (out_h, out_w)

        out_wcs = WCS(naxis=2)
        out_wcs.wcs.crval = list(ref_wcs.wcs.crval)
        out_wcs.wcs.crpix = (
            np.asarray(ref_wcs.wcs.crpix, dtype=float) * scale_factor
        ).tolist()

        ref_scale_arcsec = self.reference_pixel_scale_arcsec
        if ref_scale_arcsec is None:
            try:
                ref_scale_deg = np.mean(np.abs(proj_plane_pixel_scales(ref_wcs)))
                ref_scale_arcsec = ref_scale_deg * 3600.0
            except Exception:
                ref_scale_arcsec = 1.0

        final_scale_deg = (ref_scale_arcsec / scale_factor) / 3600.0
        out_wcs.wcs.cd = np.array([[-final_scale_deg, 0.0], [0.0, final_scale_deg]])
        out_wcs.wcs.ctype = ["RA---TAN", "DEC--TAN"]
        out_wcs.pixel_shape = (out_w, out_h)
        try:
            out_wcs._naxis1 = out_w
            out_wcs._naxis2 = out_h
        except AttributeError:
            pass

        return out_wcs, out_shape_hw

    ###########################################################################################################################################################

    def _calculate_final_mosaic_grid_dynamic(
        self, all_input_wcs_list, all_input_headers_list=None, scale_factor: float = 1.0
    ):
        """Compute a global WCS using a dynamic bounding box with optional rotation.

        Parameters
        ----------
        all_input_wcs_list : list
            List of input :class:`~astropy.wcs.WCS` objects.
        all_input_headers_list : list, optional
            Optional list of FITS headers matching ``all_input_wcs_list`` used to
            recover missing ``pixel_shape`` information.
        scale_factor : float, optional
            Drizzle scale factor to apply to the output grid. The final pixel
            scale of the mosaic is divided by this factor. Defaults to ``1.0``.
        """
        num_wcs = len(all_input_wcs_list)
        logger.debug(
            f"DEBUG (Backend _calculate_final_mosaic_grid - Dynamic Box): Appel avec {num_wcs} WCS (scale={scale_factor})."
        )
        self.update_progress(
            f"üìê Calcul de la grille de sortie dynamique ({num_wcs} WCS)..."
        )
        if num_wcs == 0:
            return None, None

        all_sky_corners_list = []
        for i, wcs_in in enumerate(all_input_wcs_list):
            if wcs_in is None or not wcs_in.is_celestial:
                continue
            if (
                wcs_in.pixel_shape is None
                and all_input_headers_list
                and i < len(all_input_headers_list)
            ):
                hdr = all_input_headers_list[i]
                n1 = hdr.get("NAXIS1")
                n2 = hdr.get("NAXIS2")
                if n1 and n2:
                    wcs_in.pixel_shape = (int(n1), int(n2))
            if wcs_in.pixel_shape is None:
                continue
            nx, ny = wcs_in.pixel_shape
            pixel_corners = np.array(
                [[0, 0], [nx - 1, 0], [nx - 1, ny - 1], [0, ny - 1]], dtype=np.float64
            )
            sky_corners = wcs_in.pixel_to_world(
                pixel_corners[:, 0], pixel_corners[:, 1]
            )
            all_sky_corners_list.append(sky_corners)

        if not all_sky_corners_list:
            return None, None

        all_corners_flat_skycoord = skycoord_concatenate(all_sky_corners_list)

        center_ra = np.median([w.wcs.crval[0] for w in all_input_wcs_list])
        center_dec = np.median([w.wcs.crval[1] for w in all_input_wcs_list])

        local_tan = WCS(naxis=2)
        local_tan.wcs.ctype = ["RA---TAN", "DEC--TAN"]
        local_tan.wcs.crval = [center_ra, center_dec]
        local_tan.wcs.crpix = [0.0, 0.0]
        local_tan.wcs.cd = np.eye(2)

        xy = np.vstack(local_tan.world_to_pixel(all_corners_flat_skycoord)).T
        eigvals, eigvecs = np.linalg.eig(np.cov(xy, rowvar=False))
        theta = np.arctan2(eigvecs[1, 0], eigvecs[0, 0]) * 180 / np.pi

        rot = np.array(
            [
                [np.cos(np.deg2rad(-theta)), -np.sin(np.deg2rad(-theta))],
                [np.sin(np.deg2rad(-theta)), np.cos(np.deg2rad(-theta))],
            ]
        )
        xy_rot = xy @ rot.T
        minx, miny = xy_rot.min(axis=0)
        maxx, maxy = xy_rot.max(axis=0)

        scales_arcsec = []
        for w in all_input_wcs_list:
            try:
                scales_arcsec.append(
                    np.mean(np.abs(proj_plane_pixel_scales(w))) * 3600.0
                )
            except Exception:
                pass
        final_pixel_scale_arcsec = (
            float(np.median(scales_arcsec)) if scales_arcsec else 1.0
        )
        final_pixel_scale_deg = final_pixel_scale_arcsec / 3600.0
        # Apply drizzle scale factor if requested
        if scale_factor and scale_factor != 1.0:
            final_pixel_scale_deg /= float(scale_factor)

        content_width_deg = maxx - minx
        content_height_deg = maxy - miny

        nw = int(np.ceil(content_width_deg / final_pixel_scale_deg)) + 4
        nh = int(np.ceil(content_height_deg / final_pixel_scale_deg)) + 4

        output_wcs = WCS(naxis=2)
        output_wcs.wcs.ctype = ["RA---TAN", "DEC--TAN"]
        output_wcs.wcs.crval = [center_ra, center_dec]
        # Center the mosaic so that the lower-left corner of the bounding box
        # maps to pixel (1, 1). This avoids negative pixel coordinates once
        # images are reprojected onto the final canvas.
        output_wcs.wcs.crpix = [-minx + 1.0, -miny + 1.0]
        cos_t = np.cos(np.deg2rad(theta))
        sin_t = np.sin(np.deg2rad(theta))
        output_wcs.wcs.cd = final_pixel_scale_deg * np.array(
            [[-cos_t, sin_t], [sin_t, cos_t]]
        )
        output_wcs.pixel_shape = (nw, nh)

        self.update_progress(
            f"üó∫Ô∏è Global grid : dynamic box {(nh, nw)} px, theta={theta:.2f}¬∞",
            "INFO",
        )
        logger.debug(
            f"DEBUG (Backend Grid Calc): dynamic grid {nw}x{nh}  scale={final_pixel_scale_arcsec:.3f} arcsec/pix  theta={theta:.2f}  factor={scale_factor}"
        )
        return output_wcs, (nh, nw)

    def _calculate_final_mosaic_grid(
        self, all_input_wcs_list, all_input_headers_list=None, scale_factor: float = 1.0
    ):
        """Compute the final mosaic grid using ``find_optimal_celestial_wcs``.

        Parameters
        ----------
        all_input_wcs_list : list
            List of input :class:`~astropy.wcs.WCS` objects.
        all_input_headers_list : list, optional
            Optional list of FITS headers matching ``all_input_wcs_list`` used to
            recover missing ``pixel_shape`` information.
        scale_factor : float, optional
            Drizzle scale factor to apply to the output grid. The final pixel
            scale of the mosaic is divided by this factor. Defaults to ``1.0``.
        """

        num_wcs = len(all_input_wcs_list)
        logger.debug(
            f"DEBUG (Backend _calculate_final_mosaic_grid - Optimal): Appel avec {num_wcs} WCS (scale={scale_factor})."
        )
        self.update_progress(f"üìê Calcul de la grille de sortie ({num_wcs} WCS)...")

        if num_wcs == 0:
            return None, None

        try:
            from reproject.mosaicking import find_optimal_celestial_wcs
        except Exception as e:
            logger.error("find_optimal_celestial_wcs unavailable: %s", e)
            find_optimal_celestial_wcs = None
        _fallback_grid = None

        valid_wcs = []
        valid_shapes_hw = []
        headers = all_input_headers_list or []

        for i, wcs_in in enumerate(all_input_wcs_list):
            if not isinstance(wcs_in, WCS) or not wcs_in.is_celestial:
                continue

            shape_hw = None

            if wcs_in.pixel_shape is not None:
                shape_hw = (wcs_in.pixel_shape[1], wcs_in.pixel_shape[0])
            elif i < len(headers):
                hdr = headers[i]
                n1 = hdr.get("NAXIS1")
                n2 = hdr.get("NAXIS2")
                if n1 and n2:
                    shape_hw = (int(n2), int(n1))
                    wcs_in.pixel_shape = (int(n1), int(n2))

            if shape_hw is None:
                continue

            valid_wcs.append(wcs_in)
            valid_shapes_hw.append(shape_hw)

        if not valid_wcs:
            return None, None

        inputs_for_optimal = []
        for wcs_obj, shape_hw in zip(valid_wcs, valid_shapes_hw):
            if wcs_obj.pixel_shape is None:
                wcs_obj.pixel_shape = (shape_hw[1], shape_hw[0])
            inputs_for_optimal.append((shape_hw, wcs_obj))

        sum_scales_deg = 0.0
        count_scales = 0
        for wcs_scale in valid_wcs:
            try:
                pixel_scales = proj_plane_pixel_scales(wcs_scale)
                scale_deg = np.mean(np.abs([s.to_value(u.deg) for s in pixel_scales]))
            except Exception:
                try:
                    scale_deg = np.sqrt(
                        np.abs(np.linalg.det(wcs_scale.pixel_scale_matrix))
                    )
                except Exception:
                    continue
            if np.isfinite(scale_deg) and scale_deg > 1e-10:
                sum_scales_deg += scale_deg
                count_scales += 1

        avg_scale_deg = 2.0 / 3600.0
        if count_scales > 0:
            avg_scale_deg = sum_scales_deg / count_scales

        target_res_deg_per_pix = avg_scale_deg / float(scale_factor or 1.0)

        try:
            if find_optimal_celestial_wcs:
                out_wcs, out_shape_hw = find_optimal_celestial_wcs(
                    inputs_for_optimal,
                    resolution=Angle(target_res_deg_per_pix, unit=u.deg),
                    auto_rotate=True,
                    projection="TAN",
                    reference=None,
                    frame="icrs",
                )
            else:
                raise ImportError("find_optimal_celestial_wcs unavailable")
        except Exception as e:
            logger.error(
                "Error calling find_optimal_celestial_wcs: %s", e, exc_info=True
            )
            if _fallback_grid:
                out_wcs, out_shape_hw = _fallback_grid(
                    valid_wcs, valid_shapes_hw, scale_factor
                )
            else:
                out_wcs, out_shape_hw = self._calculate_final_mosaic_grid_dynamic(
                    valid_wcs, None, scale_factor
                )

        if out_wcs and out_shape_hw:
            expected_wh = (out_shape_hw[1], out_shape_hw[0])
            try:
                out_wcs.pixel_shape = expected_wh
                out_wcs.wcs.naxis1 = expected_wh[0]
                out_wcs.wcs.naxis2 = expected_wh[1]
            except Exception:
                pass

            self.update_progress(
                f"üó∫Ô∏è Global grid : optimal {(out_shape_hw)} px",
                "INFO",
            )
            logger.debug(
                "DEBUG (Backend Grid Calc): optimal grid %dx%d scale=%.5f deg/pix",
                expected_wh[0],
                expected_wh[1],
                target_res_deg_per_pix,
            )

        return out_wcs, out_shape_hw

    ###########################################################################################################################################################

    def _prepare_global_reprojection_grid(self):
        """Solve all FITS files and compute the final mosaic grid."""
        self.update_progress(
            "üîç Pr√©-scan et r√©solution astrom√©trique de tous les fichiers...", 5
        )
        if not self.all_input_filepaths:
            try:
                self.all_input_filepaths = list(self.queue.queue)
            except Exception:
                self.all_input_filepaths = []

        wcs_list: list[WCS] = []
        header_list: list[fits.Header] = []

        solver_settings = {
            "local_solver_preference": self.local_solver_preference,
            "api_key": self.api_key,
            "astap_path": self.astap_path,
            "astap_data_dir": self.astap_data_dir,
            "astap_search_radius": self.astap_search_radius,
            "astap_downsample": self.astap_downsample,
            "astap_sensitivity": self.astap_sensitivity,
            "local_ansvr_path": self.local_ansvr_path,
            "scale_est_arcsec_per_pix": getattr(
                self, "reference_pixel_scale_arcsec", None
            ),
            "use_radec_hints": False,
        }

        total = len(self.all_input_filepaths)

        def _solve_single(path):
            try:
                hdr_local = fits.getheader(path, memmap=False)
                if self.astrometry_solver:
                    wcs_obj_local = self.astrometry_solver.solve(
                        path,
                        hdr_local,
                        solver_settings,
                        update_header_with_solution=False,
                    )
                else:
                    wcs_obj_local = solve_image_wcs(
                        path,
                        hdr_local,
                        solver_settings,
                        update_header_with_solution=False,
                    )
                return path, hdr_local, wcs_obj_local, None
            except Exception as exc:
                return path, None, None, exc

        max_workers = max(1, (os.cpu_count() or 1) // 2)
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as ex:
            futures = [ex.submit(_solve_single, fp) for fp in self.all_input_filepaths]
            for idx, fut in enumerate(concurrent.futures.as_completed(futures), 1):
                if self.stop_processing:
                    for f in futures:
                        f.cancel()
                    return False

                fpath, hdr, wcs_obj, err = fut.result()
                self.update_progress(
                    f"   Solving {idx}/{total}: {os.path.basename(fpath)}",
                    5 + int(35 * ((idx - 1) / max(total, 1))),
                )

                if err is not None:
                    self.update_progress(
                        f"‚ö†Ô∏è [Pr√©-scan] Erreur WCS sur {os.path.basename(fpath)}: {err}",
                        "WARN",
                    )

                elif wcs_obj and wcs_obj.is_celestial:
                    wcs_list.append(wcs_obj)
                    header_list.append(hdr)
                else:
                    self.update_progress(
                        f"‚ö†Ô∏è [Pr√©-scan] √âchec r√©solution pour {os.path.basename(fpath)}",
                        "WARN",
                    )

        if not wcs_list:
            self.update_progress(
                "‚ùå √âchec de la pr√©paration de la grille : aucun WCS valide trouv√© apr√®s r√©solution.",
                "ERROR",
            )
            return False

        if (
            len(wcs_list) == 1
            and self.reproject_between_batches
            and not self.is_mosaic_run
        ):
            # When doing classic stacking with reprojection of a single
            # file, use the dynamic bounding-box logic to avoid cropping.
            ref_wcs, ref_shape = self._calculate_final_mosaic_grid(
                wcs_list,
                header_list,
                scale_factor=self.drizzle_scale if self.drizzle_active_session else 1.0,
            )
        elif len(wcs_list) == 1:
            ref_wcs = wcs_list[0]
            ref_shape = ref_wcs.pixel_shape
        else:
            ref_wcs, ref_shape = self._calculate_final_mosaic_grid(
                wcs_list,
                header_list,
                scale_factor=self.drizzle_scale if self.drizzle_active_session else 1.0,
            )
            if ref_wcs is None:
                self.update_progress(
                    "‚ùå √âchec du calcul de la grille de sortie globale.", "ERROR"
                )
                return False

        self.reference_wcs_object = ref_wcs
        self.reference_shape = ref_shape
        self.reference_header_for_wcs = ref_wcs.to_header(relax=True)
        self.ref_wcs_header = self.reference_header_for_wcs
        try:
            self.reference_wcs_object.pixel_shape = (
                self.reference_shape[1],
                self.reference_shape[0],
            )
            self.reference_wcs_object._naxis1 = self.reference_shape[1]
            self.reference_wcs_object._naxis2 = self.reference_shape[0]
        except Exception:
            pass


        # Do not automatically enable inter-batch reprojection when preparing
        # the global grid. The user's existing preference is preserved.

        crval_str = ", ".join(f"{x:.5f}" for x in self.reference_wcs_object.wcs.crval)
        self.update_progress(
            f"üó∫Ô∏è Grille globale finale pr√™te ‚Äì Centre={crval_str}, Shape={self.reference_shape}",
            "INFO",
        )

        self._ensure_memmaps_match_reference()

        return True

    def _recalculate_total_batches(self):
        """Estimates the total number of batches based on files_in_queue."""
        if self.batch_size > 0:
            self.total_batches_estimated = math.ceil(
                self.files_in_queue / self.batch_size
            )
        else:
            self.update_progress(
                f"‚ö†Ô∏è Taille de lot invalide ({self.batch_size}), impossible d'estimer le nombre total de lots."
            )
            self.total_batches_estimated = 0

    ################################################################################################################################################

    def _calculate_quality_metrics(self, image_data):
        """Calculates SNR and Star Count, WITH ADDED LOGGING."""  # Docstring updated
        scores = {"snr": 0.0, "stars": 0.0}
        # --- Added: Get filename for logging ---
        # We need the filename here. Since it's not passed directly, we'll have to
        # rely on it being logged just before this function is called in _process_file.
        # This isn't ideal, but avoids major refactoring for diagnostics.
        # The log message in _process_file before calling this will provide context.
        # --- End Added ---

        if image_data is None:
            return scores  # Should not happen if called correctly

        # --- Calculate SNR ---
        snr = 0.0
        try:
            if image_data.ndim == 3 and image_data.shape[2] == 3:
                # Use luminance for SNR calculation
                data_for_snr = (
                    0.299 * image_data[..., 0]
                    + 0.587 * image_data[..., 1]
                    + 0.114 * image_data[..., 2]
                )
            elif image_data.ndim == 2:
                data_for_snr = image_data
            else:
                # self.update_progress(f"‚ö†Ô∏è Format non support√© pour SNR (fichier ?)") # Logged before
                raise ValueError("Unsupported image format for SNR")

            finite_data = data_for_snr[np.isfinite(data_for_snr)]
            if finite_data.size < 50:  # Need enough pixels
                # self.update_progress(f"‚ö†Ô∏è Pas assez de pixels finis pour SNR (fichier ?)") # Logged before
                raise ValueError("Not enough finite pixels for SNR")

            signal = np.median(finite_data)
            mad = np.median(np.abs(finite_data - signal))  # Median Absolute Deviation
            noise_std = max(mad * 1.4826, 1e-9)  # Approx std dev from MAD, avoid zero
            snr = signal / noise_std
            scores["snr"] = np.clip(snr, 0.0, 1000.0)  # Clip SNR to a reasonable range

        except Exception as e:
            # Error message will be logged before returning from _process_file
            # self.update_progress(f"‚ö†Ô∏è Erreur calcul SNR (fichier ?): {e}")
            scores["snr"] = 0.0

        # --- Calculate Star Count ---
        num_stars = 0
        try:
            transform, (source_list, _target_list) = aa.find_transform(
                image_data, image_data
            )
            num_stars = len(source_list)
            max_stars_for_score = 200.0
            scores["stars"] = np.clip(num_stars / max_stars_for_score, 0.0, 1.0)

        except (
            aa.MaxIterError,
            ValueError,
        ) as star_err:  # Handles specific astroalign errors
            self.update_progress(
                f"      Quality Scores -> Warning: Failed finding stars ({type(star_err).__name__}). Stars score set to 0."
            )
            scores = {
                "snr": scores.get("snr", 0.0),
                "stars": 0.0,
            }  # Explicitly set scores
            return scores  # Return immediately

        except Exception as e:  # Handles any other unexpected error
            self.update_progress(
                f"      Quality Scores -> Error calculating stars: {e}. Stars score set to 0."
            )
            scores = {
                "snr": scores.get("snr", 0.0),
                "stars": 0.0,
            }  # Explicitly set scores
            return scores  # Return immediately

        # --- This section is ONLY reached if the 'try' block succeeds ---
        self.update_progress(
            f"      Quality Scores -> SNR: {scores['snr']:.2f}, Stars: {scores['stars']:.3f} ({num_stars} raw)"
        )
        return scores  # Return the successfully calculated scores

    ##################################################################################################################

    def set_progress_callback(self, callback):
        """D√©finit la fonction de rappel pour les mises √† jour de progression."""
        # logger.debug("DEBUG QM: Appel de set_progress_callback.") # Optionnel
        self.progress_callback = callback
        # Passer le callback √† l'aligneur astroalign s'il existe
        if (
            hasattr(self, "aligner")
            and self.aligner is not None
            and hasattr(self.aligner, "set_progress_callback")
            and callable(callback)
        ):
            try:
                # logger.debug("DEBUG QM: Tentative de configuration callback sur aligner (astroalign)...")
                self.aligner.set_progress_callback(callback)
                # logger.debug("DEBUG QM: Callback aligner (astroalign) configur√©.")
            except Exception as e_align_cb:
                logger.debug(
                    f"Warning QM: Could not set progress callback on aligner (astroalign): {e_align_cb}"
                )
        # Passer le callback √† l'aligneur local s'il existe
        if (
            hasattr(self, "local_aligner_instance")
            and self.local_aligner_instance is not None
            and hasattr(self.local_aligner_instance, "set_progress_callback")
            and callable(callback)
        ):
            try:
                # logger.debug("DEBUG QM: Tentative de configuration callback sur local_aligner_instance...")
                self.local_aligner_instance.set_progress_callback(callback)
                # logger.debug("DEBUG QM: Callback local_aligner_instance configur√©.")
            except Exception as e_local_cb:
                logger.debug(
                    f"Warning QM: Could not set progress callback on local_aligner_instance: {e_local_cb}"
                )

    ################################################################################################################################################

    def set_preview_callback(self, callback):
        """D√©finit la fonction de rappel pour les mises √† jour de l'aper√ßu."""
        logger.debug("DEBUG QM: Appel de set_preview_callback (VERSION ULTRA PROPRE).")
        self.preview_callback = callback

    ################################################################################################################################################

    def _worker(self):
        """
        Thread principal pour le traitement des images.
        """
        logger.debug(
            "\n"
            + "=" * 10
            + f" DEBUG QM [_worker V_NoDerotation]: Initialisation du worker "
            + "=" * 10
        )
        self.processing_active = True
        self.processing_error = None
        # start_time_session = time.monotonic() # D√©commenter si besoin
        self._eta_start_time = time.monotonic()

        reference_image_data_for_global_alignment = None
        reference_header_for_global_alignment = None
        mosaic_ref_panel_image_data = None  # Utilis√© seulement si local_fast_fallback
        mosaic_ref_panel_header = None  # Utilis√© seulement si local_fast_fallback

        current_batch_items_with_masks_for_stack_batch = []
        self._current_batch_paths = []
        self.intermediate_drizzle_batch_files = []
        solved_items_for_final_reprojection = []
        all_aligned_files_with_info_for_mosaic = []

        # --- 0.B D√©termination du mode d'op√©ration (bas√© sur self.xxx sett√©s par start_processing) ---
        use_local_aligner_for_this_mosaic_run = (
            self.is_mosaic_run
            and self.mosaic_alignment_mode in ["local_fast_fallback", "local_fast_only"]
            and _LOCAL_ALIGNER_AVAILABLE
            and self.local_aligner_instance is not None
        )
        use_wcs_fallback_if_local_fails = (  # Utilis√© seulement si use_local_aligner_for_this_mosaic_run est True
            use_local_aligner_for_this_mosaic_run
            and self.mosaic_alignment_mode == "local_fast_fallback"
        )
        use_astrometry_per_panel_mosaic = (
            self.is_mosaic_run and self.mosaic_alignment_mode == "astrometry_per_panel"
        )

        logger.debug(f"DEBUG QM [_worker V_NoDerotation]: Configuration de la session:")
        logger.debug(f"  - is_mosaic_run: {self.is_mosaic_run}")
        if self.is_mosaic_run:
            logger.debug(f"    - mosaic_alignment_mode: '{self.mosaic_alignment_mode}'")
            logger.debug(
                f"    - -> Utilisation Aligneur Local (FastAligner): {use_local_aligner_for_this_mosaic_run}"
            )
            if use_local_aligner_for_this_mosaic_run:
                logger.debug(
                    f"      - Fallback WCS si FastAligner √©choue: {use_wcs_fallback_if_local_fails}"
                )
            logger.debug(
                f"    - -> Utilisation Astrometry par Panneau: {use_astrometry_per_panel_mosaic}"
            )  # Crucial
        logger.debug(
            f"  - drizzle_active_session (pour stacking standard non-mosa√Øque): {self.drizzle_active_session}"
        )
        if self.drizzle_active_session and not self.is_mosaic_run:
            logger.debug(f"    - drizzle_mode (standard): '{self.drizzle_mode}'")

        path_of_processed_ref_panel_basename = (
            None  # Pour skipper le panneau d'ancre si local_fast_fallback
        )

        # R√©cup√©rer les param√®tres Drizzle sp√©cifiques √† la mosa√Øque depuis mosaic_settings_dict
        mosaic_drizzle_kernel_effective = str(
            self.mosaic_settings_dict.get("kernel", "square")
        )
        mosaic_drizzle_pixfrac_effective = float(
            self.mosaic_settings_dict.get("pixfrac", 1.0)
        )
        mosaic_drizzle_fillval_effective = str(
            self.mosaic_settings_dict.get("fillval", "0.0")
        )
        mosaic_drizzle_wht_threshold_effective = float(
            self.mosaic_settings_dict.get("wht_threshold", 0.01)
        )

        # Les param√®tres globaux de Drizzle (self.drizzle_kernel, self.drizzle_pixfrac, etc.)
        # sont d√©j√† configur√©s par start_processing.
        # Ici, nous les *surchargons* avec les valeurs sp√©cifiques √† la mosa√Øque si le mode mosa√Øque est actif.
        if self.is_mosaic_run:
            self.drizzle_kernel = mosaic_drizzle_kernel_effective
            self.drizzle_pixfrac = mosaic_drizzle_pixfrac_effective
            self.drizzle_fillval = mosaic_drizzle_fillval_effective  # <-- Assurez-vous que cet attribut existe sur self
            self.drizzle_wht_threshold = mosaic_drizzle_wht_threshold_effective  # <-- Assurez-vous que cet attribut existe sur self

            logger.debug(
                f"DEBUG QM [_worker]: Mode Mosa√Øque ACTIF. Surcharge des param√®tres Drizzle globaux:"
            )
            logger.debug(
                f"  -> self.drizzle_kernel mis √† '{self.drizzle_kernel}' (depuis mosaic_settings)"
            )
            logger.debug(
                f"  -> self.drizzle_pixfrac mis √† '{self.drizzle_pixfrac}' (depuis mosaic_settings)"
            )
            logger.debug(
                f"  -> self.drizzle_fillval mis √† '{self.drizzle_fillval}' (depuis mosaic_settings)"
            )
            logger.debug(
                f"  -> self.drizzle_wht_threshold mis √† '{self.drizzle_wht_threshold}' (depuis mosaic_settings)"
            )
        else:
            # S'assurer que les attributs sp√©cifiques √† la mosa√Øque (qui ne sont pas self.drizzle_*)
            # ont une valeur par d√©faut, m√™me si le mode mosa√Øque n'est pas actif.
            # Cela √©vite des erreurs si on les lit par erreur dans d'autres branches de code.
            # (Si vos attributs `mosaic_drizzle_kernel` etc. ne sont pas d√©j√† initialis√©s dans `__init__`,
            # il faudrait les initialiser ici. Actuellement, ils le sont via `start_processing` ou `initialize`
            # donc ce bloc 'else' est pour la clart√© mais pas strictement n√©cessaire ici si le flux est correct.)
            pass  # Les attributs self.mosaic_drizzle_xyz sont d√©j√† sett√©s par start_processing et ne sont pas lus ici.

        try:

            # =====================================================================================
            # === SECTION 1: PR√âPARATION DE L'IMAGE DE R√âF√âRENCE ET DU/DES WCS DE R√âF√âRENCE ===
            # =====================================================================================

            self.update_progress("‚≠ê Pr√©paration image(s) de r√©f√©rence...")

            # --- D√©termination du dossier et des fichiers pour la r√©f√©rence ---
            files_for_ref_scan = []
            folder_for_ref_scan = None
            if self.current_folder and os.path.isdir(self.current_folder):
                files_for_ref_scan = sorted(
                    [
                        f
                        for f in os.listdir(self.current_folder)
                        if f.lower().endswith((".fit", ".fits"))
                    ]
                )
                if files_for_ref_scan:
                    folder_for_ref_scan = self.current_folder

            if (
                not files_for_ref_scan
                and hasattr(self, "additional_folders")
                and self.additional_folders
            ):
                first_additional = self.additional_folders[0]
                if os.path.isdir(first_additional):
                    files_for_ref_scan_add = sorted(
                        [
                            f
                            for f in os.listdir(first_additional)
                            if f.lower().endswith((".fit", ".fits"))
                        ]
                    )
                    if files_for_ref_scan_add:
                        files_for_ref_scan = files_for_ref_scan_add
                        folder_for_ref_scan = first_additional
                        logger.debug(
                            f"DEBUG QM [_worker]: Dossier initial vide/invalide, utilisation du premier dossier additionnel '{os.path.basename(folder_for_ref_scan)}' pour la r√©f√©rence."
                        )

            if not files_for_ref_scan or not folder_for_ref_scan:
                raise RuntimeError(
                    "Aucun fichier FITS trouv√© dans les dossiers d'entr√©e initiaux pour d√©terminer la r√©f√©rence."
                )
            # --- Fin logique dossier/fichiers r√©f√©rence ---

            # Configuration de self.aligner pour _get_reference_image
            self.aligner.correct_hot_pixels = self.correct_hot_pixels
            self.aligner.hot_pixel_threshold = self.hot_pixel_threshold
            self.aligner.neighborhood_size = self.neighborhood_size
            self.aligner.bayer_pattern = self.bayer_pattern
            # self.aligner.reference_image_path est d√©j√† sett√© dans start_processing

            logger.debug(
                f"DEBUG QM [_worker]: Appel √† self.aligner._get_reference_image avec dossier '{os.path.basename(folder_for_ref_scan)}' pour la r√©f√©rence de base/globale..."
            )
            # _get_reference_image DOIT s'assurer que s'il ajoute _SOURCE_PATH √† son header interne
            # avant de sauvegarder reference_image.fit, il utilise os.path.basename().
            # C'est la source de l'erreur "keyword too long".
            (
                reference_image_data_for_global_alignment,
                reference_header_for_global_alignment,
            ) = self.aligner._get_reference_image(
                folder_for_ref_scan, files_for_ref_scan, self.output_folder
            )
            if (
                reference_image_data_for_global_alignment is None
                or reference_header_for_global_alignment is None
            ):
                raise RuntimeError(
                    "√âchec critique obtention image/header de r√©f√©rence de base (globale/premier panneau)."
                )

            # Pr√©paration du header qui sera utilis√© pour le WCS de r√©f√©rence global
            self.reference_header_for_wcs = reference_header_for_global_alignment.copy()
            self.ref_wcs_header = self.reference_header_for_wcs

            # La cl√© '_SOURCE_PATH' dans reference_header_for_global_alignment vient de
            # la logique interne de _get_reference_image. Si cette cl√© contient un chemin complet,
            # nous devons extraire le nom de base pour nos propres besoins.
            # Le fichier reference_image.fit lui-m√™me (s'il contient _SOURCE_PATH) doit avoir √©t√© sauvegard√©
            # par _get_reference_image en utilisant d√©j√† un nom de base pour ce mot-cl√©.
            original_source_path_from_ref_fits = (
                reference_header_for_global_alignment.get("_SOURCE_PATH")
            )

            if original_source_path_from_ref_fits:
                source_basename_for_wcs_ref = os.path.basename(
                    str(original_source_path_from_ref_fits)
                )
                # Utiliser une cl√© claire pour indiquer que c'est le nom de base du fichier de r√©f√©rence
                self.reference_header_for_wcs["REF_FNAME"] = (
                    source_basename_for_wcs_ref,
                    "Basename of the source file for global WCS reference",
                )

                # Pour la logique de mosa√Øque locale, path_of_processed_ref_panel_basename
                # doit aussi √™tre juste le nom de base.
                if use_local_aligner_for_this_mosaic_run:
                    path_of_processed_ref_panel_basename = source_basename_for_wcs_ref
                    logger.debug(
                        f"DEBUG QM [_worker]: Panneau d'ancre identifi√© par basename: {path_of_processed_ref_panel_basename}"
                    )
            else:
                # Si _SOURCE_PATH n'est pas dans le header de reference_image.fit, on ne peut pas le d√©finir
                # Cela pourrait arriver si _get_reference_image ne l'ajoute pas.
                logger.debug(
                    "WARN QM [_worker]: Mot-cl√© '_SOURCE_PATH' non trouv√© dans le header de l'image de r√©f√©rence globale."
                )
                if use_local_aligner_for_this_mosaic_run:
                    path_of_processed_ref_panel_basename = (
                        "unknown_reference_panel.fits"  # Fallback
                    )

            ref_temp_processing_dir = os.path.join(
                self.output_folder, "temp_processing"
            )
            reference_image_path_for_solver = os.path.join(
                ref_temp_processing_dir, "reference_image.fit"
            )

            # √Ä ce stade, reference_image.fit doit exister, sinon l'erreur que tu as eue se produira.
            if not os.path.exists(reference_image_path_for_solver):
                # Cette erreur devrait √™tre pr√©venue si _get_reference_image fonctionne correctement
                # ET si la correction pour _SOURCE_PATH trop long est appliqu√©e DANS _get_reference_image.
                raise RuntimeError(
                    f"CRITICAL: Fichier de r√©f√©rence '{reference_image_path_for_solver}' non trouv√© apr√®s appel √† _get_reference_image. V√©rifier la logique de sauvegarde dans SeestarAligner._get_reference_image pour les headers longs."
                )

            logger.debug(
                f"DEBUG QM [_worker]: Image de r√©f√©rence de base (pour shape et solving) pr√™te: {reference_image_path_for_solver}"
            )

            # --- 1.A Plate-solving de la r√©f√©rence ---
            if (
                self.drizzle_active_session
                or self.is_mosaic_run
                or self.reproject_between_batches
            ):
                self.update_progress(
                    "DEBUG WORKER: Section 1.A - Plate-solving de la r√©f√©rence..."
                )
            else:
                logger.debug(
                    "DEBUG QM [_worker]: Plate-solving de la r√©f√©rence ignor√© (mode Stacking Classique sans reprojection)."
                )
            if not (
                self.reproject_between_batches and self.freeze_reference_wcs
            ):
                self.reference_wcs_object = None
            temp_wcs_ancre = None  # Sp√©cifique pour la logique mosa√Øque locale

            logger.debug(f"!!!! DEBUG _WORKER AVANT CR√âATION DICT SOLVEUR ANCRE !!!!")
            logger.debug(f"    self.is_mosaic_run = {self.is_mosaic_run}")
            logger.debug(
                f"    self.local_solver_preference = '{getattr(self, 'local_solver_preference', 'NON_D√âFINI')}'"
            )
            logger.debug(
                f"    self.astap_search_radius = {getattr(self, 'astap_search_radius', 'NON_D√âFINI')}"
            )
            logger.debug(
                f"    self.reference_pixel_scale_arcsec = {self.reference_pixel_scale_arcsec}"
            )

            solver_settings_for_ref_anchor = {
                "local_solver_preference": self.local_solver_preference,
                "api_key": self.api_key,
                "astap_path": self.astap_path,
                "astap_data_dir": self.astap_data_dir,
                "astap_search_radius": self.astap_search_radius,
                "astap_downsample": self.astap_downsample,
                "astap_sensitivity": self.astap_sensitivity,
                "local_ansvr_path": self.local_ansvr_path,
                "scale_est_arcsec_per_pix": self.reference_pixel_scale_arcsec,  # Peut √™tre None au premier passage
                "scale_tolerance_percent": 20,
                "ansvr_timeout_sec": getattr(self, "ansvr_timeout_sec", 120),
                "astap_timeout_sec": getattr(self, "astap_timeout_sec", 120),
                "astrometry_net_timeout_sec": getattr(
                    self, "astrometry_net_timeout_sec", 300
                ),
            }
            # (Vos logs pour le contenu de solver_settings_for_ref_anchor peuvent rester ici)
            logger.debug(
                f"DEBUG QM (_worker): Contenu de solver_settings_for_ref_anchor:"
            )
            for key_s, val_s in solver_settings_for_ref_anchor.items():
                if key_s == "api_key":
                    logger.debug(
                        f"    '{key_s}': '{'Pr√©sente' if val_s else 'Absente'}'"
                    )
                else:
                    logger.debug(f"    '{key_s}': '{val_s}'")

            logger.debug(
                f"!!!! DEBUG _worker AVANT BLOC IF/ELIF POUR SOLVING ANCRE (SECTION 1.A) !!!! self.is_mosaic_run = {self.is_mosaic_run}"
            )

            # --- CAS 1: Mosa√Øque Locale (FastAligner avec ou sans fallback WCS) ---
            if (
                use_local_aligner_for_this_mosaic_run
            ):  # Flag d√©fini au tout d√©but de _worker
                self.update_progress(
                    "‚≠ê Mosa√Øque Locale: Traitement du panneau de r√©f√©rence (ancrage)..."
                )
                mosaic_ref_panel_image_data = reference_image_data_for_global_alignment
                mosaic_ref_panel_header = self.reference_header_for_wcs.copy()

                if reference_header_for_global_alignment.get("_SOURCE_PATH"):
                    # path_of_processed_ref_panel_basename est d√©j√† d√©fini plus haut
                    mosaic_ref_panel_header["_PANREF_FN"] = (
                        path_of_processed_ref_panel_basename,
                        "Base name of this mosaic ref panel source",
                    )

                if self.astrometry_solver and os.path.exists(
                    reference_image_path_for_solver
                ):
                    self.update_progress(
                        "   -> Mosa√Øque Locale: Tentative r√©solution astrom√©trique ancre via self.astrometry_solver.solve..."
                    )
                    temp_wcs_ancre = self.astrometry_solver.solve(
                        reference_image_path_for_solver,
                        mosaic_ref_panel_header,
                        settings=solver_settings_for_ref_anchor,
                        update_header_with_solution=True,
                    )
                    if temp_wcs_ancre:
                        self.update_progress(
                            "   -> Mosa√Øque Locale: Astrometry (via solveur) ancre R√âUSSI."
                        )
                    else:
                        self.update_progress(
                            "   -> Mosa√Øque Locale: Astrometry (via solveur) ancre √âCHOU√â."
                        )
                else:
                    self.update_progress(
                        "   -> Mosa√Øque Locale: AstrometrySolver non dispo ou fichier r√©f. manquant. Solving ancre impossible.",
                        "ERROR",
                    )

                if temp_wcs_ancre is None:
                    self.update_progress(
                        "   ‚ö†Ô∏è √âchec de tous les solveurs pour panneau de r√©f√©rence. Tentative WCS approximatif (fallback)..."
                    )
                    _cwfh_func = None
                    from ..enhancement.drizzle_integration import (
                        _create_wcs_from_header as _cwfh,
                    )

                    _cwfh_func = _cwfh
                    if _cwfh_func:
                        temp_wcs_ancre = _cwfh_func(mosaic_ref_panel_header)
                    if temp_wcs_ancre and temp_wcs_ancre.is_celestial:
                        nx_hdr_a = mosaic_ref_panel_header.get("NAXIS1")
                        ny_hdr_a = mosaic_ref_panel_header.get("NAXIS2")
                        if nx_hdr_a and ny_hdr_a:
                            temp_wcs_ancre.pixel_shape = (int(nx_hdr_a), int(ny_hdr_a))
                        elif hasattr(mosaic_ref_panel_image_data, "shape"):
                            temp_wcs_ancre.pixel_shape = (
                                mosaic_ref_panel_image_data.shape[1],
                                mosaic_ref_panel_image_data.shape[0],
                            )

                if temp_wcs_ancre is None:
                    raise RuntimeError(
                        "Mosa√Øque Locale: √âchec critique obtention WCS pour panneau de r√©f√©rence."
                    )
                self.reference_wcs_object = temp_wcs_ancre

                if self.reference_wcs_object and hasattr(
                    self.reference_wcs_object, "pixel_scale_matrix"
                ):  # Mettre √† jour l'√©chelle globale
                    try:
                        self.reference_pixel_scale_arcsec = (
                            np.sqrt(
                                np.abs(
                                    np.linalg.det(
                                        self.reference_wcs_object.pixel_scale_matrix
                                    )
                                )
                            )
                            * 3600.0
                        )
                    except:
                        pass  # Ignorer si erreur de calcul

                if self.reference_wcs_object:
                    logger.debug(
                        f"  DEBUG QM [_worker]: Infos WCS du Panneau d'Ancrage (self.reference_wcs_object): CRVAL={self.reference_wcs_object.wcs.crval if self.reference_wcs_object.wcs else 'N/A'} ..."
                    )

                mat_identite_ref_panel = np.array(
                    [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]], dtype=np.float32
                )
                valid_mask_ref_panel_pixels = np.ones(
                    mosaic_ref_panel_image_data.shape[:2], dtype=bool
                )
                all_aligned_files_with_info_for_mosaic.append(
                    (
                        mosaic_ref_panel_image_data.copy(),
                        mosaic_ref_panel_header.copy(),
                        self.reference_wcs_object,
                        mat_identite_ref_panel,
                        valid_mask_ref_panel_pixels,
                    )
                )
                self.aligned_files_count += 1
                self.processed_files_count += 1
                logger.debug(
                    f"DEBUG QM [_worker]: Mosa√Øque Locale: Panneau de r√©f√©rence ajout√© √† all_aligned_files_with_info_for_mosaic."
                )

            # --- CAS 2: Mosa√Øque Astrometry.net par panneau, Drizzle Standard ou Reprojection entre lots ---
            elif (
                self.drizzle_active_session
                or use_astrometry_per_panel_mosaic
                or self.reproject_between_batches
            ):  # `use_astrometry_per_panel_mosaic` est True si mode mosaique="astrometry_per_panel"
                self.update_progress(
                    "DEBUG WORKER: Branche Drizzle Std / AstroMosaic / ReprojectBatches pour r√©f√©rence globale..."
                )

                if (
                    self.reproject_between_batches
                    and not self.freeze_reference_wcs
                    and not self.drizzle_active_session
                    and not self.is_mosaic_run
                ):
                    self.update_progress(
                        "   -> Reproject entre lots actif: r√©solution de la r√©f√©rence report√©e au premier stack",
                        "INFO_DETAIL",
                    )
                    self.reference_wcs_object = None
                elif self.astrometry_solver and os.path.exists(
                    reference_image_path_for_solver
                ):
                    self.update_progress(
                        "   -> Drizzle Std/AstroMosaic: Tentative r√©solution astrom√©trique r√©f. globale via self.astrometry_solver.solve..."
                    )
                    self.reference_wcs_object = self.astrometry_solver.solve(
                        reference_image_path_for_solver,
                        self.reference_header_for_wcs,
                        settings=solver_settings_for_ref_anchor,  # Utilise le m√™me dict de settings que pour l'ancre
                        update_header_with_solution=True,
                    )
                else:
                    self.update_progress(
                        "   -> Drizzle Std/AstroMosaic: AstrometrySolver non dispo ou fichier r√©f. manquant. Solving r√©f. globale impossible.",
                        "ERROR",
                    )
                    self.reference_wcs_object = None

                if self.reference_wcs_object is None:  # Si solving a √©chou√©
                    self.update_progress(
                        "ERREUR WORKER: √âchec plate-solving r√©f. principale (Drizzle Std / AstroMosaic). Tentative WCS approximatif...",
                        "WARN",
                    )
                    # Fallback WCS approximatif pour Drizzle Standard / Mosa√Øque Astrometry.net per Panel
                    _cwfh_func_std_driz = None
                    from ..enhancement.drizzle_integration import (
                        _create_wcs_from_header as _cwfh_std,
                    )

                    _cwfh_func_std_driz = _cwfh_std
                    if _cwfh_func_std_driz:
                        self.reference_wcs_object = _cwfh_func_std_driz(
                            self.reference_header_for_wcs
                        )
                    if not (
                        self.reference_wcs_object
                        and self.reference_wcs_object.is_celestial
                    ):
                        raise RuntimeError(
                            "√âchec critique obtention WCS pour Drizzle standard ou Mosa√Øque Astrometry (m√™me apr√®s fallback)."
                        )
                    self.update_progress(
                        "   -> WCS approximatif pour r√©f. globale cr√©√© (pour Drizzle Std / AstroMosaic).",
                        "INFO",
                    )

                # Si on a un WCS (r√©solu ou approximatif)
                self.update_progress(
                    "   -> Drizzle Std/AstroMosaic: WCS pour r√©f. globale obtenu (r√©solu ou approx)."
                )
                if self.reference_wcs_object.pixel_shape is None:
                    nx_ref_hdr = self.reference_header_for_wcs.get(
                        "NAXIS1", reference_image_data_for_global_alignment.shape[1]
                    )
                    ny_ref_hdr = self.reference_header_for_wcs.get(
                        "NAXIS2", reference_image_data_for_global_alignment.shape[0]
                    )
                    self.reference_wcs_object.pixel_shape = (
                        int(nx_ref_hdr),
                        int(ny_ref_hdr),
                    )

                if hasattr(
                    self.reference_wcs_object, "pixel_scale_matrix"
                ):  # Mettre √† jour l'√©chelle globale
                    try:
                        self.reference_pixel_scale_arcsec = (
                            np.sqrt(
                                np.abs(
                                    np.linalg.det(
                                        self.reference_wcs_object.pixel_scale_matrix
                                    )
                                )
                            )
                            * 3600.0
                        )
                    except:
                        pass

                logger.debug(
                    f"  DEBUG QM [_worker]: Infos WCS de R√©f√©rence Globale: CRVAL={self.reference_wcs_object.wcs.crval if self.reference_wcs_object.wcs else 'N/A'} ..."
                )

            logger.debug(
                f"!!!! DEBUG _worker APR√àS BLOC IF/ELIF POUR SOLVING ANCRE (SECTION 1.A) !!!! self.is_mosaic_run = {self.is_mosaic_run}"
            )

            # --- Initialisation grille Drizzle Standard (si applicable pour un run NON-mosa√Øque) ---
            if self.drizzle_active_session and not self.is_mosaic_run:
                self.update_progress(
                    "DEBUG WORKER: Initialisation grille de sortie pour Drizzle Standard...",
                    "DEBUG_DETAIL",
                )
                if self.reference_wcs_object and hasattr(
                    reference_image_data_for_global_alignment, "shape"
                ):
                    ref_shape_for_drizzle_grid_hw = (
                        reference_image_data_for_global_alignment.shape[:2]
                    )
                    try:
                        if (
                            self.drizzle_output_wcs is None
                            or self.drizzle_output_shape_hw is None
                        ):
                            self.drizzle_output_wcs, self.drizzle_output_shape_hw = (
                                self._create_drizzle_output_wcs(
                                    self.reference_wcs_object,
                                    ref_shape_for_drizzle_grid_hw,
                                    self.drizzle_scale,
                                )
                            )
                            if (
                                self.drizzle_output_wcs is None
                                or self.drizzle_output_shape_hw is None
                            ):
                                raise RuntimeError(
                                    "√âchec de _create_drizzle_output_wcs (retourne None) pour Drizzle Standard."
                                )
                        logger.debug(
                            f"DEBUG QM [_worker]: Grille de sortie Drizzle Standard initialis√©e: Shape={self.drizzle_output_shape_hw}"
                        )
                        self.update_progress(
                            f"   Grille Drizzle Standard pr√™te: {self.drizzle_output_shape_hw}",
                            "INFO",
                        )
                    except Exception as e_grid_driz:
                        error_msg_grid = f"√âchec critique cr√©ation grille de sortie Drizzle Standard: {e_grid_driz}"
                        self.update_progress(error_msg_grid, "ERROR")
                        raise RuntimeError(error_msg_grid)
                else:
                    error_msg_ref_driz = "R√©f√©rence WCS ou shape de l'image de r√©f√©rence globale manquante pour initialiser la grille Drizzle Standard."
                    self.update_progress(error_msg_ref_driz, "ERROR")
                    raise RuntimeError(error_msg_ref_driz)

            logger.debug(
                f"!!!! DEBUG _worker POST SECTION 1 (apr√®s init grille Drizzle si applicable) !!!! self.is_mosaic_run = {self.is_mosaic_run}"
            )

            self.update_progress(
                "DEBUG WORKER: Fin Section 1 (Pr√©paration R√©f√©rence)."
            )  # Message plus g√©n√©ral
            self.update_progress("‚≠ê R√©f√©rence(s) pr√™te(s).", 5)
            self._recalculate_total_batches()

            self.update_progress(
                f"‚ñ∂Ô∏è D√©marrage boucle principale (En file: {self.files_in_queue} | Lots Estim√©s: {self.total_batches_estimated if self.total_batches_estimated > 0 else '?'})..."
            )

            # ============================================================
            # === SECTION 2 : BOUCLE PRINCIPALE DE TRAITEMENT DES IMAGES ===
            # ============================================================
            iteration_count = 0
            # self.update_progress("DEBUG WORKER: ENTR√âE IMMINENTE DANS LA BOUCLE while not self.stop_processing...") # Peut √™tre un peu verbeux

            while not self.stop_processing:
                iteration_count += 1

                logger.debug(
                    f"!!!! DEBUG _worker LOOP START iter {iteration_count}: self.is_mosaic_run = {self.is_mosaic_run}, "
                    f"self.mosaic_alignment_mode = '{self.mosaic_alignment_mode}', "
                    f"self.drizzle_active_session = {self.drizzle_active_session}, "
                    f"self.drizzle_mode = '{self.drizzle_mode}'"
                )

                # Log existant (bon √† garder)
                logger.debug(
                    f"DEBUG QM [_worker V_LoopFocus - Loop Iter]: D√âBUT It√©ration #{iteration_count}. "
                    f"Queue approx: {self.queue.qsize()}. "
                    f"Mosaic list AVANT GET: {len(all_aligned_files_with_info_for_mosaic)}"
                )

                file_path = None
                file_name_for_log = "FichierInconnu"

                try:
                    file_path = self.queue.get(timeout=1.0)
                    file_name_for_log = os.path.basename(file_path)
                    logger.debug(
                        f"DEBUG QM [_worker V_LoopFocus / Boucle Principale]: Traitement fichier '{file_name_for_log}' depuis la queue."
                    )

                    if (
                        path_of_processed_ref_panel_basename
                        and file_name_for_log == path_of_processed_ref_panel_basename
                    ):
                        self.update_progress(
                            f"   [WorkerLoop] Panneau d'ancre '{file_name_for_log}' d√©j√† trait√©. Ignor√© dans la boucle principale."
                        )
                        logger.debug(
                            f"DEBUG QM [_worker V_LoopFocus]: Panneau d'ancre '{file_name_for_log}' skipp√© car d√©j√† trait√© (path_of_processed_ref_panel_basename='{path_of_processed_ref_panel_basename}')."
                        )
                        self.processed_files_count += 1
                        self.queue.task_done()
                        continue

                    item_result_tuple = None

                    logger.debug(
                        f"  DEBUG _worker (iter {iteration_count}): PRE-CALL _process_file pour '{file_name_for_log}'"
                    )
                    logger.debug(
                        f"    - use_local_aligner_for_this_mosaic_run: {use_local_aligner_for_this_mosaic_run}"
                    )
                    logger.debug(
                        f"    - use_astrometry_per_panel_mosaic: {use_astrometry_per_panel_mosaic}"
                    )
                    logger.debug(
                        f"    - self.is_mosaic_run (juste avant if/elif): {self.is_mosaic_run}"
                    )

                    if use_local_aligner_for_this_mosaic_run:
                        logger.debug(
                            f"  DEBUG _worker (iter {iteration_count}): Entr√©e branche 'use_local_aligner_for_this_mosaic_run' pour _process_file."
                        )  # DEBUG
                        item_result_tuple = self._process_file(
                            file_path,
                            reference_image_data_for_global_alignment,
                            solve_astrometry_for_this_file=False,
                            fa_orb_features_config=self.fa_orb_features,
                            fa_min_abs_matches_config=self.fa_min_abs_matches,
                            fa_min_ransac_inliers_value_config=self.fa_min_ransac_raw,
                            fa_ransac_thresh_config=self.fa_ransac_thresh,
                            daofind_fwhm_config=self.fa_daofind_fwhm,
                            daofind_threshold_sigma_config=self.fa_daofind_thr_sig,
                            max_stars_to_describe_config=self.fa_max_stars_descr,
                        )

                        self.processed_files_count += (
                            1  # Mis ici car _process_file est appel√©
                        )
                        if (
                            item_result_tuple
                            and isinstance(item_result_tuple, tuple)
                            and len(item_result_tuple) == 6
                            and item_result_tuple[0] is not None
                            and item_result_tuple[3] is not None
                            and isinstance(item_result_tuple[3], WCS)
                            and item_result_tuple[4] is not None
                        ):

                            (
                                panel_data,
                                panel_header,
                                _scores,
                                panel_wcs,
                                panel_matrix_m,
                                panel_mask,
                            ) = item_result_tuple
                            all_aligned_files_with_info_for_mosaic.append(
                                (
                                    panel_data,
                                    panel_header,
                                    panel_wcs,
                                    panel_matrix_m,
                                    panel_mask,
                                )
                            )
                            self.aligned_files_count += 1
                            align_method_used_log = panel_header.get(
                                "_ALIGN_METHOD_LOG", ("Unknown", None)
                            )[0]
                            logger.debug(
                                f"  DEBUG QM [_worker / Mosa√Øque Locale]: Panneau '{file_name_for_log}' trait√© ({align_method_used_log}) et ajout√© √† all_aligned_files_with_info_for_mosaic."
                            )
                        else:
                            self.failed_align_count += 1
                            logger.debug(
                                f"  DEBUG QM [_worker / Mosa√Øque Locale]: √âchec traitement/alignement panneau '{file_name_for_log}'. _process_file a retourn√©: {item_result_tuple}"
                            )
                            if hasattr(self, "_move_to_unaligned"):
                                self._move_to_unaligned(file_path)

                    elif use_astrometry_per_panel_mosaic:
                        logger.debug(
                            f"  DEBUG _worker (iter {iteration_count}): Entr√©e branche 'use_astrometry_per_panel_mosaic' pour _process_file."
                        )  # DEBUG
                        item_result_tuple = self._process_file(
                            file_path,
                            reference_image_data_for_global_alignment,  # Pass√© mais pas utilis√© pour l'alignement direct dans ce mode
                            solve_astrometry_for_this_file=(
                                False if self.reproject_between_batches else True
                            ),
                        )
                        self.processed_files_count += 1
                        if (
                            item_result_tuple
                            and isinstance(item_result_tuple, tuple)
                            and len(item_result_tuple) == 6
                            and item_result_tuple[0] is not None
                            and item_result_tuple[3] is not None
                            and isinstance(item_result_tuple[3], WCS)
                        ):

                            (
                                panel_data,
                                panel_header,
                                _scores,
                                wcs_object_panel,
                                M_returned,
                                valid_mask_panel,
                            ) = item_result_tuple
                            M_to_store = (
                                M_returned
                                if M_returned is not None
                                else np.array(
                                    [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]], dtype=np.float32
                                )
                            )
                            all_aligned_files_with_info_for_mosaic.append(
                                (
                                    panel_data,
                                    panel_header,
                                    wcs_object_panel,
                                    M_to_store,
                                    valid_mask_panel,
                                )
                            )
                            self.aligned_files_count += 1
                            align_method_used_log = panel_header.get(
                                "_ALIGN_METHOD_LOG", ("Unknown", None)
                            )[0]
                            logger.debug(
                                f"  DEBUG QM [_worker / Mosa√Øque AstroPanel]: Panneau '{file_name_for_log}' trait√© ({align_method_used_log}) et ajout√© √† all_aligned_files_with_info_for_mosaic."
                            )
                        else:
                            self.failed_align_count += 1
                            logger.debug(
                                f"  DEBUG QM [_worker / Mosa√Øque AstroPanel]: √âchec traitement/alignement panneau '{file_name_for_log}'. _process_file a retourn√©: {item_result_tuple}"
                            )
                            if hasattr(self, "_move_to_unaligned"):
                                self._move_to_unaligned(file_path)

                    else:  # Stacking Classique ou Drizzle Standard (non-mosa√Øque)
                        logger.debug(
                            f"  DEBUG _worker (iter {iteration_count}): Entr√©e branche 'Stacking Classique/Drizzle Standard' pour _process_file."
                        )
                        solve_astrometry = False
                        if (
                            self.reproject_between_batches
                            and self.drizzle_active_session
                            and not current_batch_items_with_masks_for_stack_batch
                        ):
                            solve_astrometry = True

                        item_result_tuple = self._process_file(
                            file_path,
                            reference_image_data_for_global_alignment,
                            solve_astrometry_for_this_file=solve_astrometry,
                        )
                        self.processed_files_count += 1
                        if (
                            item_result_tuple
                            and isinstance(item_result_tuple, tuple)
                            and len(item_result_tuple) == 6
                            and item_result_tuple[0] is not None
                        ):

                            if self.reproject_between_batches:
                                # --- NEW incremental reprojection on *stacked* batches ---
                                # store only the components expected by
                                # ``_stack_batch`` (data, header, scores,
                                # wcs_object, valid_mask)
                                # _stack_batch expects (data, header, scores, wcs, valid_mask)
                                # item_result_tuple structure is
                                # (data, header, scores, wcs, matrix_M, valid_mask)
                                current_batch_items_with_masks_for_stack_batch.append(
                                    (
                                        item_result_tuple[0],
                                        item_result_tuple[1],
                                        item_result_tuple[2],
                                        item_result_tuple[3],
                                        item_result_tuple[5],
                                    )
                                )
                                self._current_batch_paths.append(file_path)

                                if (
                                    len(current_batch_items_with_masks_for_stack_batch)
                                    >= self.batch_size
                                ):
                                    self.stacked_batches_count += 1
                                    num_in_batch = len(
                                        current_batch_items_with_masks_for_stack_batch
                                    )

                                    # 1. Stack the batch (classic SUM/W)
                                    stacked_np, hdr, wht_2d = self._stack_batch(
                                        current_batch_items_with_masks_for_stack_batch,
                                        self.stacked_batches_count,
                                        self.total_batches_estimated,
                                    )
                                    if stacked_np is None:
                                        current_batch_items_with_masks_for_stack_batch.clear()
                                        gc.collect()
                                    else:
                                        # 2. Ensure WCS on the stacked image
                                        solved_path, _ = (
                                            self._save_and_solve_classic_batch(
                                                stacked_np,
                                                wht_2d,
                                                hdr,
                                                self.stacked_batches_count,
                                            )
                                        )
                                        batch_wcs = None
                                        try:
                                            batch_wcs = WCS(hdr, naxis=2)
                                        except Exception:
                                            batch_wcs = None

                                        # 3. Accumulate (reprojection now happens inside _combine_batch_result)
                                        self._combine_batch_result(
                                            stacked_np,
                                            hdr,
                                            wht_2d,
                                            batch_wcs=batch_wcs,
                                        )
                                        if hasattr(self.cumulative_sum_memmap, "flush"):
                                            self.cumulative_sum_memmap.flush()
                                        if hasattr(self.cumulative_wht_memmap, "flush"):
                                            self.cumulative_wht_memmap.flush()
                                        if not self.drizzle_active_session:
                                            self._update_preview_sum_w()

                                        # After accumulation, solve the cumulative stack
                                        if self.reproject_between_batches:
                                            stack_img, solved_hdr = (
                                                self._solve_cumulative_stack()
                                            )
                                            if (
                                                stack_img is not None
                                                and solved_hdr is not None
                                            ):
                                                reference_image_data_for_global_alignment = (
                                                    stack_img
                                                )
                                                reference_header_for_global_alignment = (
                                                    solved_hdr.copy()
                                                )
                                            else:
                                                reference_image_data_for_global_alignment = stacked_np.astype(
                                                    np.float32, copy=True
                                                )
                                                reference_header_for_global_alignment = (
                                                    hdr.copy()
                                                )
                                        else:
                                            reference_image_data_for_global_alignment = stacked_np.astype(
                                                np.float32, copy=True
                                            )
                                            reference_header_for_global_alignment = (
                                                hdr.copy()
                                            )

                                        current_batch_items_with_masks_for_stack_batch.clear()
                                        self._current_batch_paths = []
                                        self._save_partial_stack()
                                        gc.collect()

                            else:
                                # --- MODE CLASSIQUE OU DRIZZLE ---
                                self.aligned_files_count += 1
                                (
                                    aligned_data,
                                    header_orig,
                                    scores_val,
                                    wcs_gen_val,
                                    matrix_M_val,
                                    valid_mask_val,
                                ) = item_result_tuple

                                if (
                                    self.drizzle_active_session
                                ):  # Drizzle Standard (non-mosa√Øque)
                                    logger.debug(
                                        f"    DEBUG _worker (iter {iteration_count}): Mode Drizzle Standard actif pour '{file_name_for_log}'."
                                    )
                                    temp_driz_file_path = self._save_drizzle_input_temp(
                                        aligned_data, header_orig
                                    )
                                    if temp_driz_file_path:
                                        current_batch_items_with_masks_for_stack_batch.append(
                                            temp_driz_file_path
                                        )
                                        self._current_batch_paths.append(file_path)
                                    else:
                                        self.failed_stack_count += 1
                                        logger.debug(
                                            f"    DEBUG _worker (iter {iteration_count}): √âchec _save_drizzle_input_temp pour '{file_name_for_log}'."
                                        )
                                else:  # Stacking Classique (SUM/W)
                                    logger.debug(
                                        f"    DEBUG _worker (iter {iteration_count}): Mode Stacking Classique pour '{file_name_for_log}'."
                                    )
                                    classic_stack_item = (
                                        aligned_data,
                                        header_orig,
                                        scores_val,
                                        wcs_gen_val,
                                        valid_mask_val,
                                    )
                                    current_batch_items_with_masks_for_stack_batch.append(
                                        classic_stack_item
                                    )
                                    self._current_batch_paths.append(file_path)

                                if (
                                    len(current_batch_items_with_masks_for_stack_batch)
                                    >= self.batch_size
                                ):
                                    self.stacked_batches_count += 1
                                    self._send_eta_update()
                                    if self.drizzle_active_session:
                                        if self.drizzle_mode == "Incremental":
                                            self._process_incremental_drizzle_batch(
                                                current_batch_items_with_masks_for_stack_batch,
                                                self.stacked_batches_count,
                                                self.total_batches_estimated,
                                            )
                                        elif self.drizzle_mode == "Final":
                                            batch_sci_p, batch_wht_p_list = (
                                                self._process_and_save_drizzle_batch(
                                                    current_batch_items_with_masks_for_stack_batch,
                                                    self.drizzle_output_wcs,
                                                    self.drizzle_output_shape_hw,
                                                    self.stacked_batches_count,
                                                )
                                            )
                                            if batch_sci_p and batch_wht_p_list:
                                                self.intermediate_drizzle_batch_files.append(
                                                    (batch_sci_p, batch_wht_p_list)
                                                )
                                            else:
                                                self.failed_stack_count += len(
                                                    current_batch_items_with_masks_for_stack_batch
                                                )
                                    else:  # Stacking Classique SUM/W
                                        self._process_completed_batch(
                                            current_batch_items_with_masks_for_stack_batch,
                                            self.stacked_batches_count,
                                            self.total_batches_estimated,
                                            self.reference_wcs_object,
                                        )

                                    self._move_to_stacked(self._current_batch_paths)
                                    self._save_partial_stack()
                                    self._update_batch_count_file()
                                    self._current_batch_paths = []

                                    current_batch_items_with_masks_for_stack_batch = []

                        else:  # _process_file a √©chou√©
                            self.failed_align_count += 1
                            logger.debug(
                                f"  DEBUG QM [_worker / Classique-DrizStd]: √âchec _process_file pour '{file_name_for_log}'. Retour: {item_result_tuple}"
                            )
                            if hasattr(self, "_move_to_unaligned"):
                                self._move_to_unaligned(file_path)

                    self.queue.task_done()
                except Empty:
                    # --- NOUVELLE LOGIQUE POUR G√âRER LES DOSSIERS ADDITIONNELS (D√âBUT) ---
                    logger.debug(
                        f"DEBUG QM [_worker / EmptyExcept]: Queue vide. V√©rification des dossiers additionnels."
                    )
                    new_files_added_from_additional_folder = 0
                    folder_to_process_from_additional = None

                    # Prot√©ger l'acc√®s √† self.additional_folders avec le Lock
                    with self.folders_lock:
                        if (
                            self.additional_folders
                        ):  # Si des dossiers additionnels sont en attente
                            folder_to_process_from_additional = (
                                self.additional_folders.pop(0)
                            )  # Prendre le premier et le retirer
                            logger.debug(
                                f"DEBUG QM [_worker / EmptyExcept]: Dossier additionnel trouv√© et retir√©: '{os.path.basename(folder_to_process_from_additional)}'."
                            )
                            # Mettre √† jour le statut dans l'UI imm√©diatement (m√™me si pas de fichiers √† l'int√©rieur)
                            self.update_progress(
                                f"üîç Scan du dossier additionnel: {os.path.basename(folder_to_process_from_additional)}...",
                                None,
                            )
                        else:
                            logger.debug(
                                f"DEBUG QM [_worker / EmptyExcept]: self.additional_folders est vide (pas de dossiers additionnels en attente)."
                            )

                    if folder_to_process_from_additional:
                        # Mettre √† jour self.current_folder pour que les logs d'erreurs √©ventuelles soient pertinents
                        self.current_folder = folder_to_process_from_additional
                        new_files_added_from_additional_folder = (
                            self._add_files_to_queue(folder_to_process_from_additional)
                        )
                        logger.debug(
                            f"DEBUG QM [_worker / EmptyExcept]: {new_files_added_from_additional_folder} nouveaux fichiers ajout√©s de '{os.path.basename(folder_to_process_from_additional)}'."
                        )

                        # Notifier le GUI que le nombre de dossiers additionnels a diminu√©
                        # (La mise √† jour de l'affichage du nombre de dossiers dans l'UI via le callback)
                        self.update_progress(
                            f"folder_count_update:{len(self.additional_folders)}"
                        )

                        if new_files_added_from_additional_folder > 0:
                            # Si de nouveaux fichiers ont √©t√© ajout√©s, on continue la boucle
                            # et la queue sera trait√©e √† la prochaine it√©ration.
                            logger.debug(
                                f"DEBUG QM [_worker / EmptyExcept]: Nouveaux fichiers d√©tect√©s, continuer la boucle."
                            )
                            continue  # <-- CRUCIAL: Retourne au d√©but de la boucle while pour traiter les nouveaux fichiers
                        else:
                            # Si le dossier additionnel √©tait vide de FITS, on log l'info.
                            self.update_progress(
                                f"   ‚ÑπÔ∏è Dossier '{os.path.basename(folder_to_process_from_additional)}' ne contient aucun fichier FITS √† traiter. Passons au suivant ou finalisons."
                            )
                            logger.debug(
                                f"DEBUG QM [_worker / EmptyExcept]: Dossier additionnel vide, pas de nouveaux fichiers √† traiter."
                            )
                            # Si le dossier additionnel ne contenait pas de fichiers FITS, la queue reste vide.
                            # On laisse la logique de fin de traitement prendre le relais √† la prochaine it√©ration.
                            # Pas de 'continue' ici, pour permettre l'√©valuation de la condition finale de sortie.
                            pass

                    # Si aucun dossier additionnel n'a √©t√© trouv√© OU si le dossier trouv√© √©tait vide de FITS
                    # (et qu'on est arriv√© ici sans 'continue' pr√©c√©dent)
                    if not self.additional_folders and self.queue.empty():
                        self.update_progress(
                            "INFO: Plus aucun fichier ni dossier suppl√©mentaire. Fin de la boucle de traitement.",
                            None,
                        )
                        logger.debug(
                            f"DEBUG QM [_worker / EmptyExcept]: Condition de sortie (self.additional_folders et queue vides) remplie. BREAK."
                        )
                        break  # <-- CRUCIAL: Sortie normale de la boucle while
                    else:
                        # Si self.additional_folders n'est PAS vide (m√™me apr√®s le pop d'un √©l√©ment, d'autres ont pu √™tre ajout√©s √† la vol√©e),
                        # ou si la queue n'est pas vide (si _add_files_to_queue a r√©ussi),
                        # alors on devrait continuer. Si on est ici, la queue est vide.
                        # Cela signifie que self.additional_folders doit avoir des √©l√©ments pour que la boucle continue.
                        # Sinon, c'est une boucle infinie si on arrive ici sans `break` ou `continue` et que la queue est vide.
                        # Un `time.sleep` est alors n√©cessaire pour √©viter le CPU √† 100%.
                        self.update_progress(
                            "INFO: File d'attente vide, en attente de nouveaux ...",
                            None,
                        )
                        logger.debug(
                            f"DEBUG QM [_worker / EmptyExcept]: Queue vide. self.additional_folders n'est PAS vide (il reste des dossiers √† traiter), OU un 'continue' a √©t√© manqu√©. Sleep et rev√©rification..."
                        )
                        time.sleep(
                            0.5
                        )  # Attendre un peu avant de refaire un `get` (pour √©viter boucle serr√©e)
                        continue  # <-- CRUCIAL: Retourne au d√©but de la boucle `while` pour re-tenter de prendre un item ou un autre dossier additionnel
                    # --- NOUVELLE LOGIQUE POUR G√âRER LES DOSSIERS ADDITIONNELS (FIN) ---

            # ==============================================================
            # === SECTION 3 : TRAITEMENT FINAL APR√àS LA BOUCLE PRINCIPALE ===
            # ==============================================================
            logger.debug(
                f"DEBUG QM [_worker V_DrizIncrTrue_Fix1 / FIN DE BOUCLE WHILE]:"
            )  # Version Log
            logger.debug(f"  >> self.stop_processing est: {self.stop_processing}")
            logger.debug(
                f"  >> Taille de all_aligned_files_with_info_for_mosaic IMM√âDIATEMENT APR√àS LA BOUCLE WHILE: {len(all_aligned_files_with_info_for_mosaic)}"
            )
            if all_aligned_files_with_info_for_mosaic:
                logger.debug(
                    f"  >> Premier item (pour v√©rif type): {type(all_aligned_files_with_info_for_mosaic[0])}, len: {len(all_aligned_files_with_info_for_mosaic[0]) if isinstance(all_aligned_files_with_info_for_mosaic[0], tuple) else 'N/A'}"
                )

            logger.debug(
                f"DEBUG QM [_worker V_DrizIncrTrue_Fix1]: Sortie de la boucle principale. D√©but de la phase de finalisation..."
            )
            logger.debug(f"  √âTAT FINAL AVANT BLOC if/elif/else de finalisation:")
            logger.debug(f"    - self.stop_processing: {self.stop_processing}")
            logger.debug(f"    - self.is_mosaic_run: {self.is_mosaic_run}")
            if self.is_mosaic_run:
                logger.debug(
                    f"      - Mode align.: '{self.mosaic_alignment_mode}', Nb items mosa√Øque: {len(all_aligned_files_with_info_for_mosaic)}"
                )
            logger.debug(
                f"    - self.drizzle_active_session (std): {self.drizzle_active_session}"
            )
            if self.drizzle_active_session and not self.is_mosaic_run:
                logger.debug(
                    f"      - Mode Drizzle (std): '{self.drizzle_mode}', Nb lots Drizzle interm.: {len(self.intermediate_drizzle_batch_files)}"
                )
            logger.debug(
                f"    - self.images_in_cumulative_stack (classique/DrizIncrVRAI): {self.images_in_cumulative_stack}"
            )
            logger.debug(
                f"    - current_batch_items_with_masks_for_stack_batch (non trait√© si dernier lot partiel): {len(current_batch_items_with_masks_for_stack_batch)}"
            )

            logger.debug(
                "DEBUG QM [_worker V_DrizIncrTrue_Fix1]: *** JUSTE AVANT LE PREMIER 'if self.stop_processing:' ***"
            )

            if self.stop_processing:
                logger.debug(
                    "DEBUG QM [_worker V_DrizIncrTrue_Fix1]: *** ENTR√âE DANS 'if self.stop_processing:' ***"
                )
                self.update_progress(
                    "‚õî Traitement interrompu par l'utilisateur ou erreur."
                )
                if self.processing_error:
                    self.update_progress(f"   Cause: {self.processing_error}")

                # Logique de sauvegarde partielle
                if (
                    self.drizzle_active_session
                    and self.drizzle_mode == "Incremental"
                    and hasattr(self, "incremental_drizzle_objects")
                    and self.incremental_drizzle_objects
                    and self.images_in_cumulative_stack > 0
                ):  # V√©rifier si Drizzle Incr. VRAI a des donn√©es
                    self.update_progress(
                        "   Sauvegarde du stack Drizzle Incr√©mental VRAI partiel..."
                    )
                    self._save_final_stack(
                        output_filename_suffix="_drizzle_incr_true_stopped",
                        stopped_early=True,
                    )
                elif (
                    not self.is_mosaic_run
                    and not self.drizzle_active_session
                    and hasattr(self, "cumulative_sum_memmap")
                    and self.cumulative_sum_memmap is not None
                    and self.images_in_cumulative_stack > 0
                ):  # Stacking Classique SUM/W
                    self.update_progress(
                        "   Sauvegarde du stack classique partiel (SUM/W)..."
                    )
                    self._save_final_stack(
                        output_filename_suffix="_classic_stopped", stopped_early=True
                    )
                else:
                    self.update_progress(
                        "   Aucun stack partiel significatif √† sauvegarder."
                    )

            # --- MODE MOSA√èQUE ---
            elif self.is_mosaic_run:
                logger.debug(
                    "DEBUG QM [_worker V_DrizIncrTrue_Fix1]: *** ENTR√âE DANS 'elif self.is_mosaic_run:' ***"
                )
                # ... (logique mosa√Øque inchang√©e, elle appelle _finalize_mosaic_processing qui appelle _save_final_stack
                #      en passant drizzle_final_sci_data, donc c'est g√©r√© par la branche correspondante dans _save_final_stack)
                self.update_progress("üèÅ Finalisation Mosa√Øque...")
                if not all_aligned_files_with_info_for_mosaic:
                    self.update_progress(
                        "   ‚ùå Mosa√Øque: Aucun panneau align√© pour l'assemblage.",
                        "ERROR",
                    )
                    self.processing_error = "Mosa√Øque: Aucun panneau align√©"
                    self.final_stacked_path = None
                else:
                    try:
                        self._finalize_mosaic_processing(
                            all_aligned_files_with_info_for_mosaic
                        )
                    except Exception as e_finalize_mosaic:
                        # ... (gestion erreur identique)
                        error_msg = f"Erreur CRITIQUE durant finalisation mosa√Øque: {e_finalize_mosaic}"
                        logger.debug(
                            f"ERREUR QM [_worker V_DrizIncrTrue_Fix1]: {error_msg}"
                        )
                        traceback.print_exc(limit=3)
                        self.update_progress(f"   ‚ùå {error_msg}", "ERROR")
                        self.processing_error = error_msg
                        self.final_stacked_path = None

            # --- MODE DRIZZLE STANDARD (NON-MOSA√èQUE) ---
            elif self.drizzle_active_session:
                logger.debug(
                    "DEBUG QM [_worker V_DrizIncrTrue_Fix1]: *** ENTR√âE DANS 'elif self.drizzle_active_session:' (NON-MOSA√èQUE) ***"
                )
                logger.debug(
                    f"DEBUG QM [_worker/Finalize DrizzleStd]: Mode Drizzle Standard: {self.drizzle_mode}"
                )

                if current_batch_items_with_masks_for_stack_batch:
                    self.stacked_batches_count += 1
                    self._send_eta_update()
                    num_in_partial_batch = len(
                        current_batch_items_with_masks_for_stack_batch
                    )
                    progress_info_partial_log = f"(Lot PARTIEL {self.stacked_batches_count}/{self.total_batches_estimated if self.total_batches_estimated > 0 else '?'})"

                    if self.drizzle_mode == "Final":
                        self.update_progress(
                            f"üíß Traitement Drizzle (mode Final) du dernier lot partiel {progress_info_partial_log}..."
                        )
                        batch_sci_path, batch_wht_paths = (
                            self._process_and_save_drizzle_batch(
                                current_batch_items_with_masks_for_stack_batch,  # Liste de CHEMINS
                                self.drizzle_output_wcs,
                                self.drizzle_output_shape_hw,
                                self.stacked_batches_count,
                            )
                        )
                        if batch_sci_path and batch_wht_paths:
                            self.intermediate_drizzle_batch_files.append(
                                (batch_sci_path, batch_wht_paths)
                            )
                        else:
                            self.failed_stack_count += len(
                                current_batch_items_with_masks_for_stack_batch
                            )

                    elif self.drizzle_mode == "Incremental":  # VRAI Drizzle Incr√©mental
                        self.update_progress(
                            f"üíß Traitement Drizzle Incr. VRAI du dernier lot partiel {progress_info_partial_log}..."
                        )
                        self._process_incremental_drizzle_batch(  # Utilise la version V_True_Incremental_Driz
                            current_batch_items_with_masks_for_stack_batch,  # Liste de CHEMINS
                            self.stacked_batches_count,
                            self.total_batches_estimated,
                        )

                    self._move_to_stacked(self._current_batch_paths)
                    self._save_partial_stack()
                    self._update_batch_count_file()
                    self._current_batch_paths = []

                    current_batch_items_with_masks_for_stack_batch = []

                # --- Sauvegarde finale sp√©cifique au mode Drizzle ---
                if self.drizzle_mode == "Incremental":
                    self.update_progress(
                        "üèÅ Finalisation Drizzle Incr√©mental VRAI (depuis objets Drizzle)..."
                    )
                    # Pour le VRAI Drizzle Incr√©mental, _save_final_stack doit lire depuis
                    # self.incremental_drizzle_objects/arrays. Ne pas passer drizzle_final_sci_data.
                    self._save_final_stack(
                        output_filename_suffix="_drizzle_incr_true"
                    )  # MODIFI√â ICI

                elif self.drizzle_mode == "Final":
                    self.update_progress(
                        "üèÅ Combinaison finale des lots Drizzle (Mode Final)..."
                    )
                    if not self.intermediate_drizzle_batch_files:
                        self.update_progress(
                            "   ‚ùå Drizzle Final: Aucun lot interm√©diaire √† combiner.",
                            None,
                        )
                        self.processing_error = "Drizzle Final: Aucun lot interm√©diaire"
                        self.final_stacked_path = None
                    else:
                        final_drizzle_sci_hxwxc, final_drizzle_wht_hxwxc = (
                            self._combine_intermediate_drizzle_batches(
                                self.intermediate_drizzle_batch_files,
                                self.drizzle_output_wcs,
                                self.drizzle_output_shape_hw,
                            )
                        )
                        if final_drizzle_sci_hxwxc is not None:
                            self.update_progress(
                                "   Drizzle Final combin√©. Pr√©paration sauvegarde..."
                            )
                            self._save_final_stack(
                                output_filename_suffix="_drizzle_final",  # Suffixe correct
                                drizzle_final_sci_data=final_drizzle_sci_hxwxc,
                                drizzle_final_wht_data=final_drizzle_wht_hxwxc,
                            )
                        else:
                            self.update_progress(
                                "   ‚ùå √âchec combinaison finale des lots Drizzle (r√©sultat vide).",
                                None,
                            )
                            self.processing_error = "√âchec combinaison Drizzle Final"
                            self.final_stacked_path = None

            # --- MODE STACKING CLASSIQUE (NON-MOSA√èQUE, NON-DRIZZLE) ---
            elif not self.is_mosaic_run and not self.drizzle_active_session:
                logger.debug(
                    "DEBUG QM [_worker Finalize]: Finalisation Stacking Classique (ou Reprojection)."
                )

                if (
                    self.reproject_between_batches
                    and current_batch_items_with_masks_for_stack_batch
                ):
                    self.stacked_batches_count += 1
                    self._send_eta_update()
                    num_in_batch = len(current_batch_items_with_masks_for_stack_batch)
                    self.update_progress(
                        f"‚öôÔ∏è Traitement classique du dernier lot partiel ({num_in_batch} images)..."
                    )

                    stacked_np, hdr, wht_2d = self._stack_batch(
                        current_batch_items_with_masks_for_stack_batch,
                        self.stacked_batches_count,
                        self.total_batches_estimated,
                    )
                    if stacked_np is not None:
                        solved_path, _ = self._save_and_solve_classic_batch(
                            stacked_np, wht_2d, hdr, self.stacked_batches_count
                        )
                        batch_wcs = None
                        try:
                            batch_wcs = WCS(hdr, naxis=2)
                        except Exception:
                            batch_wcs = None

                        self._combine_batch_result(
                            stacked_np,
                            hdr,
                            wht_2d,
                            batch_wcs=batch_wcs,
                        )

                        if self.reproject_between_batches:
                            stack_img, solved_hdr = self._solve_cumulative_stack()
                            if stack_img is not None and solved_hdr is not None:
                                reference_image_data_for_global_alignment = stack_img
                                reference_header_for_global_alignment = (
                                    solved_hdr.copy()
                                )
                            else:
                                reference_image_data_for_global_alignment = (
                                    stacked_np.astype(np.float32, copy=True)
                                )
                                reference_header_for_global_alignment = hdr.copy()
                        else:
                            reference_image_data_for_global_alignment = (
                                stacked_np.astype(np.float32, copy=True)
                            )
                            reference_header_for_global_alignment = hdr.copy()

                        if hasattr(self.cumulative_sum_memmap, "flush"):
                            self.cumulative_sum_memmap.flush()
                        if hasattr(self.cumulative_wht_memmap, "flush"):
                            self.cumulative_wht_memmap.flush()
                        self._update_preview_sum_w()
                        self._move_to_stacked(self._current_batch_paths)
                        self._save_partial_stack()
                        self._update_batch_count_file()
                        self._current_batch_paths = []
                    else:
                        self.update_progress(
                            "   -> √âchec combinaison du dernier lot partiel", "ERROR"
                        )

                    if self.move_stacked and self._current_batch_paths:
                        move_to_stacked(
                            self._current_batch_paths,
                            self.update_progress,
                            self.stacked_subdir_name,
                        )
                        self._current_batch_paths = []
                    self._update_batches_meta()
                    self._save_partial_stack()
                    current_batch_items_with_masks_for_stack_batch = []
                    gc.collect()

                elif (
                    not self.reproject_between_batches
                    and current_batch_items_with_masks_for_stack_batch
                ):
                    self.stacked_batches_count += 1
                    self._send_eta_update()
                    self.update_progress(
                        f"‚öôÔ∏è Traitement classique du dernier lot partiel ({len(current_batch_items_with_masks_for_stack_batch)} images)..."
                    )
                    self._process_completed_batch(
                        current_batch_items_with_masks_for_stack_batch,
                        self.stacked_batches_count,
                        self.total_batches_estimated,
                        self.reference_wcs_object,
                    )
                    self._move_to_stacked(self._current_batch_paths)
                    self._save_partial_stack()
                    self._update_batch_count_file()
                    self._current_batch_paths = []

                    current_batch_items_with_masks_for_stack_batch = []

                if self.reproject_between_batches:
                    self.update_progress("üèÅ Finalisation Stacking (Reprojection)...")
                    if self.images_in_cumulative_stack > 0 or (
                        hasattr(self, "cumulative_sum_memmap")
                        and self.cumulative_sum_memmap is not None
                    ):
                        self._save_final_stack(
                            output_filename_suffix="_classic_reproject"
                        )
                    else:
                        self.update_progress(
                            "   Aucune image accumul√©e pour sauvegarde."
                        )
                        self.final_stacked_path = None
                else:
                    self.update_progress(
                        "üèÅ Finalisation Stacking Classique (SUM/W)..."
                    )
                    if self.images_in_cumulative_stack > 0 or (
                        hasattr(self, "cumulative_sum_memmap")
                        and self.cumulative_sum_memmap is not None
                    ):
                        self._save_final_stack(output_filename_suffix="_classic_sumw")
                    else:
                        self.update_progress(
                            "   Aucune image accumul√©e dans le stack classique. Sauvegarde ignor√©e."
                        )
                        self.final_stacked_path = None
            else:  # Cas impr√©vu
                logger.debug(
                    "DEBUG QM [_worker V_DrizIncrTrue_Fix1]: *** ENTR√âE DANS LE 'else' FINAL (√âTAT NON G√âR√â) ***"
                )
                self.update_progress(
                    "‚ö†Ô∏è √âtat de finalisation non g√©r√©. Aucune action de sauvegarde principale."
                )
                self.processing_error = "√âtat de finalisation non g√©r√©."
                self.final_stacked_path = None

            logger.debug(
                "DEBUG QM [_worker V_DrizIncrTrue_Fix1]: *** APR√àS LE BLOC if/elif/else DE FINALISATION ***"
            )

        # --- FIN DU BLOC TRY PRINCIPAL DU WORKER ---
        except RuntimeError as rte:
            self.update_progress(
                f"‚ùå ERREUR CRITIQUE (RuntimeError) dans le worker: {rte}", "ERROR"
            )  # S'assurer que "ERROR" est pass√© pour le log GUI
            logger.debug(f"ERREUR QM [_worker V_NoDerotation]: RuntimeError: {rte}")
            traceback.print_exc(limit=3)
            self.processing_error = f"RuntimeError: {rte}"
            self.stop_processing = True  # Provoquer l'arr√™t propre du thread
        except Exception as e_global_worker:
            self.update_progress(
                f"‚ùå ERREUR INATTENDUE GLOBALE dans le worker: {e_global_worker}",
                "ERROR",
            )
            logger.debug(
                f"ERREUR QM [_worker V_NoDerotation]: Exception Globale: {e_global_worker}"
            )
            traceback.print_exc(limit=3)
            self.processing_error = f"Erreur Globale: {e_global_worker}"
            self.stop_processing = True  # Provoquer l'arr√™t propre du thread
        finally:
            logger.debug(
                f"DEBUG QM [_worker V_NoDerotation]: Entr√©e dans le bloc FINALLY principal du worker."
            )
            if (
                hasattr(self, "cumulative_sum_memmap")
                and self.cumulative_sum_memmap is not None
                or hasattr(self, "cumulative_wht_memmap")
                and self.cumulative_wht_memmap is not None
            ):
                self._close_memmaps()

            if self.perform_cleanup:
                self.update_progress("üßπ Nettoyage final des fichiers temporaires...")
                self._cleanup_drizzle_temp_files()  # Dossier des inputs Drizzle (aligned_input_*.fits)
                self._cleanup_drizzle_batch_outputs()  # Dossier des sorties Drizzle par lot (batch_*_sci.fits, batch_*_wht_*.fits)
                self._cleanup_classic_batch_outputs()  # Dossier des sorties Classic par lot
                self._cleanup_mosaic_panel_stacks_temp()  # Dossier des stacks de panneaux (si ancienne logique ou tests)
                if not self.user_requested_stop:
                    self.cleanup_temp_reference()  # Fichiers reference_image.fit/png
                if not self.stop_processing:
                    self._cleanup_memmap_files()

            self.processing_active = False
            self.stop_processing_flag_for_gui = (
                self.stop_processing
            )  # Transmettre l'√©tat d'arr√™t √† l'UI
            if self.autotuner:
                self.autotuner.stop()
            gc.collect()
            logger.debug(
                f"DEBUG QM [_worker V_NoDerotation]: Fin du bloc FINALLY principal. Flag processing_active mis √† False."
            )
            self.update_progress("üö™ Thread de traitement principal termin√©.")

    ############################################################################################################################

    # --- DANS LA CLASSE SeestarQueuedStacker DANS seestar/queuep/queue_manager.py ---

    def _generate_and_save_mosaic_alignment_log(
        self,
        all_aligned_panel_info_list: list,
        anchor_wcs_details: dict,
        final_output_grid_details: dict,
    ):
        """
        G√©n√®re un log d√©taill√© sur l'alignement de la mosa√Øque et le sauvegarde.
        MODIFIED V2: Gestion plus robuste de la lecture de _ALIGN_METHOD_LOG depuis le header.
        """
        if not self.output_folder:
            logger.debug(
                "WARN QM [_generate_mosaic_log V2]: Output folder non d√©fini, log non sauvegard√©."
            )
            return

        log_lines = []
        separator = "=" * 70

        log_lines.append(
            f"{separator}\nRAPPORT D'ALIGNEMENT DE MOSA√èQUE (V2)\n{separator}"
        )
        log_lines.append(f"Date du rapport: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        log_lines.append(f"Dossier de sortie: {self.output_folder}")

        # --- 1. Param√®tres Cl√©s de la Mosa√Øque ---
        log_lines.append(f"\n--- Param√®tres de la Mosa√Øque Utilis√©s ---")
        log_lines.append(
            f"  Mode d'alignement: {getattr(self, 'mosaic_alignment_mode', 'N/A')}"
        )
        log_lines.append(
            f"  Fallback WCS activ√©: {getattr(self, 'use_wcs_fallback_for_mosaic', 'N/A')}"
        )
        log_lines.append(
            f"  FastAligner - Seuil RANSAC: {getattr(self, 'fa_ransac_thresh', 'N/A')}"
        )
        log_lines.append(
            f"  FastAligner - Min Abs Matches: {getattr(self, 'fa_min_abs_matches', 'N/A')}"
        )
        log_lines.append(
            f"  FastAligner - Min RANSAC Raw (valeur config): {getattr(self, 'fa_min_ransac_raw', 'N/A')}"
        )
        log_lines.append(
            f"  FastAligner - ORB Features (cible): {getattr(self, 'fa_orb_features', 'N/A')}"
        )
        log_lines.append(
            f"  FastAligner DAO - FWHM: {getattr(self, 'fa_daofind_fwhm', 'N/A')}"
        )
        log_lines.append(
            f"  FastAligner DAO - Seuil Sigma Factor: {getattr(self, 'fa_daofind_thr_sig', 'N/A')}"
        )
        log_lines.append(
            f"  FastAligner DAO - Max √âtoiles Desc.: {getattr(self, 'fa_max_stars_descr', 'N/A')}"
        )
        log_lines.append(
            f"  Drizzle Mosa√Øque - Kernel: {getattr(self, 'mosaic_drizzle_kernel', 'N/A')}"
        )
        log_lines.append(
            f"  Drizzle Mosa√Øque - Pixfrac: {getattr(self, 'mosaic_drizzle_pixfrac', 'N/A')}"
        )
        log_lines.append(
            f"  Drizzle Mosa√Øque - WHT Threshold: {getattr(self, 'mosaic_drizzle_wht_threshold', 'N/A')}"
        )
        log_lines.append(
            f"  Drizzle Mosa√Øque - √âchelle Globale Appliqu√©e: {getattr(self, 'drizzle_scale', 'N/A')}x"
        )

        # --- 2. Informations sur le WCS du Panneau d'Ancrage ---
        log_lines.append(f"\n--- WCS du Panneau d'Ancrage ---")
        if anchor_wcs_details:
            log_lines.append(
                f"  Fichier Source Ancre: {anchor_wcs_details.get('source_file', 'N/A')}"
            )
            log_lines.append(f"  Type de WCS: {anchor_wcs_details.get('type', 'N/A')}")
            log_lines.append(
                f"  CRVAL (RA, Dec): {anchor_wcs_details.get('crval', 'N/A')}"
            )
            log_lines.append(
                f"  CRPIX (X, Y): {anchor_wcs_details.get('crpix', 'N/A')}"
            )
            log_lines.append(
                f"  √âchelle (arcsec/pix): {anchor_wcs_details.get('scale_arcsec_pix', 'N/A')}"
            )
            log_lines.append(
                f"  Shape Pixel WCS (W,H): {anchor_wcs_details.get('pixel_shape_wh', 'N/A')}"
            )
            log_lines.append(
                f"  Distorsion SIP pr√©sente: {anchor_wcs_details.get('sip', 'N/A')}"
            )
            log_lines.append(
                f"  Info Solveur AN_SOLVED: {anchor_wcs_details.get('AN_SOLVED', 'N/A')}"
            )
            log_lines.append(
                f"  Info Solveur AN_FIELD_SCALE_ASEC: {anchor_wcs_details.get('AN_FIELD_SCALE_ASEC', 'N/A')}"
            )
        else:
            log_lines.append("  Informations sur le WCS de l'ancre non disponibles.")

        # --- 3. R√©sum√© de l'Alignement pour Chaque Panneau ---
        log_lines.append(
            f"\n--- D√©tails de l'Alignement des Panneaux (par rapport √† l'ancre) ---"
        )
        num_panneaux_pour_alignement_relatif = 0  # Panneaux autres que l'ancre
        num_fastalign_succes = 0
        num_fallback_wcs_tentatives = 0  # Combien de fois le fallback a √©t√© tent√©
        num_fallback_wcs_succes = 0
        num_align_echecs_complets = 0

        if not all_aligned_panel_info_list:
            log_lines.append(
                "  Aucun panneau (m√™me pas l'ancre) n'a √©t√© collect√© pour la mosa√Øque."
            )
        else:
            for idx, panel_info in enumerate(all_aligned_panel_info_list):
                if not isinstance(panel_info, tuple) or len(panel_info) < 4:
                    log_lines.append(
                        f"  Panneau {idx}: Format d'information invalide. Ignor√©."
                    )
                    continue

                # panel_info = (image_data_orig, header, wcs_ANCRE_POUR_M, matrix_M, valid_mask)
                panel_header = panel_info[1]
                panel_filename_tuple = panel_header.get(
                    "_SRCFILE", (f"Panneau_{idx}_NomInconnu", "")
                )
                panel_filename = (
                    panel_filename_tuple[0]
                    if isinstance(panel_filename_tuple, tuple)
                    else str(panel_filename_tuple)
                )

                matrix_m = panel_info[3]

                log_lines.append(
                    f"  Panneau {idx+1}/{len(all_aligned_panel_info_list)}: {panel_filename}"
                )  # Afficher 1-based

                if idx == 0 and panel_filename == anchor_wcs_details.get(
                    "source_file", ""
                ):  # Identification plus robuste de l'ancre
                    log_lines.append(f"    -> R√¥le: Ancre de la mosa√Øque.")
                    log_lines.append(
                        f"    -> Matrice M (normalement identit√© pour ancre): \n{matrix_m}"
                    )
                else:  # Panneaux non-ancre
                    num_panneaux_pour_alignement_relatif += 1
                    # Lire la m√©thode d'alignement depuis le header du panneau
                    align_method_from_header_raw = panel_header.get(
                        "_ALIGN_METHOD_LOG", "Non_Loggu√©"
                    )
                    align_method_from_header = (
                        align_method_from_header_raw[0]
                        if isinstance(align_method_from_header_raw, tuple)
                        else str(align_method_from_header_raw)
                    )

                    log_lines.append(
                        f"    -> M√©thode d'alignement (loggu√©e): {align_method_from_header}"
                    )
                    log_lines.append(
                        f"    -> Matrice M calcul√©e vers l'ancre: \n{matrix_m}"
                    )

                    if align_method_from_header == "FastAligner_Success":
                        num_fastalign_succes += 1
                    elif align_method_from_header == "WCS_Fallback_Success":
                        num_fallback_wcs_succes += 1
                        num_fallback_wcs_tentatives += 1
                    elif (
                        align_method_from_header
                        == "FastAligner_Fail_Then_Fallback_Fail"
                    ):
                        num_fallback_wcs_tentatives += 1
                        num_align_echecs_complets += 1
                    elif align_method_from_header == "FastAligner_Fail_No_Fallback":
                        num_align_echecs_complets += 1
                    elif (
                        align_method_from_header == "Alignment_Failed_Fully"
                    ):  # Cas g√©n√©rique d'√©chec
                        num_align_echecs_complets += 1

        log_lines.append(
            f"\n  R√©sum√© Alignement des Panneaux (pour {num_panneaux_pour_alignement_relatif} panneaux relatifs √† l'ancre):"
        )
        log_lines.append(f"    - Succ√®s FastAligner: {num_fastalign_succes}")
        log_lines.append(
            f"    - Tentatives de Fallback WCS (apr√®s √©chec FastAligner): {num_fallback_wcs_tentatives}"
        )
        log_lines.append(f"    - Succ√®s Fallback WCS: {num_fallback_wcs_succes}")
        log_lines.append(
            f"    - √âchecs Complets d'Alignement (ni FastAligner, ni Fallback): {num_align_echecs_complets}"
        )
        total_aligned_relatifs = num_fastalign_succes + num_fallback_wcs_succes
        log_lines.append(
            f"    - Total Panneaux Relatifs Align√©s (FastAligner ou Fallback): {total_aligned_relatifs}"
        )

        # --- 4. Informations sur la Grille de Sortie Finale ---
        log_lines.append(f"\n--- Grille de Sortie Finale de la Mosa√Øque ---")
        if final_output_grid_details:
            log_lines.append(
                f"  Shape (Hauteur, Largeur): {final_output_grid_details.get('shape_hw', 'N/A')}"
            )
            log_lines.append(
                f"  WCS CRVAL (RA, Dec): {final_output_grid_details.get('crval', 'N/A')}"
            )
            log_lines.append(
                f"  WCS CRPIX (X, Y): {final_output_grid_details.get('crpix', 'N/A')}"
            )
            log_lines.append(
                f"  WCS √âchelle (arcsec/pix): {final_output_grid_details.get('scale_arcsec_pix', 'N/A')}"
            )
        else:
            log_lines.append(
                "  Informations sur la grille de sortie non disponibles (probablement car assemblage annul√©)."
            )

        # --- 5. R√©sum√© de l'Assemblage Drizzle ---
        log_lines.append(f"\n--- Assemblage Drizzle ---")
        log_lines.append(
            f"  Nombre total de panneaux (ancre + align√©s) fournis √† DrizzleProcessor: {len(all_aligned_panel_info_list)}"
        )
        # On pourrait ajouter plus d'infos si DrizzleProcessor retournait des stats d'assemblage

        # --- 6. Compteurs G√©n√©raux du Traitement (depuis l'instance QueuedStacker) ---
        log_lines.append(
            f"\n--- Compteurs G√©n√©raux du Traitement (depuis QueuedStacker) ---"
        )
        log_lines.append(
            f"  Fichiers trait√©s au total par le worker (tentatives): {getattr(self, 'processed_files_count', 0)}"
        )
        log_lines.append(
            f"  Panneaux retenus pour la mosa√Øque (attribut 'aligned_files_count'): {getattr(self, 'aligned_files_count', 0)}"
        )
        log_lines.append(
            f"  √âchecs d'alignement comptabilis√©s par QueuedStacker: {getattr(self, 'failed_align_count', 0)}"
        )
        log_lines.append(
            f"  Fichiers skipp√©s (autres raisons, ex: faible variance ref): {getattr(self, 'skipped_files_count', 0)}"
        )

        log_lines.append(f"\n{separator}\nFIN DU RAPPORT\n{separator}")

        log_filename = "rapport_alignement_mosaique.txt"
        log_filepath = os.path.join(self.output_folder, log_filename)
        try:
            with open(log_filepath, "w", encoding="utf-8") as f_log:
                for line in log_lines:
                    f_log.write(line + "\n")
            self.update_progress(
                f"üìÑ Rapport d'alignement mosa√Øque sauvegard√©: {log_filename}", None
            )
            logger.debug(
                f"DEBUG QM: Rapport d'alignement mosa√Øque V2 sauvegard√© dans '{log_filepath}'"
            )
        except Exception as e_save_log:
            self.update_progress(
                f"‚ö†Ô∏è Erreur sauvegarde rapport d'alignement mosa√Øque V2: {e_save_log}",
                None,
            )
            logger.debug(
                f"ERREUR QM: √âchec sauvegarde rapport alignement mosa√Øque V2: {e_save_log}"
            )

    #####################################################################################################################################################

    @staticmethod
    def _project_to_tangent_plane(
        sky_coords_obj: SkyCoord, tangent_point_sky: SkyCoord
    ):
        """
        Projete des coordonn√©es c√©lestes sur un plan tangent.

        Args:
            sky_coords_obj (SkyCoord): Coordonn√©es c√©lestes √† projeter.
            tangent_point_sky (SkyCoord): Point de tangence (centre de la projection).

        Returns:
            np.ndarray: Array de points (x, y) projet√©s en arcsecondes sur le plan tangent.
                        L'origine (0,0) du plan tangent correspond √† tangent_point_sky.
        """
        # Cr√©er un frame de projection centr√© sur le point de tangence
        # SkyOffsetFrame repr√©sente les offsets angulaires par rapport √† un point central.
        # Ces offsets (lon, lat) sont essentiellement des coordonn√©es sur le plan tangent.
        skyoffset_frame = tangent_point_sky.skyoffset_frame()
        coords_in_offset_frame = sky_coords_obj.transform_to(skyoffset_frame)

        # Extraire les longitudes et latitudes dans ce frame (en arcsecondes)
        # .lon et .lat dans SkyOffsetFrame sont les coordonn√©es tangentielles.
        projected_x_arcsec = coords_in_offset_frame.lon.to(u.arcsec).value
        projected_y_arcsec = coords_in_offset_frame.lat.to(u.arcsec).value

        # logger.debug(f"DEBUG _project_to_tangent_plane: SkyCoords (premier): {sky_coords_obj[0].ra.deg:.3f}, {sky_coords_obj[0].dec.deg:.3f}")
        # logger.debug(f"DEBUG _project_to_tangent_plane: Tangent Point: {tangent_point_sky.ra.deg:.3f}, {tangent_point_sky.dec.deg:.3f}")
        # logger.debug(f"DEBUG _project_to_tangent_plane: Projected (premier): x={projected_x_arcsec[0]:.2f}\", y={projected_y_arcsec[0]:.2f}\"")

        return np.column_stack((projected_x_arcsec, projected_y_arcsec))

    @staticmethod
    def _deproject_from_tangent_plane(
        xy_arcsec_array: np.ndarray, tangent_point_sky: SkyCoord
    ):
        """
        D√©-projete des coordonn√©es d'un plan tangent vers des coordonn√©es c√©lestes.

        Args:
            xy_arcsec_array (np.ndarray): Array de points (x, y) en arcsecondes sur le plan tangent.
            tangent_point_sky (SkyCoord): Point de tangence utilis√© pour la projection initiale.

        Returns:
            SkyCoord: Objet SkyCoord contenant les coordonn√©es c√©lestes d√©-projet√©es.
        """
        skyoffset_frame = tangent_point_sky.skyoffset_frame()

        # Cr√©er des SkyCoord √† partir des coordonn√©es du plan tangent, dans le SkyOffsetFrame
        # lon et lat dans SkyOffsetFrame correspondent √† nos x et y projet√©s.
        coords_on_tangent_plane = SkyCoord(
            lon=xy_arcsec_array[:, 0] * u.arcsec,
            lat=xy_arcsec_array[:, 1] * u.arcsec,
            frame=skyoffset_frame,
        )

        # Transformer ces coordonn√©es retour vers le syst√®me c√©leste de base (ex: ICRS)
        deprojected_sky_coords = coords_on_tangent_plane.transform_to(
            tangent_point_sky.frame
        )  # Utiliser le frame du point de tangence

        # logger.debug(f"DEBUG _deproject_from_tangent_plane: Input XY (premier): {xy_arcsec_array[0,0]:.2f}\", {xy_arcsec_array[0,1]:.2f}\"")
        # logger.debug(f"DEBUG _deproject_from_tangent_plane: Deprojected (premier): RA={deprojected_sky_coords[0].ra.deg:.3f}, Dec={deprojected_sky_coords[0].dec.deg:.3f}")

        return deprojected_sky_coords

    ##########################################################################################################################

    # --- DANS LA CLASSE SeestarQueuedStacker DANS seestar/queuep/queue_manager.py ---

    def _calculate_local_mosaic_output_grid(
        self, panel_info_list_for_grid: list, anchor_wcs: WCS
    ):
        """
        Version: V_OMBB_SnapToAxes
        OMBB pour dimensions et centre, puis orientation "snapp√©e" aux axes cardinaux.
        """
        num_panels = len(panel_info_list_for_grid)
        logger.debug(
            f"DEBUG QM [_calculate_local_mosaic_output_grid V_OMBB_SnapToAxes]: D√©but pour {num_panels} panneaux..."
        )
        # ... (calcul de all_corners_flat_skycoord, tangent_point_sky, tangent_plane_points_arcsec, hull_points_arcsec comme avant)
        # ... jusqu'√† obtenir rect de cv2.minAreaRect
        # Les premi√®res parties sont identiques √† V_OMBB_Fix5
        all_sky_corners_list = []
        anchor_frame_name = "icrs"
        if (
            hasattr(anchor_wcs, "wcs")
            and hasattr(anchor_wcs.wcs, "radesys")
            and anchor_wcs.wcs.radesys
        ):
            radesys_val = str(anchor_wcs.wcs.radesys).strip().lower()
            if radesys_val in ["icrs", "fk5", "fk4", "galactic"]:
                anchor_frame_name = radesys_val
        for i, panel_info in enumerate(panel_info_list_for_grid):
            try:
                img_data_orig = panel_info[0]
                transform_M = panel_info[3]
                if img_data_orig is None or transform_M is None:
                    continue
                original_h, original_w = img_data_orig.shape[:2]
                pixel_corners_orig = np.array(
                    [
                        [0.0, 0.0],
                        [original_w - 1.0, 0.0],
                        [original_w - 1.0, original_h - 1.0],
                        [0.0, original_h - 1.0],
                    ],
                    dtype=np.float32,
                ).reshape(-1, 1, 2)
                corners_in_anchor_pixels = cv2.transform(
                    pixel_corners_orig, transform_M
                ).reshape(-1, 2)
                ra_coords_deg, dec_coords_deg = anchor_wcs.all_pix2world(
                    corners_in_anchor_pixels[:, 0], corners_in_anchor_pixels[:, 1], 0
                )
                sky_corners_panel_obj = SkyCoord(
                    ra=ra_coords_deg,
                    dec=dec_coords_deg,
                    unit="deg",
                    frame=anchor_frame_name,
                )
                all_sky_corners_list.append(sky_corners_panel_obj)
            except Exception:
                continue  # Simplifi√© pour la longueur
        if not all_sky_corners_list:
            return None, None

        try:
            if len(all_sky_corners_list) == 1:
                all_corners_flat_skycoord = all_sky_corners_list[0]
            else:
                all_corners_flat_skycoord = skycoord_concatenate(all_sky_corners_list)

            median_ra_deg = np.median(
                all_corners_flat_skycoord.ra.wrap_at(180 * u.deg).deg
            )
            median_dec_deg = np.median(all_corners_flat_skycoord.dec.deg)
            tangent_point_sky = SkyCoord(
                ra=median_ra_deg * u.deg,
                dec=median_dec_deg * u.deg,
                frame=all_corners_flat_skycoord.frame.name.lower(),
            )
            tangent_plane_points_arcsec = (
                SeestarQueuedStacker._project_to_tangent_plane(
                    all_corners_flat_skycoord, tangent_point_sky
                )
            )
            if (
                tangent_plane_points_arcsec is None
                or len(tangent_plane_points_arcsec) < 3
            ):
                return None, None

            unique_tangent_points = np.unique(tangent_plane_points_arcsec, axis=0)
            if len(unique_tangent_points) < 3:
                hull_points_arcsec = np.ascontiguousarray(unique_tangent_points)
            else:
                try:
                    hull = ConvexHull(np.ascontiguousarray(unique_tangent_points))
                    hull_points_arcsec = unique_tangent_points[hull.vertices]
                except Exception:
                    hull_points_arcsec = np.ascontiguousarray(unique_tangent_points)
            if len(hull_points_arcsec) < 2:
                return None, None

            rect = cv2.minAreaRect(hull_points_arcsec.astype(np.float32))
            (
                (center_x_tan_arcsec, center_y_tan_arcsec),
                (dim1_arcsec, dim2_arcsec),
                angle_cv_deg,
            ) = rect
            logger.debug(
                f"DEBUG QM: OMBB brut: centre_tan=({center_x_tan_arcsec:.1f}, {center_y_tan_arcsec:.1f}), dims_tan=({dim1_arcsec:.1f}, {dim2_arcsec:.1f}), angle_cv={angle_cv_deg:.1f}¬∞"
            )

            # --- NOUVELLE LOGIQUE D'ORIENTATION ET DE DIMENSION ---
            # angle_cv_deg est l'angle du c√¥t√© dim1_arcsec par rapport √† l'axe X du plan tangent.
            # On veut que l'image finale soit "droite" (horizontale ou verticale).
            # On teste deux orientations principales pour l'OMBB : son orientation naturelle, et tourn√©e de 90 deg.
            # Puis on choisit celle qui est la plus proche d'√™tre align√©e aux axes.

            angle_option1 = angle_cv_deg  # dim1 est la largeur, dim2 est la hauteur
            angle_option2 = (
                angle_cv_deg + 90.0
            )  # dim2 est la largeur, dim1 est la hauteur

            # Normaliser les angles √† [-90, 90] pour faciliter la comparaison avec 0 (horizontal)
            # Un angle de 0 ou ~180 devient 0. Un angle de ~90 ou ~-90 devient ~90.
            def normalize_angle_for_straightness(angle):
                angle = angle % 180  # Met dans [0, 180) ou (-180, 0]
                if angle > 90:
                    angle -= 180  # Met dans (-90, 90]
                elif angle < -90:
                    angle += 180  # Met dans [-90, 90)
                return angle

            norm_angle1 = normalize_angle_for_straightness(angle_option1)
            norm_angle2 = normalize_angle_for_straightness(angle_option2)

            # Choisir l'orientation qui est la plus "droite" (plus proche de 0 ou 90, donc |angle| plus petit ou |angle-90| plus petit)
            # On veut minimiser l'angle absolu par rapport √† l'axe le plus proche (0 ou 90)
            # Un angle normalis√© de 0 est horizontal, un angle de +/-90 est vertical.
            # On pr√©f√®re celui dont l'angle normalis√© est le plus proche de 0.
            # (Si |norm_angle1| est plus petit, dim1 est plus "horizontal")
            # (Si |norm_angle2| est plus petit, dim2 est plus "horizontal")

            final_wcs_rotation_deg = 0.0
            # On veut que le c√¥t√© le plus long de l'OMBB soit la largeur de l'image SI CETTE ORIENTATION EST PLUS "DROITE"
            # OU que le c√¥t√© le plus long de l'OMBB soit la hauteur de l'image SI CETTE ORIENTATION EST PLUS "DROITE"

            # Si l'angle de dim1 (angle_cv_deg) est plus proche de 0 (ou 180) que de 90 (ou -90),
            # alors on pr√©f√®re aligner dim1 horizontalement.
            # Si l'angle de dim1 est plus proche de 90 (ou -90) que de 0,
            # alors on pr√©f√®re aligner dim1 verticalement (donc dim2 horizontalement).

            # `angle_cv_deg` est dans [-90, 0).
            # Si angle_cv_deg est entre -45 et 0, dim1 est "plut√¥t horizontal". Rotation WCS = angle_cv_deg.
            # Si angle_cv_deg est entre -90 et -45, dim1 est "plut√¥t vertical". Rotation WCS = angle_cv_deg + 90 (pour rendre dim2 horizontal).

            if abs(angle_cv_deg) <= 45.0:  # dim1 est plus horizontal que vertical
                final_wcs_rotation_deg = angle_cv_deg
                # Les dimensions de l'OMBB SONT d√©j√† celles-ci par rapport √† cette rotation
                # Mais pour le calcul de la SHAPE finale, on utilisera la reprojection de tous les coins
            else:  # dim1 est plus vertical, donc on tourne de 90 deg pour que dim2 devienne "horizontal"
                final_wcs_rotation_deg = angle_cv_deg + 90.0

            # Maintenant, on "snappe" cet angle √† 0 ou 90 pour que ce soit vraiment droit
            # Mais attention, si on snappe l'angle WCS, les dimensions de l'OMBB ne correspondent plus.
            # L'objectif de l'OMBB √©tait de minimiser l'aire. Si on force l'angle WCS √† 0 ou 90,
            # alors on devrait utiliser les dimensions de l'AABB (Axis Aligned Bounding Box) sur le plan tangent.

            # REVENONS √Ä L'ID√âE SIMPLE : PAS DE ROTATION PAR RAPPORT AUX AXES RA/DEC
            # L'OMBB sert uniquement √† trouver le CRVAL.
            # La SHAPE est ensuite calcul√©e pour englober tout.

            final_wcs_rotation_deg = 0.0  # Forcer l'alignement avec les axes RA/Dec
            self.update_progress(f"   -> Orientation WCS forc√©e √† 0¬∞ (align√©e RA/Dec).")
            logger.debug(
                f"DEBUG QM: Angle de rotation WCS final forc√© √†: {final_wcs_rotation_deg:.1f}¬∞"
            )

            # CRVAL vient du centre de l'OMBB (calcul√© avant)
            crval_skycoord_list = SeestarQueuedStacker._deproject_from_tangent_plane(
                np.array([[center_x_tan_arcsec, center_y_tan_arcsec]]),
                tangent_point_sky,
            )
            crval_skycoord = crval_skycoord_list[0]
            output_crval = [crval_skycoord.ra.deg, crval_skycoord.dec.deg]
            logger.debug(
                f"DEBUG QM: CRVAL utilis√© (centre OMBB): RA={output_crval[0]:.4f}, Dec={output_crval[1]:.4f}"
            )
            # --- FIN NOUVELLE LOGIQUE D'ORIENTATION ---

            # ... (Calcul de anchor_pix_scale_deg et output_pixel_scale_deg comme dans V_OMBB_Fix4)
            # ... (Utiliser le code de calcul d'√©chelle de V_OMBB_Fix4 ici)
            anchor_pix_scale_deg = 0.0
            try:
                if (
                    hasattr(anchor_wcs.wcs, "cd")
                    and anchor_wcs.wcs.cd is not None
                    and anchor_wcs.wcs.cd.shape == (2, 2)
                    and np.all(np.isfinite(anchor_wcs.wcs.cd))
                ):
                    det_cd = np.abs(np.linalg.det(anchor_wcs.wcs.cd))
                    if det_cd > 1e-20:
                        anchor_pix_scale_deg = np.sqrt(det_cd)
                    else:
                        raise ValueError("Det CD trop faible")
                elif (
                    hasattr(anchor_wcs.wcs, "pc")
                    and hasattr(anchor_wcs.wcs, "cdelt")
                    and anchor_wcs.wcs.pc is not None
                    and anchor_wcs.wcs.cdelt is not None
                ):
                    scale_m = np.diag(anchor_wcs.wcs.cdelt)
                    cd_m_reco = np.dot(scale_m, anchor_wcs.wcs.pc)
                    det_cd_reco = np.abs(np.linalg.det(cd_m_reco))
                    if det_cd_reco > 1e-20:
                        anchor_pix_scale_deg = np.sqrt(det_cd_reco)
                    else:
                        raise ValueError("Det CD reconstruit trop faible")
                else:
                    if (
                        anchor_wcs.is_celestial
                        and hasattr(anchor_wcs, "array_shape")
                        and anchor_wcs.array_shape
                        and anchor_wcs.array_shape[0] > 0
                    ):
                        scales_dpp = proj_plane_pixel_scales(anchor_wcs)
                        anchor_pix_scale_deg = np.mean(np.abs(scales_dpp))
                    else:
                        raise ValueError("Fallback √©chelle")
            except Exception:
                fov_e = getattr(self, "estimated_fov_degrees", 1.0)
                iw_e = (
                    anchor_wcs.pixel_shape[0]
                    if hasattr(anchor_wcs, "pixel_shape")
                    and anchor_wcs.pixel_shape
                    and anchor_wcs.pixel_shape[0] > 0
                    else 1000
                )
                anchor_pix_scale_deg = fov_e / (iw_e if iw_e > 0 else 1000)
            if anchor_pix_scale_deg <= 1e-15:
                return None, None
            output_pixel_scale_deg = anchor_pix_scale_deg / self.drizzle_scale

            # --- Construction du WCS de sortie avec CRVAL et CD (maintenant avec rotation snapp√©e) ---
            output_wcs = WCS(naxis=2)
            output_wcs.wcs.ctype = [
                str(getattr(anchor_wcs.wcs, "ctype", ["RA---TAN", "DEC--TAN"])[0]),
                str(getattr(anchor_wcs.wcs, "ctype", ["RA---TAN", "DEC--TAN"])[1]),
            ]
            output_wcs.wcs.crval = output_crval
            output_wcs.wcs.cunit = [
                str(getattr(anchor_wcs.wcs, "cunit", ["deg", "deg"])[0]),
                str(getattr(anchor_wcs.wcs, "cunit", ["deg", "deg"])[1]),
            ]
            output_wcs.wcs.radesys = str(
                getattr(anchor_wcs.wcs, "radesys", "ICRS")
            ).upper()

            angle_pc_rad = np.deg2rad(final_wcs_rotation_deg)  # UTILISER L'ANGLE SNAPP√â
            cos_rot = np.cos(angle_pc_rad)
            sin_rot = np.sin(angle_pc_rad)
            pc_matrix = np.array([[cos_rot, -sin_rot], [sin_rot, cos_rot]])
            cdelt_matrix = np.array(
                [[-output_pixel_scale_deg, 0.0], [0.0, output_pixel_scale_deg]]
            )
            output_wcs.wcs.cd = np.dot(cdelt_matrix, pc_matrix)
            logger.debug(
                f"DEBUG QM: WCS orient√© (snapp√©) cr√©√©. CRVAL={output_wcs.wcs.crval}, CD=\n{output_wcs.wcs.cd}"
            )

            # --- Reprojection des coins, calcul shape et CRPIX final (comme dans V_OMBB_Fix5) ---
            all_ra_deg = all_corners_flat_skycoord.ra.deg
            all_dec_deg = all_corners_flat_skycoord.dec.deg
            projected_x_pixels, projected_y_pixels = output_wcs.all_world2pix(
                all_ra_deg, all_dec_deg, 0
            )

            valid_projection_mask = np.isfinite(projected_x_pixels) & np.isfinite(
                projected_y_pixels
            )
            if not np.any(valid_projection_mask):
                return None, None  # Erreur si aucun point valide
            projected_x_pixels = projected_x_pixels[valid_projection_mask]
            projected_y_pixels = projected_y_pixels[valid_projection_mask]

            x_min_final = np.min(projected_x_pixels)
            x_max_final = np.max(projected_x_pixels)
            y_min_final = np.min(projected_y_pixels)
            y_max_final = np.max(projected_y_pixels)

            final_output_width_px = int(np.ceil(x_max_final - x_min_final))
            final_output_height_px = int(np.ceil(y_max_final - y_min_final))
            final_output_width_px = max(10, final_output_width_px)
            final_output_height_px = max(10, final_output_height_px)
            output_shape_final_hw = (final_output_height_px, final_output_width_px)

            crval_x_abs_pix, crval_y_abs_pix = output_wcs.all_world2pix(
                output_wcs.wcs.crval[0], output_wcs.wcs.crval[1], 0
            )
            final_crpix1 = crval_x_abs_pix - x_min_final
            final_crpix2 = crval_y_abs_pix - y_min_final

            output_wcs.wcs.crpix = [final_crpix1, final_crpix2]
            output_wcs.pixel_shape = (final_output_width_px, final_output_height_px)
            try:
                output_wcs._naxis1 = final_output_width_px
                output_wcs._naxis2 = final_output_height_px
            except AttributeError:
                pass

            logger.debug(
                f"DEBUG QM: WCS Mosa√Øque Finale (SnapToAxes) OK: CRPIX={output_wcs.wcs.crpix}, PixelShape={output_wcs.pixel_shape}"
            )
            return output_wcs, output_shape_final_hw

        except Exception as e_grid:
            logger.debug(
                f"ERREUR QM [_calculate_local_mosaic_output_grid V_OMBB_SnapToAxes]: √âchec calcul final grille/WCS: {e_grid}"
            )
            traceback.print_exc(limit=2)
            return None, None

    # ... (reste de la classe) ...

    ##############################################################################################################################

    def _update_header_for_drizzle_final(self):
        """
        Cr√©e et retourne un header FITS pour le stack final en mode Drizzle "Final".
        """
        logger.debug(
            "DEBUG QM [_update_header_for_drizzle_final]: Cr√©ation du header pour Drizzle Final..."
        )

        final_header = fits.Header()

        # 1. Copier les informations de base du header de r√©f√©rence (si disponible)
        if self.reference_header_for_wcs:
            logger.debug(
                "DEBUG QM [_update_header_for_drizzle_final]: Copie des cl√©s depuis reference_header_for_wcs..."
            )
            # Liste des cl√©s FITS standard et utiles √† copier depuis une brute/r√©f√©rence
            keys_to_copy_from_ref = [
                "INSTRUME",
                "TELESCOP",
                "OBSERVER",
                "OBJECT",
                "DATE-OBS",
                "TIME-OBS",  # Ou juste DATE-OBS si TIME-OBS n'est pas toujours l√†
                "EXPTIME",  # L'exposition d'une brute individuelle
                "FILTER",
                "BAYERPAT",
                "XBAYROFF",
                "YBAYROFF",
                "GAIN",
                "OFFSET",
                "CCD-TEMP",
                "READMODE",
                "FOCALLEN",
                "APERTURE",
                "PIXSIZE",
                "XPIXSZ",
                "YPIXSZ",  # Infos optiques
                "SITELAT",
                "SITELONG",
                "SITEELEV",  # Infos site
            ]
            for key in keys_to_copy_from_ref:
                if key in self.reference_header_for_wcs:
                    try:
                        # Essayer de copier avec le commentaire
                        final_header[key] = (
                            self.reference_header_for_wcs[key],
                            self.reference_header_for_wcs.comments[key],
                        )
                    except KeyError:  # Si pas de commentaire, copier juste la valeur
                        final_header[key] = self.reference_header_for_wcs[key]
                    except Exception as e_copy:
                        logger.debug(
                            f"DEBUG QM [_update_header_for_drizzle_final]: Erreur copie cl√© '{key}': {e_copy}"
                        )
        else:
            logger.debug(
                "DEBUG QM [_update_header_for_drizzle_final]: reference_header_for_wcs non disponible."
            )

        # 2. Ajouter/Mettre √† jour les informations sp√©cifiques au Drizzle Final
        final_header["STACKTYP"] = (
            f"Drizzle Final ({self.drizzle_scale:.0f}x)",
            "Stacking method with Drizzle",
        )
        final_header["DRZSCALE"] = (self.drizzle_scale, "Drizzle final scale factor")
        final_header["DRZKERNEL"] = (self.drizzle_kernel, "Drizzle kernel used")
        final_header["DRZPIXFR"] = (self.drizzle_pixfrac, "Drizzle pixfrac used")
        final_header["DRZMODE"] = (
            "Final",
            "Drizzle combination mode",
        )  # Sp√©cifique pour ce header

        # NIMAGES et TOTEXP seront mis √† jour dans _save_final_stack avec les valeurs finales
        # mais on peut mettre une estimation ici si self.aligned_files_count est d√©j√† pertinent
        if hasattr(self, "aligned_files_count") and self.aligned_files_count > 0:
            final_header["NINPUTS"] = (
                self.aligned_files_count,
                "Number of aligned images input to Drizzle",
            )
            # Pour TOTEXP, il faudrait multiplier aligned_files_count par l'EXPTIME moyen
            # Laissons _save_final_stack g√©rer le TOTEXP final pour plus de pr√©cision.

        # 3. Informations g√©n√©rales
        final_header["CREATOR"] = ("SeestarStacker (Queued)", "Processing Software")
        final_header["HISTORY"] = "Final Drizzle image created by SeestarStacker"
        if self.correct_hot_pixels:
            final_header["HISTORY"] = "Hot pixel correction applied to input frames"
        if (
            self.use_quality_weighting
        ):  # Le Drizzle actuel ne prend pas en compte ces poids directement
            final_header["HISTORY"] = (
                "Quality weighting parameters were set, but Drizzle uses its own weighting."
            )

        # Le WCS sera ajout√© par _save_final_stack √† partir du self.drizzle_output_wcs

        logger.debug(
            "DEBUG QM [_update_header_for_drizzle_final]: Header pour Drizzle Final cr√©√©."
        )
        return final_header

    ############################################################################################################################

    # --- DANS LA CLASSE SeestarQueuedStacker DANS seestar/queuep/queue_manager.py ---

    def _cleanup_mosaic_panel_stacks_temp(self):
        """
        Supprime le dossier contenant les stacks de panneaux temporaires
        (utilis√© par l'ancienne logique de mosa√Øque ou si des fichiers y sont cr√©√©s).
        """
        # --- V√âRIFICATION AJOUT√âE ---
        if self.output_folder is None:
            logger.debug(
                "WARN QM [_cleanup_mosaic_panel_stacks_temp]: self.output_folder non d√©fini, nettoyage annul√©."
            )
            return
        # --- FIN V√âRIFICATION ---

        panel_stacks_dir = os.path.join(self.output_folder, "mosaic_panel_stacks_temp")

        # V√©rifier si le dossier existe avant d'essayer de le supprimer
        if os.path.isdir(panel_stacks_dir):  # Utiliser os.path.isdir pour v√©rifier
            try:
                shutil.rmtree(panel_stacks_dir)
                self.update_progress(
                    f"üßπ Dossier stacks panneaux temp. supprim√©: {os.path.basename(panel_stacks_dir)}"
                )
                logger.debug(
                    f"DEBUG QM [_cleanup_mosaic_panel_stacks_temp]: Dossier {panel_stacks_dir} supprim√©."
                )
            except FileNotFoundError:
                # Devrait √™tre attrap√© par isdir, mais s√©curit√©
                logger.debug(
                    f"DEBUG QM [_cleanup_mosaic_panel_stacks_temp]: Dossier {panel_stacks_dir} non trouv√© (d√©j√† supprim√© ou jamais cr√©√©)."
                )
                pass  # Le dossier n'existe pas, rien √† faire
            except OSError as e:  # Capturer les erreurs d'OS (permissions, etc.)
                self.update_progress(
                    f"‚ö†Ô∏è Erreur suppression dossier stacks panneaux temp. ({os.path.basename(panel_stacks_dir)}): {e}"
                )
                logger.debug(
                    f"ERREUR QM [_cleanup_mosaic_panel_stacks_temp]: Erreur OSError lors de la suppression de {panel_stacks_dir}: {e}"
                )
            except Exception as e_generic:  # Capturer toute autre exception
                self.update_progress(
                    f"‚ö†Ô∏è Erreur inattendue suppression dossier stacks panneaux temp.: {e_generic}"
                )
                logger.debug(
                    f"ERREUR QM [_cleanup_mosaic_panel_stacks_temp]: Erreur Exception lors de la suppression de {panel_stacks_dir}: {e_generic}"
                )
        else:
            # Log optionnel si le dossier n'existait pas
            # logger.debug(f"DEBUG QM [_cleanup_mosaic_panel_stacks_temp]: Dossier {panel_stacks_dir} non trouv√©, aucun nettoyage n√©cessaire.")
            pass

    ###################################################################################################################

    def _finalize_mosaic_processing(self, aligned_files_info_list):
        """Effectue la combinaison finale pour le mode mosa√Øque en utilisant reproject."""
        num_panels = len(aligned_files_info_list)
        logger.debug(
            f"DEBUG (Backend _finalize_mosaic_processing): D√©but finalisation pour {num_panels} panneaux."
        )
        self.update_progress(
            f"üñºÔ∏è Pr√©paration assemblage mosa√Øque final ({num_panels} images) avec reproject..."
        )

        if num_panels < 1:
            self.update_progress(
                "‚ö†Ô∏è Moins de 1 panneau align√© disponible pour la mosa√Øque. Traitement annul√©."
            )
            self.final_stacked_path = None
            self.processing_error = "Mosa√Øque: Moins de 1 panneau align√©"
            return

        try:
            from seestar.enhancement.reproject_utils import (
                reproject_and_coadd,
                reproject_interp,
            )
        except ImportError:
            self.update_progress(
                "‚ùå Biblioth√®que reproject non disponible pour l'assemblage mosa√Øque.",
                "ERROR",
            )
            self.processing_error = "reproject non disponible"
            self.final_stacked_path = None
            return

        input_data_for_reproject = []
        input_footprints_for_reproject = []
        all_wcs_for_grid_calc = []
        all_headers_for_grid_calc = []

        for panel_info_tuple in aligned_files_info_list:
            try:
                panel_image_data, panel_header, wcs_for_panel, _, pixel_mask = (
                    panel_info_tuple
                )
                if panel_image_data is None or wcs_for_panel is None:
                    continue
                input_data_for_reproject.append((panel_image_data, wcs_for_panel))
                if pixel_mask is not None:
                    input_footprints_for_reproject.append(pixel_mask.astype(np.float32))
                else:
                    input_footprints_for_reproject.append(
                        np.ones(panel_image_data.shape[:2], dtype=np.float32)
                    )
                all_wcs_for_grid_calc.append(wcs_for_panel)
                all_headers_for_grid_calc.append(panel_header)
            except Exception as e_unpack:
                self.update_progress(
                    f"    -> ERREUR d√©ballage tuple panneau: {e_unpack}. Ignor√©.",
                    "ERROR",
                )

        if not input_data_for_reproject:
            self.update_progress(
                "‚ùå Mosa√Øque: Aucun panneau valide √† traiter. Traitement annul√©.",
                "ERROR",
            )
            return

        if self.reference_wcs_object is not None and self.reference_shape is not None:
            output_wcs = self.reference_wcs_object
            output_shape_hw = self.reference_shape
        else:
            output_wcs, output_shape_hw = self._calculate_final_mosaic_grid(
                all_wcs_for_grid_calc,
                all_headers_for_grid_calc,
                scale_factor=self.drizzle_scale if self.drizzle_active_session else 1.0,
            )

        if output_wcs is None or output_shape_hw is None:
            self.update_progress(
                "‚ùå √âchec calcul grille de sortie pour la mosa√Øque.",
                "ERROR",
            )
            return

        final_mosaic_sci_channels = []
        final_mosaic_coverage_channels = []
        for i_ch in range(3):
            self.update_progress(
                f"   Reprojection et combinaison du canal {i_ch+1}/3..."
            )
            channel_arrays_wcs_list = [
                (panel_data[..., i_ch], wcs)
                for panel_data, wcs in input_data_for_reproject
            ]
            try:
                sci, cov = reproject_and_coadd(
                    channel_arrays_wcs_list,
                    output_projection=output_wcs,
                    shape_out=output_shape_hw,
                    input_weights=input_footprints_for_reproject,
                    reproject_function=reproject_interp,
                    combine_function="mean",
                    match_background=True,
                )
                final_mosaic_sci_channels.append(sci.astype(np.float32))
                final_mosaic_coverage_channels.append(cov.astype(np.float32))
            except Exception as e_reproject:
                self.update_progress(
                    f"‚ùå Erreur durant reproject_and_coadd pour canal {i_ch+1}: {e_reproject}",
                    "ERROR",
                )
                return

        try:
            final_sci_image_HWC = np.stack(final_mosaic_sci_channels, axis=-1)
            final_coverage_map_2D = final_mosaic_coverage_channels[0]
            self.current_stack_header = fits.Header()
            self.current_stack_header.update(output_wcs.to_header(relax=True))
            self._save_final_stack(
                output_filename_suffix="_mosaic_reproject",
                drizzle_final_sci_data=final_sci_image_HWC,
                drizzle_final_wht_data=final_coverage_map_2D,
            )
        except Exception as e_stack_final:
            self.update_progress(
                f"‚ùå Erreur finalisation/sauvegarde mosa√Øque: {e_stack_final}",
                "ERROR",
            )
        finally:
            gc.collect()

    ##################################################################################################################

    def _cleanup_drizzle_batch_outputs(self):
        """Supprime le dossier contenant les fichiers Drizzle interm√©diaires par lot."""
        # AJOUT D'UNE V√âRIFICATION : Ne rien faire si self.output_folder n'est pas encore d√©fini.
        if self.output_folder is None:
            logger.debug(
                "WARN QM [_cleanup_drizzle_batch_outputs]: self.output_folder non d√©fini, nettoyage annul√©."
            )
            return

        batch_output_dir = os.path.join(self.output_folder, "drizzle_batch_outputs")
        if batch_output_dir and os.path.isdir(
            batch_output_dir
        ):  # V√©rifier aussi si le chemin construit est valide
            try:
                shutil.rmtree(batch_output_dir)
                self.update_progress(
                    f"üßπ Dossier Drizzle interm√©diaires par lot supprim√©: {os.path.basename(batch_output_dir)}"
                )
            except Exception as e:
                self.update_progress(
                    f"‚ö†Ô∏è Erreur suppression dossier Drizzle interm√©diaires ({os.path.basename(batch_output_dir)}): {e}"
                )
        # else: # Log optionnel si le dossier n'existait pas ou chemin invalide
        # if self.output_folder: # Pour √©viter de logguer si c'est juste output_folder qui est None
        #    logger.debug(f"DEBUG QM [_cleanup_drizzle_batch_outputs]: Dossier {batch_output_dir} non trouv√© ou invalide pour nettoyage.")

    ####################################################################################################

    def _cleanup_classic_batch_outputs(self):
        """Supprime le dossier contenant les sorties interm√©diaires du mode classique."""
        if self.output_folder is None:
            logger.debug(
                "WARN QM [_cleanup_classic_batch_outputs]: self.output_folder non d√©fini, nettoyage annul√©."
            )
            return

        batch_output_dir = self.classic_batch_output_dir or os.path.join(
            self.output_folder, "classic_batch_outputs"
        )
        if os.path.isdir(batch_output_dir):
            try:
                shutil.rmtree(batch_output_dir)
                self.update_progress(
                    f"üßπ Dossier batches classiques supprim√©: {os.path.basename(batch_output_dir)}"
                )
            except Exception as e:
                self.update_progress(
                    f"‚ö†Ô∏è Erreur suppression dossier batches classiques ({os.path.basename(batch_output_dir)}): {e}"
                )

    ####################################################################################################################

    def _calculate_weights(self, batch_scores):
        num_images = len(batch_scores)
        if num_images == 0:
            return np.array([])
        raw_weights = np.ones(num_images, dtype=np.float32)
        for i, scores in enumerate(batch_scores):
            weight = 1.0
            if self.weight_by_snr:
                weight *= max(scores.get("snr", 0.0), 0.0) ** self.snr_exponent
            if self.weight_by_stars:
                weight *= max(scores.get("stars", 0.0), 0.0) ** self.stars_exponent
            raw_weights[i] = max(weight, 1e-9)
        sum_weights = np.sum(raw_weights)
        if sum_weights > 1e-9:
            normalized_weights = raw_weights * (num_images / sum_weights)
        else:
            normalized_weights = np.ones(num_images, dtype=np.float32)
        normalized_weights = np.maximum(normalized_weights, self.min_weight)
        sum_weights_final = np.sum(normalized_weights)
        if sum_weights_final > 1e-9:
            normalized_weights = normalized_weights * (num_images / sum_weights_final)
        else:
            normalized_weights = np.ones(num_images, dtype=np.float32)
        return normalized_weights

    def _reproject_to_reference(self, image_array, input_wcs):
        """Reproject ``image_array`` from ``input_wcs`` to the reference WCS.

        Parameters
        ----------
        image_array : np.ndarray
            Array ``HxW`` or ``HxWx3`` to reproject.
        input_wcs : astropy.wcs.WCS
            WCS describing ``image_array``.

        Returns
        -------
        tuple
            ``(reprojected_image, footprint)`` both ``float32``.
        """
        from seestar.enhancement.reproject_utils import reproject_interp

        if self.keep_input_size_for_reproject and self.input_reference_shape_hw:
            target_shape = self.input_reference_shape_hw
        else:
            target_shape = self.memmap_shape[:2]
        if image_array.ndim == 3:
            channels = []
            footprint = None
            for ch in range(image_array.shape[2]):
                reproj_ch, footprint = reproject_interp(
                    (image_array[..., ch], input_wcs),
                    self.reference_wcs_object,
                    shape_out=target_shape,
                )
                channels.append(reproj_ch)
            result = np.stack(channels, axis=2)
        else:
            result, footprint = reproject_interp(
                (image_array, input_wcs),
                self.reference_wcs_object,
                shape_out=target_shape,
            )
        return result.astype(np.float32), footprint.astype(np.float32)

    def _reproject_batch_to_reference(self, batch_image, batch_wht, batch_wcs):
        """Reproject batch data and weight map to the reference WCS."""
        if self.reference_wcs_object is None or batch_wcs is None:
            return batch_image, batch_wht

        from seestar.enhancement.reproject_utils import reproject_interp

        if self.keep_input_size_for_reproject and self.input_reference_shape_hw:
            target_shape = self.input_reference_shape_hw
        else:
            target_shape = self.memmap_shape[:2]

        if batch_image.ndim == 3:
            channels = []
            for ch in range(batch_image.shape[2]):
                reproj_ch, _ = reproject_interp(
                    (batch_image[:, :, ch], batch_wcs),
                    self.reference_wcs_object,
                    shape_out=target_shape,
                )
                channels.append(reproj_ch)
            batch_image = np.stack(channels, axis=2)
        else:
            batch_image, _ = reproject_interp(
                (batch_image, batch_wcs),
                self.reference_wcs_object,
                shape_out=target_shape,
            )

        batch_wht, _ = reproject_interp(
            (batch_wht, batch_wcs),
            self.reference_wcs_object,
            shape_out=target_shape,
        )

        return batch_image.astype(np.float32), batch_wht.astype(np.float32)

    ############################################################################################################################

    # --- DANS LA CLASSE SeestarQueuedStacker DANS seestar/queuep/queue_manager.py ---

    def _process_file(
        self,
        file_path,
        reference_image_data_for_alignment,  # Image de l'ANCRE pour FastAligner ou r√©f. pour Astroalign std
        solve_astrometry_for_this_file=False,
        fa_orb_features_config=5000,
        fa_min_abs_matches_config=10,
        fa_min_ransac_inliers_value_config=4,
        fa_ransac_thresh_config=3.0,
        daofind_fwhm_config=3.5,
        daofind_threshold_sigma_config=6.0,
        max_stars_to_describe_config=750,
    ):
        """
        Traite un seul fichier image.
        Version: V_ProcessFile_M81_Debug_UltimateLog_1
        """
        file_name = os.path.basename(file_path)
        quality_scores = {"snr": 0.0, "stars": 0.0}
        logger.debug(
            f"\nDEBUG QM [_process_file V_ProcessFile_M81_Debug_UltimateLog_1]:"
        )  # Modifi√© le nom de version pour le log
        logger.debug(f"  >> Fichier: '{file_name}'")
        logger.debug(
            f"  >> Solve Astrometry Directly: {solve_astrometry_for_this_file}"
        )
        logger.debug(
            f"  >> is_mosaic_run: {self.is_mosaic_run}, mosaic_alignment_mode: {getattr(self, 'mosaic_alignment_mode', 'N/A')}"
        )
        logger.debug(f"  >> drizzle_active_session: {self.drizzle_active_session}")

        header_final_pour_retour = None
        img_data_array_loaded = None
        prepared_img_after_initial_proc = None
        image_for_alignment_or_drizzle_input = None
        wcs_final_pour_retour = None
        data_final_pour_retour = None
        valid_pixel_mask_2d = None
        matrice_M_calculee = None
        align_method_log_msg = "Unknown"

        try:
            logger.debug(f"  -> [1/7] Chargement/Validation FITS pour '{file_name}'...")
            loaded_data_tuple = load_and_validate_fits(file_path)
            if loaded_data_tuple and loaded_data_tuple[0] is not None:
                img_data_array_loaded, header_from_load = loaded_data_tuple
                header_final_pour_retour = (
                    header_from_load.copy() if header_from_load else fits.Header()
                )
            else:
                header_temp_fallback = None
                if loaded_data_tuple and loaded_data_tuple[1] is not None:
                    header_temp_fallback = loaded_data_tuple[1].copy()
                else:
                    try:
                        header_temp_fallback = fits.getheader(file_path)
                    except:
                        header_temp_fallback = fits.Header()
                header_final_pour_retour = header_temp_fallback
                raise ValueError(
                    "√âchec chargement/validation FITS (donn√©es non retourn√©es)."
                )
            header_final_pour_retour["_SRCFILE"] = (
                file_name,
                "Original source filename",
            )
            logger.debug(
                f"     - FITS original (apr√®s load_and_validate): Range: [{np.min(img_data_array_loaded):.4g}, {np.max(img_data_array_loaded):.4g}], Shape: {img_data_array_loaded.shape}, Dtype: {img_data_array_loaded.dtype}"
            )

            logger.debug(f"  -> [2/7] V√©rification variance pour '{file_name}'...")
            std_dev = np.std(img_data_array_loaded)
            variance_threshold = 1e-4  # anciennement 0.0015
            if std_dev < variance_threshold:
                raise ValueError(
                    f"Faible variance: {std_dev:.4f} (seuil: {variance_threshold})."
                )
            logger.debug(f"     - Variance OK (std: {std_dev:.4f}).")

            logger.debug(f"  -> [3/7] Pr√©-traitement pour '{file_name}'...")
            prepared_img_after_initial_proc = img_data_array_loaded.astype(np.float32)
            logger.debug(
                f"     - (a) Apr√®s conversion float32: Range: [{np.min(prepared_img_after_initial_proc):.4g}, {np.max(prepared_img_after_initial_proc):.4g}]"
            )

            is_color_after_preprocessing = False
            if prepared_img_after_initial_proc.ndim == 2:
                bayer_pattern_from_header = header_final_pour_retour.get(
                    "BAYERPAT", self.bayer_pattern
                )
                pattern_upper = (
                    bayer_pattern_from_header.upper()
                    if isinstance(bayer_pattern_from_header, str)
                    else self.bayer_pattern.upper()
                )
                if pattern_upper in ["GRBG", "RGGB", "GBRG", "BGGR"]:
                    prepared_img_after_initial_proc = debayer_image(
                        prepared_img_after_initial_proc, pattern_upper
                    )
                    is_color_after_preprocessing = True
                    logger.debug(
                        f"     - (b) Image d√©bayeris√©e. Range: [{np.min(prepared_img_after_initial_proc):.4g}, {np.max(prepared_img_after_initial_proc):.4g}]"
                    )
            elif (
                prepared_img_after_initial_proc.ndim == 3
                and prepared_img_after_initial_proc.shape[2] == 3
            ):
                is_color_after_preprocessing = True
            else:
                raise ValueError(
                    f"Shape image {prepared_img_after_initial_proc.shape} non support√©e post-chargement."
                )

            if is_color_after_preprocessing:
                try:
                    r_ch, g_ch, b_ch = (
                        prepared_img_after_initial_proc[..., 0],
                        prepared_img_after_initial_proc[..., 1],
                        prepared_img_after_initial_proc[..., 2],
                    )
                    med_r, med_g, med_b = (
                        np.median(r_ch),
                        np.median(g_ch),
                        np.median(b_ch),
                    )
                    if med_g > 1e-6:
                        gain_r = np.clip(med_g / max(med_r, 1e-6), 0.5, 2.0)
                        gain_b = np.clip(med_g / max(med_b, 1e-6), 0.5, 2.0)
                        prepared_img_after_initial_proc[..., 0] *= gain_r
                        prepared_img_after_initial_proc[..., 2] *= gain_b
                    logger.debug(
                        f"     - (c) WB basique appliqu√©e. Range: [{np.min(prepared_img_after_initial_proc):.4g}, {np.max(prepared_img_after_initial_proc):.4g}]"
                    )
                except Exception as e_wb:
                    logger.debug(f"WARN QM [_process_file]: Erreur WB basique: {e_wb}")

            zoom_pct = getattr(self, "zoom_percent", 0)
            if isinstance(zoom_pct, (int, float)) and zoom_pct > 0:
                factor = 1.0 + zoom_pct / 100.0
                try:
                    h, w = prepared_img_after_initial_proc.shape[:2]
                    resized = cv2.resize(
                        prepared_img_after_initial_proc,
                        None,
                        fx=factor,
                        fy=factor,
                        interpolation=cv2.INTER_CUBIC,
                    )
                    center = (resized.shape[1] // 2, resized.shape[0] // 2)
                    prepared_img_after_initial_proc = cv2.getRectSubPix(
                        resized,
                        patchSize=(w, h),
                        center=center,
                    )
                except Exception as e_zoom:
                    logger.warning(f"Zoom ROI d√©sactiv√© (erreur : {e_zoom})")

            if self.correct_hot_pixels:
                prepared_img_after_initial_proc = detect_and_correct_hot_pixels(
                    prepared_img_after_initial_proc,
                    self.hot_pixel_threshold,
                    self.neighborhood_size,
                )
                logger.debug(
                    f"     - (d) Correction HP. Range: [{np.min(prepared_img_after_initial_proc):.4g}, {np.max(prepared_img_after_initial_proc):.4g}]"
                )

            is_drizzle_or_mosaic_mode = (
                self.drizzle_active_session or self.is_mosaic_run
            )
            logger.debug(
                f"     - (e) is_drizzle_or_mosaic_mode: {is_drizzle_or_mosaic_mode}"
            )

            image_for_alignment_or_drizzle_input = (
                prepared_img_after_initial_proc.copy()
            )
            logger.debug(
                f"     - (f) image_for_alignment_or_drizzle_input (copie de (d)) - Range: [{np.min(image_for_alignment_or_drizzle_input):.4g}, {np.max(image_for_alignment_or_drizzle_input):.4g}]"
            )

            current_max_val = np.nanmax(image_for_alignment_or_drizzle_input)
            if is_drizzle_or_mosaic_mode:
                if current_max_val <= 1.0 + 1e-5 and current_max_val > -1e-5:
                    logger.debug(
                        f"       - (g) DRIZZLE/MOSAIQUE: D√©tection plage [0,1] (max_val={current_max_val:.4g}). Rescale vers ADU 0-65535."
                    )
                    image_for_alignment_or_drizzle_input = (
                        image_for_alignment_or_drizzle_input * 65535.0
                    )
                    logger.debug(
                        f"         Nouveau range image_for_alignment_or_drizzle_input: [{np.min(image_for_alignment_or_drizzle_input):.4g}, {np.max(image_for_alignment_or_drizzle_input):.4g}]"
                    )
                image_for_alignment_or_drizzle_input = np.clip(
                    image_for_alignment_or_drizzle_input, 0.0, None
                )
                logger.debug(
                    f"     - (h) Pr√©-traitement final POUR DRIZZLE/MOSAIQUE: image_for_alignment_or_drizzle_input - Range: [{np.min(image_for_alignment_or_drizzle_input):.4g}, {np.max(image_for_alignment_or_drizzle_input):.4g}]"
                )
                data_final_pour_retour = image_for_alignment_or_drizzle_input.astype(
                    np.float32
                )
            else:
                logger.debug(
                    f"     - (g) STACKING CLASSIQUE: image_for_alignment_or_drizzle_input (pour alignement) - Range: [{np.min(image_for_alignment_or_drizzle_input):.4g}, {np.max(image_for_alignment_or_drizzle_input):.4g}]"
                )

            logger.debug(f"  -> [4/7] Alignement/R√©solution WCS pour '{file_name}'...")
            logger.debug(
                f"     - AVANT ALIGNEMENT: image_for_alignment_or_drizzle_input - Range: [{np.min(image_for_alignment_or_drizzle_input):.4g}, {np.max(image_for_alignment_or_drizzle_input):.4g}], Shape: {image_for_alignment_or_drizzle_input.shape}"
            )

            if (
                not solve_astrometry_for_this_file
                and self.is_mosaic_run
                and self.mosaic_alignment_mode
                in ["local_fast_fallback", "local_fast_only"]
            ):
                align_method_log_msg = "FastAligner_Attempted"
                fa_success = False
                if (
                    self.local_aligner_instance
                    and reference_image_data_for_alignment is not None
                ):
                    _, M_par_fa, fa_success = self.local_aligner_instance._align_image(
                        image_for_alignment_or_drizzle_input,
                        reference_image_data_for_alignment,
                        file_name,
                        fa_min_abs_matches_config,
                        fa_min_ransac_inliers_value_config,
                        fa_ransac_thresh_config,
                        0.15,
                        daofind_fwhm_config,
                        daofind_threshold_sigma_config,
                        max_stars_to_describe_config,
                    )
                    if fa_success and M_par_fa is not None:
                        align_method_log_msg = "FastAligner_Success"
                        matrice_M_calculee = M_par_fa
                        wcs_final_pour_retour = self.reference_wcs_object
                    else:
                        fa_success = False
                        align_method_log_msg = "FastAligner_Fail"
                else:
                    align_method_log_msg = "LocalAlign_Not_Attempted"
                if not fa_success and self.use_wcs_fallback_for_mosaic:
                    align_method_log_msg += "_Fallback_Attempted"
                    if self.astrometry_solver:
                        solver_settings_for_panel_fallback = {
                            "local_solver_preference": self.local_solver_preference,
                            "api_key": self.api_key,
                            "astap_path": self.astap_path,
                            "astap_data_dir": self.astap_data_dir,
                            "astap_search_radius": self.astap_search_radius,
                            "astap_downsample": self.astap_downsample,
                            "astap_sensitivity": self.astap_sensitivity,
                            "local_ansvr_path": self.local_ansvr_path,
                            "scale_est_arcsec_per_pix": self.reference_pixel_scale_arcsec,
                            "scale_tolerance_percent": 20,
                            "ansvr_timeout_sec": getattr(
                                self, "ansvr_timeout_sec", 120
                            ),
                            "astap_timeout_sec": getattr(
                                self, "astap_timeout_sec", 120
                            ),
                            "astrometry_net_timeout_sec": getattr(
                                self, "astrometry_net_timeout_sec", 300
                            ),
                        }
                        wcs_panel_solved_by_solver = None
                        try:
                            wcs_panel_solved_by_solver = self.astrometry_solver.solve(
                                file_path,
                                header_final_pour_retour,
                                solver_settings_for_panel_fallback,
                                True,
                            )
                        except Exception as e_s:
                            align_method_log_msg += f"_SolveError_{type(e_s).__name__}"
                        if (
                            wcs_panel_solved_by_solver
                            and wcs_panel_solved_by_solver.is_celestial
                        ):
                            align_method_log_msg = (
                                "FastAligner_Fail_Fallback_WCS_Success"
                            )
                            wcs_final_pour_retour = wcs_panel_solved_by_solver
                            matrice_M_calculee = self._calculate_M_from_wcs(
                                wcs_panel_solved_by_solver,
                                self.reference_wcs_object,
                                image_for_alignment_or_drizzle_input.shape[:2],
                            )
                            if matrice_M_calculee is None:
                                align_method_log_msg = (
                                    "FastAligner_Fail_Fallback_WCS_Matrix_Fail"
                                )
                                wcs_final_pour_retour = None
                        else:
                            if "_SolveError_" not in align_method_log_msg:
                                align_method_log_msg = (
                                    "FastAligner_Fail_Fallback_WCS_Fail"
                                )
                            wcs_final_pour_retour = None
                            matrice_M_calculee = None
                    else:
                        align_method_log_msg = "FastAligner_Fail_Fallback_NoSolver"
                        wcs_final_pour_retour = None
                        matrice_M_calculee = None
                elif not fa_success and not self.use_wcs_fallback_for_mosaic:
                    align_method_log_msg = "FastAligner_Fail_No_Fallback"
                    wcs_final_pour_retour = None
                    matrice_M_calculee = None
                # data_final_pour_retour a d√©j√† √©t√© mis √† image_for_alignment_or_drizzle_input (ADU) si mode drizzle/mosaic

            elif (
                solve_astrometry_for_this_file
                and self.is_mosaic_run
                and self.mosaic_alignment_mode == "astrometry_per_panel"
            ):
                align_method_log_msg = "Astrometry_Per_Panel_Attempted"
                if self.astrometry_solver:
                    solver_settings_for_this_panel = {
                        "local_solver_preference": self.local_solver_preference,
                        "api_key": self.api_key,
                        "astap_path": self.astap_path,
                        "astap_data_dir": self.astap_data_dir,
                        "astap_search_radius": self.astap_search_radius,
                        "astap_downsample": self.astap_downsample,
                        "astap_sensitivity": self.astap_sensitivity,
                        "local_ansvr_path": self.local_ansvr_path,
                        "scale_est_arcsec_per_pix": self.reference_pixel_scale_arcsec,
                        "scale_tolerance_percent": 20,
                        "ansvr_timeout_sec": getattr(self, "ansvr_timeout_sec", 120),
                        "astap_timeout_sec": getattr(self, "astap_timeout_sec", 120),
                        "astrometry_net_timeout_sec": getattr(
                            self, "astrometry_net_timeout_sec", 300
                        ),
                    }
                    wcs_final_pour_retour = self.astrometry_solver.solve(
                        file_path,
                        header_final_pour_retour,
                        solver_settings_for_this_panel,
                        True,
                    )
                    if wcs_final_pour_retour and wcs_final_pour_retour.is_celestial:
                        align_method_log_msg = "Astrometry_Per_Panel_Success"
                        matrice_M_calculee = np.array(
                            [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]], dtype=np.float32
                        )
                    else:
                        align_method_log_msg = "Astrometry_Per_Panel_Fail"
                        wcs_final_pour_retour = None
                        matrice_M_calculee = None
                else:
                    align_method_log_msg = "Astrometry_Per_Panel_NoSolver"
                    wcs_final_pour_retour = None
                    matrice_M_calculee = None
                # data_final_pour_retour a d√©j√† √©t√© mis √† image_for_alignment_or_drizzle_input (ADU)
            elif solve_astrometry_for_this_file and not self.is_mosaic_run:
                align_method_log_msg = "Astrometry_Single_Attempted"
                if self.astrometry_solver:
                    solver_settings_for_file = {
                        "local_solver_preference": self.local_solver_preference,
                        "api_key": self.api_key,
                        "astap_path": self.astap_path,
                        "astap_data_dir": self.astap_data_dir,
                        "astap_search_radius": self.astap_search_radius,
                        "astap_downsample": self.astap_downsample,
                        "astap_sensitivity": self.astap_sensitivity,
                        "local_ansvr_path": self.local_ansvr_path,
                        "scale_est_arcsec_per_pix": self.reference_pixel_scale_arcsec,
                        "scale_tolerance_percent": 20,
                        "ansvr_timeout_sec": getattr(self, "ansvr_timeout_sec", 120),
                        "astap_timeout_sec": getattr(self, "astap_timeout_sec", 120),
                        "astrometry_net_timeout_sec": getattr(
                            self, "astrometry_net_timeout_sec", 300
                        ),
                    }
                    wcs_final_pour_retour = self.astrometry_solver.solve(
                        file_path,
                        header_final_pour_retour,
                        solver_settings_for_file,
                        True,
                    )
                    if wcs_final_pour_retour and wcs_final_pour_retour.is_celestial:
                        align_method_log_msg = "Astrometry_Single_Success"
                    else:
                        align_method_log_msg = "Astrometry_Fail_And_Rejected"
                        self.update_progress(
                            f"   -> √âchec WCS pour '{file_name}'. Image rejet√©e (mode haute pr√©cision).",
                            "WARN",
                        )
                        raise RuntimeError(
                            f"√âchec astrom√©trie pour '{file_name}' et aucun fallback autoris√© en mode reprojection."
                        )
                else:
                    align_method_log_msg = "Astrometry_Single_NoSolver"
                    wcs_final_pour_retour = None
                matrice_M_calculee = None
                if data_final_pour_retour is None:
                    data_final_pour_retour = (
                        image_for_alignment_or_drizzle_input.astype(np.float32)
                    )
            else:
                align_method_log_msg = "Astroalign_Standard_Attempted"
                if reference_image_data_for_alignment is None:
                    raise RuntimeError("Image de r√©f√©rence Astroalign manquante.")

                aligned_img_astroalign, align_success_astroalign = (
                    self.aligner._align_image(
                        image_for_alignment_or_drizzle_input,
                        reference_image_data_for_alignment,
                        file_name,
                        force_same_shape_as_ref=True,
                    )
                )

                if align_success_astroalign and aligned_img_astroalign is not None:
                    align_method_log_msg = "Astroalign_Standard_Success"
                    logger.debug(
                        f"     - APR√àS ALIGNEMENT (Astroalign): aligned_img_astroalign - Range: [{np.min(aligned_img_astroalign):.4g}, {np.max(aligned_img_astroalign):.4g}], Shape: {aligned_img_astroalign.shape}, Dtype: {aligned_img_astroalign.dtype}"
                    )
                    data_final_pour_retour = aligned_img_astroalign.astype(np.float32)

                    if (
                        self.reproject_between_batches
                        and self.reference_wcs_object is not None
                    ):
                        # Attach the reference WCS so batches can be reprojected
                        wcs_final_pour_retour = self.reference_wcs_object

                    if not is_drizzle_or_mosaic_mode:
                        # In classic stacking mode, keep the aligned image as-is
                        pass
                    else:
                        # Pour Drizzle Standard, data_final_pour_retour est d√©j√† aligned_img_astroalign.
                        # _align_image est cens√© avoir pr√©serv√© la plage ADU si l'entr√©e √©tait ADU.
                        logger.debug(
                            f"       - DRIZZLE STANDARD: data_final_pour_retour (venant de aligned_img_astroalign) gard√© en ADU. Range: [{np.min(data_final_pour_retour):.4g}, {np.max(data_final_pour_retour):.4g}]"
                        )
                else:
                    align_method_log_msg = "Astroalign_Standard_Fail"
                    raise RuntimeError(
                        f"√âchec Alignement Astroalign standard pour {file_name}."
                    )
                matrice_M_calculee = None

            header_final_pour_retour["_ALIGN_METHOD_LOG"] = (
                align_method_log_msg,
                "Alignment method used",
            )

            logger.debug(
                f"  -> [5/7] Cr√©ation du masque de pixels valides pour '{file_name}'..."
            )
            if data_final_pour_retour is None:
                raise ValueError("Donn√©es finales pour masque sont None.")
            if data_final_pour_retour.ndim == 3:
                luminance_mask_src = (
                    0.299 * data_final_pour_retour[..., 0]
                    + 0.587 * data_final_pour_retour[..., 1]
                    + 0.114 * data_final_pour_retour[..., 2]
                )
            elif data_final_pour_retour.ndim == 2:
                luminance_mask_src = data_final_pour_retour
            else:
                valid_pixel_mask_2d = np.ones(
                    data_final_pour_retour.shape[:2], dtype=bool
                )
                logger.debug(f"     - Masque (tous valides, shape inattendue).")

            if "valid_pixel_mask_2d" not in locals() or valid_pixel_mask_2d is None:
                logger.debug(
                    f"     - Cr√©ation masque depuis luminance_mask_src. Range luminance: [{np.min(luminance_mask_src):.4g}, {np.max(luminance_mask_src):.4g}]"
                )
                max_lum_val = np.nanmax(luminance_mask_src)
                if max_lum_val <= 1e-5:
                    valid_pixel_mask_2d = np.ones(luminance_mask_src.shape, dtype=bool)
                    logger.debug(
                        "     - Luminance tr√®s faible, masque par d√©faut tout True."
                    )
                else:
                    mask_threshold = (
                        1.0
                        if (is_drizzle_or_mosaic_mode and max_lum_val > 1.5 + 1e-5)
                        else 1e-5
                    )  # +1e-5 pour float
                    valid_pixel_mask_2d = (luminance_mask_src > mask_threshold).astype(
                        bool
                    )
                    logger.debug(
                        f"     - Masque cr√©√© (seuil: {mask_threshold:.4g}). Shape: {valid_pixel_mask_2d.shape}, Dtype: {valid_pixel_mask_2d.dtype}, Sum (True): {np.sum(valid_pixel_mask_2d)}"
                    )

            logger.debug(f"  -> [6/7] Calcul des scores qualit√© pour '{file_name}'...")
            if self.use_quality_weighting:
                quality_scores = self._calculate_quality_metrics(
                    prepared_img_after_initial_proc
                )
            else:
                logger.debug(f"     - Pond√©ration qualit√© d√©sactiv√©e.")

            if data_final_pour_retour is None:
                raise RuntimeError(
                    "data_final_pour_retour est None √† la fin de _process_file."
                )
            if valid_pixel_mask_2d is None:
                raise RuntimeError(
                    "valid_pixel_mask_2d est None √† la fin de _process_file."
                )

            if self.is_mosaic_run and self.mosaic_alignment_mode in [
                "local_fast_fallback",
                "local_fast_only",
            ]:
                if wcs_final_pour_retour is None or matrice_M_calculee is None:
                    raise RuntimeError(
                        f"Mosa√Øque locale '{file_name}', WCS ou M manquant. AlignMethod: {align_method_log_msg}"
                    )
            elif (
                self.is_mosaic_run
                and self.mosaic_alignment_mode == "astrometry_per_panel"
            ):
                if wcs_final_pour_retour is None:
                    raise RuntimeError(
                        f"Mosa√Øque AstroPanel '{file_name}', WCS r√©solu manquant. AlignMethod: {align_method_log_msg}"
                    )

            # ---- ULTIMATE DEBUG LOG ----
            logger.debug(
                f"ULTIMATE DEBUG QM [_process_file V_ProcessFile_M81_Debug_UltimateLog_1]: AVANT RETURN pour '{file_name}'."
            )
            if data_final_pour_retour is not None:
                logger.debug(
                    f"  >>> data_final_pour_retour - Shape: {data_final_pour_retour.shape}, Dtype: {data_final_pour_retour.dtype}, Range: [{np.min(data_final_pour_retour):.6g}, {np.max(data_final_pour_retour):.6g}], Mean: {np.mean(data_final_pour_retour):.6g}"
                )
            else:
                logger.debug(f"  >>> data_final_pour_retour est None.")
            if valid_pixel_mask_2d is not None:
                logger.debug(
                    f"  >>> valid_pixel_mask_2d - Shape: {valid_pixel_mask_2d.shape}, Dtype: {valid_pixel_mask_2d.dtype}, Sum (True): {np.sum(valid_pixel_mask_2d)}"
                )
            else:
                logger.debug(f"  >>> valid_pixel_mask_2d est None.")
            logger.debug(f"  >>> quality_scores: {quality_scores}")
            if wcs_final_pour_retour is not None:
                logger.debug(f"  >>> wcs_final_pour_retour: Pr√©sent")
            else:
                logger.debug(f"  >>> wcs_final_pour_retour: None")
            if matrice_M_calculee is not None:
                logger.debug(f"  >>> matrice_M_calculee: Pr√©sente")
            else:
                logger.debug(f"  >>> matrice_M_calculee: None")
            # ---- FIN ULTIMATE DEBUG LOG ----

            return (
                data_final_pour_retour,
                header_final_pour_retour,
                quality_scores,
                wcs_final_pour_retour,
                matrice_M_calculee,
                valid_pixel_mask_2d,
            )

        except (ValueError, RuntimeError) as proc_err:
            self.update_progress(
                f"   ‚ö†Ô∏è Fichier '{file_name}' ignor√© dans _process_file: {proc_err}",
                "WARN",
            )
            logger.debug(
                f"ERREUR QM [_process_file V_ProcessFile_M81_Debug_UltimateLog_1]: (ValueError/RuntimeError) pour '{file_name}': {proc_err}"
            )
            header_final_pour_retour = (
                header_final_pour_retour
                if header_final_pour_retour is not None
                else fits.Header()
            )
            header_final_pour_retour["_ALIGN_METHOD_LOG"] = (
                f"Error_{type(proc_err).__name__}",
                "Processing file error",
            )
            if hasattr(self, "_move_to_unaligned"):
                self._move_to_unaligned(file_path)
            return None, header_final_pour_retour, quality_scores, None, None, None
        except Exception as e:
            self.update_progress(
                f"‚ùå Erreur critique traitement fichier {file_name} dans _process_file: {e}",
                "ERROR",
            )
            logger.debug(
                f"ERREUR QM [_process_file V_ProcessFile_M81_Debug_UltimateLog_1]: Exception g√©n√©rale pour '{file_name}': {e}"
            )
            traceback.print_exc(limit=3)
            header_final_pour_retour = (
                header_final_pour_retour
                if header_final_pour_retour is not None
                else fits.Header()
            )
            header_final_pour_retour["_ALIGN_METHOD_LOG"] = (
                f"CritError_{type(e).__name__}",
                "Critical processing error",
            )
            if hasattr(self, "_move_to_unaligned"):
                self._move_to_unaligned(file_path)
            return None, header_final_pour_retour, quality_scores, None, None, None
        finally:
            if img_data_array_loaded is not None:
                del img_data_array_loaded
            if prepared_img_after_initial_proc is not None:
                del prepared_img_after_initial_proc
            if image_for_alignment_or_drizzle_input is not None:
                del image_for_alignment_or_drizzle_input
            gc.collect()

    #############################################################################################################################

    def _process_completed_batch(
        self,
        batch_items_to_stack,
        current_batch_num,
        total_batches_est,
        reference_wcs_for_reprojection,
    ):
        """Traite un lot d'images compl√©t√© en mode classique SUM/W.

        La logique de reprojection est maintenant g√©r√©e directement dans
        ``_worker`` et n'est plus trait√©e ici.
        """

        num_items_in_this_batch = (
            len(batch_items_to_stack) if batch_items_to_stack else 0
        )
        logger.debug(
            f"DEBUG QM [_process_completed_batch (Classic SUM/W only)]: D√©but pour lot #{current_batch_num} "
            f"avec {num_items_in_this_batch} items."
        )

        if not batch_items_to_stack:
            self.update_progress(
                f"‚ö†Ô∏è Tentative de traiter un lot vide (Lot #{current_batch_num}). Ignor√©.",
                None,
            )
            return

        progress_info_log = f"(Lot {current_batch_num}/{total_batches_est if total_batches_est > 0 else '?'})"

        # --- LOGIQUE EXISTANTE POUR LE MODE CLASSIQUE (NON-REPROJECTION) ---
        self.update_progress(
            f"‚öôÔ∏è Traitement classique du batch {progress_info_log} ({num_items_in_this_batch} images)..."
        )
        stacked_batch_data_np, stack_info_header, batch_coverage_map_2d = (
            self._stack_batch(
                batch_items_to_stack, current_batch_num, total_batches_est
            )
        )

        if stacked_batch_data_np is not None and batch_coverage_map_2d is not None:
            batch_wcs = None
            try:
                batch_wcs = (
                    WCS(stack_info_header, naxis=2) if stack_info_header else None
                )
            except Exception:
                pass

            self._combine_batch_result(
                stacked_batch_data_np,
                stack_info_header,
                batch_coverage_map_2d,
                batch_wcs,
            )
            if hasattr(self.cumulative_sum_memmap, "flush"):
                self.cumulative_sum_memmap.flush()
            if hasattr(self.cumulative_wht_memmap, "flush"):
                self.cumulative_wht_memmap.flush()
            if not self.drizzle_active_session:
                self._update_preview_sum_w()
        else:
            num_failed_in_stack_batch = len(batch_items_to_stack)
            self.failed_stack_count += num_failed_in_stack_batch
            self.update_progress(
                f"‚ùå √âchec combinaison du lot {progress_info_log}. {num_failed_in_stack_batch} images ignor√©es.",
                None,
            )

        gc.collect()
        logger.debug(
            f"DEBUG QM [_process_completed_batch]: Fin pour lot #{current_batch_num}."
        )

    ##############################################################################################################################################

    # --- DANS LA CLASSE SeestarQueuedStacker DANS seestar/queuep/queue_manager.py ---

    def _save_drizzle_input_temp(self, aligned_data, header):
        """
        Sauvegarde une image align√©e (HxWx3 float32) dans le dossier temp Drizzle,
        en transposant en CxHxW et en INJECTANT l'OBJET WCS DE R√âF√âRENCE stock√©
        dans le header sauvegard√©.
        Les donn√©es `aligned_data` doivent √™tre dans la plage ADU finale souhait√©e.
        """
        if self.drizzle_temp_dir is None:
            self.update_progress("‚ùå Erreur interne: Dossier temp Drizzle non d√©fini.")
            return None
        os.makedirs(self.drizzle_temp_dir, exist_ok=True)
        if aligned_data.ndim != 3 or aligned_data.shape[2] != 3:
            self.update_progress(
                f"‚ùå Erreur interne: _save_drizzle_input_temp attend HxWx3, re√ßu {aligned_data.shape}"
            )
            return None
        if self.reference_wcs_object is None:
            self.update_progress(
                "‚ùå Erreur interne: Objet WCS de r√©f√©rence non disponible pour sauvegarde temp."
            )
            return None

        try:
            # Utiliser un nom de fichier qui inclut le nom original pour le d√©bogage du header EXPTIME
            original_filename_stem = "unknown_orig"
            if header and "_SRCFILE" in header:
                original_filename_stem = os.path.splitext(header["_SRCFILE"][0])[0]

            temp_filename = f"aligned_input_{self.aligned_files_count:05d}_{original_filename_stem}.fits"
            temp_filepath = os.path.join(self.drizzle_temp_dir, temp_filename)

            data_to_save = np.moveaxis(aligned_data, -1, 0).astype(
                np.float32
            )  # Doit √™tre ADU ici

            # ---- DEBUG: V√©rifier le range de ce qui est sauvegard√© ----
            logger.debug(
                f"    DEBUG QM [_save_drizzle_input_temp]: Sauvegarde FITS temp '{temp_filename}'. data_to_save (CxHxW) Range Ch0: [{np.min(data_to_save[0]):.4g}, {np.max(data_to_save[0]):.4g}]"
            )
            # ---- FIN DEBUG ----

            header_to_save = header.copy() if header else fits.Header()

            # Effacer WCS potentiellement incorrect du header original
            keys_to_remove = [
                "PC1_1",
                "PC1_2",
                "PC2_1",
                "PC2_2",
                "CD1_1",
                "CD1_2",
                "CD2_1",
                "CD2_2",
                "CRPIX1",
                "CRPIX2",
                "CRVAL1",
                "CRVAL2",
                "CTYPE1",
                "CTYPE2",
                "CUNIT1",
                "CUNIT2",
                "CDELT1",
                "CDELT2",
                "CROTA2",
                "EQUINOX",
                "RADESYS",
            ]  # RADESYS aussi car WCS ref l'aura
            for key in keys_to_remove:
                if key in header_to_save:
                    try:
                        del header_to_save[key]
                    except KeyError:
                        pass

            ref_wcs_header = self.reference_wcs_object.to_header(relax=True)
            header_to_save.update(ref_wcs_header)

            header_to_save["NAXIS"] = 3
            header_to_save["NAXIS1"] = aligned_data.shape[1]
            header_to_save["NAXIS2"] = aligned_data.shape[0]
            header_to_save["NAXIS3"] = 3
            if "CTYPE3" not in header_to_save:
                header_to_save["CTYPE3"] = "CHANNEL"

            # Assurer BITPIX = -32 pour float32
            header_to_save["BITPIX"] = -32
            if "BSCALE" in header_to_save:
                del header_to_save["BSCALE"]
            if "BZERO" in header_to_save:
                del header_to_save["BZERO"]

            hdu = fits.PrimaryHDU(data=data_to_save, header=header_to_save)
            hdul = fits.HDUList([hdu])
            hdul.writeto(
                temp_filepath, overwrite=True, checksum=False, output_verify="ignore"
            )
            hdul.close()
            return temp_filepath

        except Exception as e:
            temp_filename_for_error = (
                f"aligned_input_{self.aligned_files_count:05d}.fits"  # G√©n√©rique
            )
            self.update_progress(
                f"‚ùå Erreur sauvegarde fichier temp Drizzle {temp_filename_for_error}: {e}"
            )
            traceback.print_exc(limit=2)
            return None

    ###########################################################################################################################

    def _process_incremental_drizzle_batch(
        self,
        batch_temp_filepaths_list,
        current_batch_num=0,
        total_batches_est=0,
        weight_map_override=None,  # Not used in this version but kept for signature compatibility
    ):
        """
        [VRAI DRIZZLE INCR√âMENTAL] Traite un lot de fichiers temporaires en les ajoutant
        aux objets Drizzle persistants. Met √† jour l'aper√ßu apr√®s chaque image (ou lot).
        Version: V_True_Incremental_Driz_DebugM81_Scale_2_Full_EXTENDED_DEBUG_ULTRA
        """
        # --- LIGNE DE PRINT ULTRA-CRITIQUE ET UNIQUE ---
        print(
            f"\n======== D√âBUT M√âTHODE: _process_incremental_drizzle_batch (VERSION: {GLOBAL_DRZ_BATCH_VERSION_STRING_ULTRA_DEBUG}) - Lot #{current_batch_num} - Fichiers: {len(batch_temp_filepaths_list)} ========"
        )
        # --- FIN LIGNE DE PRINT ULTRA-CRITIQUE ---

        num_files_in_batch = len(batch_temp_filepaths_list)
        logger.debug(
            f"DEBUG QM [_process_incremental_drizzle_batch {GLOBAL_DRZ_BATCH_VERSION_STRING_ULTRA_DEBUG}]: D√©but Lot Drizzle Incr. VRAI #{current_batch_num} ({num_files_in_batch} fichiers)."
        )

        if not batch_temp_filepaths_list:
            self.update_progress(
                f"‚ö†Ô∏è Lot Drizzle Incr√©mental VRAI #{current_batch_num} vide. Ignor√©."
            )
            logger.debug(f"  Sortie: Lot #{current_batch_num} est vide.")
            return

        progress_info = f"(Lot {current_batch_num}/{total_batches_est if total_batches_est > 0 else '?'})"
        self.update_progress(
            f"üíß Traitement Drizzle Incr√©mental VRAI du lot {progress_info}..."
        )

        # --- V√âRIFICATIONS CRITIQUES ---
        if (
            not self.incremental_drizzle_objects
            or len(self.incremental_drizzle_objects) != 3
        ):
            self.update_progress(
                "‚ùå Erreur critique: Objets Drizzle persistants non initialis√©s pour mode Incr√©mental.",
                "ERROR",
            )
            self.processing_error = "Objets Drizzle Incr. non initialis√©s"
            self.stop_processing = True
            logger.debug(f"  Sortie ERREUR: Objets Drizzle non initialis√©s.")
            return
        if self.drizzle_output_wcs is None or self.drizzle_output_shape_hw is None:
            self.update_progress(
                "‚ùå Erreur critique: Grille de sortie Drizzle (WCS/Shape) non d√©finie pour mode Incr√©mental VRAI.",
                "ERROR",
            )
            self.processing_error = "Grille Drizzle non d√©finie (Incr VRAI)"
            self.stop_processing = True
            logger.debug(
                f"  Sortie ERREUR: Grille de sortie Drizzle (WCS/Shape) non d√©finie."
            )
            return
        logger.debug(
            f"  WCS de sortie cible (self.drizzle_output_wcs) : {self.drizzle_output_wcs.wcs.crval if self.drizzle_output_wcs and self.drizzle_output_wcs.wcs else 'Non d√©fini'}"
        )
        logger.debug(
            f"  Shape de sortie cible (self.drizzle_output_shape_hw) : {self.drizzle_output_shape_hw}"
        )
        logger.debug(
            f"  Param√®tres Drizzle : Kernel='{self.drizzle_kernel}', Pixfrac={self.drizzle_pixfrac}, Fillval='{self.drizzle_fillval}'"
        )
        logger.debug(
            f"  Reprojection entre lots (self.reproject_between_batches) : {self.reproject_between_batches}"
        )
        logger.debug(
            f"  WCS de r√©f√©rence (self.reference_wcs_object) : {'D√©fini' if self.reference_wcs_object else 'Non d√©fini'} (utilis√© si reproject_between_batches)"
        )

        num_output_channels = 3
        files_added_to_drizzle_this_batch = 0

        for i_file, temp_fits_filepath in enumerate(batch_temp_filepaths_list):
            if self.stop_processing:
                logger.debug(
                    f"  Arr√™t demand√©. Interruption du traitement du lot #{current_batch_num}."
                )
                break

            current_filename_for_log = os.path.basename(temp_fits_filepath)
            self.update_progress(
                f"   -> DrizIncrVrai: Ajout fichier {i_file+1}/{num_files_in_batch} ('{current_filename_for_log}') au Drizzle cumulatif...",
                None,
            )
            logger.debug(
                f"\n    === TRAITEMENT FICHIER: '{current_filename_for_log}' (Fichier {i_file+1}/{num_files_in_batch}) ==="
            )

            input_image_cxhxw = None
            input_header = None
            wcs_input_from_file = None
            pixmap_for_this_file = None  # Initialisation pour chaque fichier

            try:
                # --- √âTAPE 1: Chargement et validation du fichier temporaire ---
                logger.debug(
                    f"      [Step  1] Chargement FITS temporaire: '{current_filename_for_log}'"
                )
                with fits.open(temp_fits_filepath, memmap=False) as hdul:
                    if not hdul or len(hdul) == 0 or hdul[0].data is None:
                        raise IOError(f"FITS temp invalide/vide: {temp_fits_filepath}")

                    data_loaded = hdul[0].data
                    input_header = hdul[0].header
                    logger.debug(
                        f"        Donn√©es brutes charg√©es: Range [{np.min(data_loaded):.4g}, {np.max(data_loaded):.4g}], Shape: {data_loaded.shape}, Dtype: {data_loaded.dtype}"
                    )

                    if (
                        data_loaded.ndim == 3
                        and data_loaded.shape[0] == num_output_channels
                    ):
                        input_image_cxhxw = data_loaded.astype(np.float32)
                        logger.debug(
                            f"        input_image_cxhxw (apr√®s astype float32): Range [{np.min(input_image_cxhxw):.4g}, {np.max(input_image_cxhxw):.4g}]"
                        )
                    else:
                        raise ValueError(
                            f"Shape FITS temp {data_loaded.shape} non CxHxW comme attendu (attendu {num_output_channels}xHxW)."
                        )

                    with warnings.catch_warnings():
                        warnings.simplefilter("ignore")  # Ignore FITSFixedWarning
                        wcs_input_from_file = WCS(input_header, naxis=2)
                    if not wcs_input_from_file or not wcs_input_from_file.is_celestial:
                        raise ValueError(
                            "WCS non c√©leste ou invalide dans le fichier FITS temporaire."
                        )
                    logger.debug(
                        f"        WCS du fichier temp (Input WCS): CRVAL={wcs_input_from_file.wcs.crval if wcs_input_from_file.wcs else 'N/A'}, CDELT={wcs_input_from_file.wcs.cdelt if wcs_input_from_file.wcs else 'N/A'}"
                    )

                image_hwc = np.moveaxis(
                    input_image_cxhxw, 0, -1
                )  # Convertir CxHxW en HxWxC

                # --- √âTAPE 2: GESTION DE LA REPROJECTION INTER-BATCH ---
                target_shape_hw = (
                    self.drizzle_output_shape_hw
                )  # La forme finale de la sortie Drizzle
                wcs_for_pixmap = wcs_input_from_file
                input_shape_hw_current_file = image_hwc.shape[
                    :2
                ]  # La forme HxW de l'image ALIGN√âE (ou reprojet√©e)

                # Assuming reproject_to_reference_wcs is correctly implemented and imported
                if (
                    hasattr(self, "reproject_between_batches")
                    and self.reproject_between_batches
                    and hasattr(self, "reference_wcs_object")
                    and self.reference_wcs_object
                ):
                    # Added a check if reproject_to_reference_wcs is actually callable
                    from seestar.core.reprojection import (
                        reproject_to_reference_wcs as _reproject_func,
                    )

                    if _reproject_func:
                        logger.debug(
                            f"      [Step 2] Reprojection active. Reprojection de l'image vers WCS de r√©f√©rence..."
                        )
                        try:
                            self.update_progress(
                                f"‚û°Ô∏è [Reproject] Entr√©e dans reproject pour le batch {current_batch_num}/{total_batches_est}",
                                "INFO_DETAIL",
                            )
                            # Reprojeter l'image HWC vers le WCS de r√©f√©rence
                            reprojected_image_hwc = _reproject_func(  # Use the imported function
                                image_hwc,
                                wcs_input_from_file,
                                self.reference_wcs_object,
                                target_shape_hw,  # La forme de sortie de la reprojection est la forme cible de Drizzle
                            )
                            if reprojected_image_hwc is None:
                                raise RuntimeError(
                                    "reproject_to_reference_wcs a retourn√© None."
                                )

                            image_hwc = reprojected_image_hwc  # L'image √† traiter par Drizzle est maintenant reprojet√©e
                            wcs_for_pixmap = (
                                self.reference_wcs_object
                            )  # Le WCS √† utiliser pour le pixmap est celui de la r√©f√©rence
                            input_shape_hw_current_file = image_hwc.shape[
                                :2
                            ]  # La forme de l'image (maintenant reprojet√©e)

                            self.update_progress(
                                f"‚úÖ [Reproject] Batch {current_batch_num}/{total_batches_est} reproject√© vers r√©f√©rence (shape {target_shape_hw})",
                                "INFO_DETAIL",
                            )
                            logger.debug(
                                f"        Image apr√®s reprojection: Shape={image_hwc.shape}, Range=[{np.nanmin(image_hwc):.4g}, {np.nanmax(image_hwc):.4g}]"
                            )
                            logger.debug(
                                f"        WCS utilis√© pour pixmap (apr√®s reproj.): CRVAL={wcs_for_pixmap.wcs.crval if wcs_for_pixmap.wcs else 'N/A'}"
                            )
                        except Exception as e:
                            self.update_progress(
                                f"‚ö†Ô∏è [Reproject] Batch {current_batch_num} ignor√© : {type(e).__name__}: {e}",
                                "WARN",
                            )
                            logger.error(f"ERREUR REPROJECTION: {e}", exc_info=True)
                            continue  # Passe au fichier suivant si reprojection √©choue
                    else:
                        logger.warning(
                            f"        AVERTISSEMENT: reproject_to_reference_wcs n'est pas import√©/disponible. Reprojection ignor√©e."
                        )

                # --- √âTAPE 3: Calcul du Pixmap (mapping des pixels d'entr√©e vers la grille de sortie Drizzle) ---
                logger.debug(f"      [Step 3] Calcul du Pixmap pour mapping WCS...")
                y_in_coords_flat, x_in_coords_flat = np.indices(
                    input_shape_hw_current_file
                ).reshape(2, -1)

                # Convertir les coordonn√©es pixels de l'image d'entr√©e en coordonn√©es c√©lestes
                sky_ra_deg, sky_dec_deg = wcs_for_pixmap.all_pix2world(
                    x_in_coords_flat, y_in_coords_flat, 0
                )
                logger.debug(
                    f"        Coordonn√©es c√©lestes calcul√©es: RA_range=[{np.nanmin(sky_ra_deg):.4g}, {np.nanmax(sky_ra_deg):.4g}], Dec_range=[{np.nanmin(sky_dec_deg):.4g}, {np.nanmax(sky_dec_deg):.4g}]"
                )

                if not (
                    np.all(np.isfinite(sky_ra_deg)) and np.all(np.isfinite(sky_dec_deg))
                ):
                    raise ValueError(
                        "Coordonn√©es c√©lestes non finies obtenues depuis le WCS du fichier temporaire. Pixmap impossible."
                    )

                # Convertir les coordonn√©es c√©lestes en coordonn√©es pixels de la grille de sortie Drizzle (initialement avec origin=0)
                final_x_output_pixels, final_y_output_pixels = (
                    self.drizzle_output_wcs.all_world2pix(sky_ra_deg, sky_dec_deg, 0)
                )

                # Dimensions de la grille de sortie Drizzle
                height_out, width_out = self.drizzle_output_shape_hw

                # Diagnostic des bornes du pixmap initial (origin=0)
                min_x_initial, max_x_initial = np.nanmin(
                    final_x_output_pixels
                ), np.nanmax(final_x_output_pixels)
                min_y_initial, max_y_initial = np.nanmin(
                    final_y_output_pixels
                ), np.nanmax(final_y_output_pixels)
                logger.debug(
                    f"        Pixmap initial (origin=0) X range [{min_x_initial:.2f}, {max_x_initial:.2f}] vs [0,{width_out-1}]; Y range [{min_y_initial:.2f}, {max_y_initial:.2f}] vs [0,{height_out-1})"
                )
                print(
                    f"ULTRA-DEBUG: Pixmap initial (origin=0) X range [{min_x_initial:.2f}, {max_x_initial:.2f}] vs [0,{width_out-1}]; Y range [{min_y_initial:.2f}, {max_y_initial:.2f}] vs [0,{height_out-1})"
                )

                # RECALCUL AVEC origin=1 SI HORS BORNES (et correction en 0-based)
                # Cette condition est essentielle pour savoir si l'ajustement -1.0 doit √™tre appliqu√©.
                needs_origin1_recalc = (
                    min_x_initial < 0
                    or max_x_initial >= width_out
                    or min_y_initial < 0
                    or max_y_initial >= height_out
                )

                if needs_origin1_recalc:
                    logger.debug(
                        "      WARN [ProcIncrDrizLoop]: Pixmap initial (origin=0) en dehors de la plage attendue. Recalcul avec origin=1."
                    )
                    print(
                        "ULTRA-DEBUG: Pixmap initial (origin=0) is OUT OF BOUNDS. Recalculating with origin=1..."
                    )
                    final_x_output_pixels, final_y_output_pixels = (
                        self.drizzle_output_wcs.all_world2pix(
                            sky_ra_deg, sky_dec_deg, 1  # Recalcul avec origin=1
                        )
                    )
                    # --- FIX CRITIQUE : CONVERSION DE 1-BASED √Ä 0-BASED ---
                    final_x_output_pixels -= 1.0  # Convertir 1-based en 0-based
                    final_y_output_pixels -= 1.0  # Convertir 1-based en 0-based
                    logger.debug(
                        f"      DEBUG QM [ProcIncrDrizLoop]: Pixmap ajust√© (1-based vers 0-based) apr√®s recalcul avec origin=1."
                    )
                    print(
                        f"ULTRA-DEBUG: Pixmap ADJUSTED (1-based to 0-based). New min_x={np.nanmin(final_x_output_pixels):.2f}, min_y={np.nanmin(final_y_output_pixels):.2f}"
                    )
                    # --- FIN FIX CRITIQUE ---

                # --- V√©rification et nettoyage des NaN/Inf apr√®s tous les calculs ---
                if not (
                    np.all(np.isfinite(final_x_output_pixels))
                    and np.all(np.isfinite(final_y_output_pixels))
                ):
                    logger.debug(
                        f"      WARN [ProcIncrDrizLoop]: Pixmap pour '{current_filename_for_log}' contient NaN/Inf apr√®s projection (post-correction). Nettoyage..."
                    )
                    print(f"ULTRA-DEBUG: Pixmap contains NaN/Inf. Cleaning...")
                    final_x_output_pixels = np.nan_to_num(
                        final_x_output_pixels, nan=0.0, posinf=0.0, neginf=0.0
                    )  # Utilisez 0.0 pour les valeurs num√©riques
                    final_y_output_pixels = np.nan_to_num(
                        final_y_output_pixels, nan=0.0, posinf=0.0, neginf=0.0
                    )

                # Cr√©ation du pixmap final apr√®s tous les ajustements
                pixmap_for_this_file = np.dstack(
                    (
                        np.clip(
                            final_x_output_pixels.reshape(input_shape_hw_current_file),
                            0,
                            width_out - 1,
                        ),
                        np.clip(
                            final_y_output_pixels.reshape(input_shape_hw_current_file),
                            0,
                            height_out - 1,
                        ),
                    )
                ).astype(np.float32)

                # Diagnostic final du pixmap apr√®s clipping
                pix_x_final = pixmap_for_this_file[..., 0]
                pix_y_final = pixmap_for_this_file[..., 1]
                min_x_final, max_x_final = np.nanmin(pix_x_final), np.nanmax(
                    pix_x_final
                )
                min_y_final, max_y_final = np.nanmin(pix_y_final), np.nanmax(
                    pix_y_final
                )
                logger.debug(
                    f"      Final Pixmap X stats (post-clip): min={min_x_final:.2f}, max={max_x_final:.2f}, mean={np.nanmean(pix_x_final):.2f}, std={np.nanstd(pix_x_final):.2f}"
                )
                logger.debug(
                    f"      Final Pixmap Y stats (post-clip): min={min_y_final:.2f}, max={max_y_final:.2f}, mean={np.nanmean(pix_y_final):.2f}, std={np.nanstd(pix_y_final):.2f}"
                )
                logger.debug(
                    f"      Output Grid (width, height) for comparison: ({width_out}, {height_out})"
                )
                print(
                    f"ULTRA-DEBUG: Final Pixmap X stats (post-clip): min={min_x_final:.2f}, max={max_x_final:.2f}, mean={np.nanmean(pix_x_final):.2f}, std={np.nanstd(pix_x_final):.2f}"
                )
                print(
                    f"ULTRA-DEBUG: Final Pixmap Y stats (post-clip): min={min_y_final:.2f}, max={max_y_final:.2f}, mean={np.nanmean(pix_y_final):.2f}, std={np.nanstd(pix_y_final):.2f}"
                )

                # V√©rification critique des bornes du pixmap final
                assert (
                    min_x_final >= 0
                    and max_x_final < width_out
                    and min_y_final >= 0
                    and max_y_final < height_out
                ), "ERREUR PIXMAP: Pixmap final (post-clipping) hors bornes attendues!"

                # D√©tection d'un pixmap "plat" (tous les points mappent au m√™me endroit)
                if np.allclose(
                    pixmap_for_this_file[..., 0],
                    pixmap_for_this_file[0, 0, 0],
                    atol=1e-3,
                ) and np.allclose(
                    pixmap_for_this_file[..., 1],
                    pixmap_for_this_file[0, 0, 1],
                    atol=1e-3,
                ):
                    logger.warning(
                        "        WARN: All pixmap points map to (or very close to) a single output pixel! This indicates a severe WCS issue or extreme input image data where all points are projected to the same output pixel. No significant image will be drizzled."
                    )
                    print(
                        "ULTRA-DEBUG: WARNING: Pixmap is 'flat' - all points map to a single output pixel!"
                    )

                logger.debug(
                    f"      [Step 3] Pixmap calcul√© et valid√© pour '{current_filename_for_log}'."
                )

                # --- √âTAPE 4: Pr√©paration des param√®tres pour add_image ---
                logger.debug(
                    f"      [Step 4] Pr√©paration des param√®tres pour add_image..."
                )
                exptime_for_drizzle_add = 1.0
                in_units_for_drizzle_add = "cps"  # Par d√©faut

                if input_header and "EXPTIME" in input_header:
                    try:
                        original_exptime = float(input_header["EXPTIME"])
                        if original_exptime > 1e-6:
                            exptime_for_drizzle_add = original_exptime
                            in_units_for_drizzle_add = (
                                "counts"  # Si EXPTIME valide, on traite en counts
                            )
                            logger.debug(
                                f"        Utilisation EXPTIME={exptime_for_drizzle_add:.2f}s du header original ('{input_header.get('_SRCFILE', 'N/A_SRC')}'), in_units='counts'"
                            )
                        else:
                            logger.debug(
                                f"        EXPTIME du header original ({original_exptime:.2f}) trop faible. Utilisation exptime=1.0, in_units='cps'."
                            )
                    except (ValueError, TypeError):
                        logger.debug(
                            f"        AVERTISSEMENT: EXPTIME invalide dans header temp ('{input_header.get('EXPTIME')}' pour '{input_header.get('_SRCFILE', 'N/A_SRC')}'). Utilisation exptime=1.0, in_units='cps'."
                        )
                else:
                    logger.debug(
                        f"        AVERTISSEMENT: EXPTIME non trouv√© dans header temp pour '{input_header.get('_SRCFILE', 'N/A_SRC')}'. Utilisation exptime=1.0, in_units='cps'."
                    )

                if exptime_for_drizzle_add <= 0:  # Double-v√©rification de l'exptime
                    logger.warning(
                        f"        AVERTISSEMENT: EXPTIME={exptime_for_drizzle_add} non valide. Remplacement par 1.0."
                    )
                    exptime_for_drizzle_add = 1.0

                # Pr√©paration du weight_map pour add_image. Utilise weight_map_override si fourni
                if weight_map_override is not None:
                    weight_map_param_for_add = np.asarray(
                        weight_map_override, dtype=np.float32
                    )
                    if weight_map_param_for_add.shape != input_shape_hw_current_file:
                        logger.debug(
                            "        WARN: weight_map_override shape mismatch; using ones"
                        )
                        weight_map_param_for_add = np.ones(
                            input_shape_hw_current_file, dtype=np.float32
                        )
                else:
                    weight_map_param_for_add = np.ones(
                        input_shape_hw_current_file, dtype=np.float32
                    )
                logger.debug(
                    f"        Weight_map pour add_image: Shape={weight_map_param_for_add.shape}, Range=[{np.min(weight_map_param_for_add):.3f}, {np.max(weight_map_param_for_add):.3f}], Sum={np.sum(weight_map_param_for_add):.3f}"
                )

                # Pr√©-traitement de l'image (nettoyage NaN/Inf et clip > 0) AVANT de la passer √† add_image
                image_hwc_cleaned = np.nan_to_num(
                    np.clip(image_hwc, 0.0, None), nan=0.0, posinf=0.0, neginf=0.0
                ).astype(np.float32)
                logger.debug(
                    f"        Image HWC nettoy√©e (pour add_image): Range=[{np.min(image_hwc_cleaned):.4g}, {np.max(image_hwc_cleaned):.4g}], Mean={np.mean(image_hwc_cleaned):.4g}"
                )

                # --- √âTAPE 5: Appel √† add_image pour chaque canal ---
                logger.debug(
                    f"      [Step 5] Appel driz_obj.add_image pour chaque canal..."
                )
                for ch_idx in range(num_output_channels):
                    channel_data_2d = image_hwc_cleaned[..., ch_idx]

                    # Log des stats sp√©cifiques √† ce canal avant add_image
                    logger.debug(
                        f"        Ch{ch_idx} AVANT add_image: data range [{np.min(channel_data_2d):.3g}, {np.max(channel_data_2d):.3g}], mean={np.mean(channel_data_2d):.3g}"
                    )
                    logger.debug(
                        f"                          exptime={exptime_for_drizzle_add}, in_units='{in_units_for_drizzle_add}', pixfrac={self.drizzle_pixfrac}"
                    )
                    print(
                        f"ULTRA-DEBUG: Ch{ch_idx} CALLING add_image - data range [{np.min(channel_data_2d):.3g}, {np.max(channel_data_2d):.3g}], exptime={exptime_for_drizzle_add}, pixfrac={self.drizzle_pixfrac}, input_shape_hw={input_shape_hw_current_file}"
                    )

                    driz_obj = self.incremental_drizzle_objects[ch_idx]
                    wht_sum_before = float(np.sum(driz_obj.out_wht))
                    sci_sum_before = float(np.sum(driz_obj.out_img))
                    logger.debug(
                        f"        Ch{ch_idx} WHT_SUM BEFORE add_image: {wht_sum_before:.3f}"
                    )
                    logger.debug(
                        f"        Ch{ch_idx} SCI_SUM BEFORE add_image: {sci_sum_before:.3f}"
                    )
                    print(
                        f"ULTRA-DEBUG: Ch{ch_idx} Drizzle Obj state BEFORE add_image: out_wht_sum={wht_sum_before:.3f}, out_img_sum={sci_sum_before:.3f}"
                    )

                    # L'appel CRITIQUE √† add_image
                    nskip, nmiss = driz_obj.add_image(
                        data=channel_data_2d,
                        pixmap=pixmap_for_this_file,
                        exptime=exptime_for_drizzle_add,
                        in_units=in_units_for_drizzle_add,
                        pixfrac=self.drizzle_pixfrac,
                        weight_map=weight_map_param_for_add,
                    )
                    logger.debug(
                        f"        Ch{ch_idx} RETURNED from add_image: nskip={nskip}, nmiss={nmiss}"
                    )  # Log des retours de add_image
                    print(
                        f"ULTRA-DEBUG: Ch{ch_idx} add_image RETURNED: nskip={nskip}, nmiss={nmiss}"
                    )  # Print direct pour nskip/nmiss

                    wht_sum_after = float(np.sum(driz_obj.out_wht))
                    sci_sum_after = float(np.sum(driz_obj.out_img))
                    logger.debug(
                        f"        Ch{ch_idx} WHT_SUM AFTER add_image: {wht_sum_after:.3f} (Change: {wht_sum_after - wht_sum_before:.3f})"
                    )
                    logger.debug(
                        f"        Ch{ch_idx} SCI_SUM AFTER add_image: {sci_sum_after:.3f} (Change: {sci_sum_after - sci_sum_before:.3f})"
                    )
                    print(
                        f"ULTRA-DEBUG: Ch{ch_idx} Drizzle Obj state AFTER add_image: out_wht_sum={wht_sum_after:.3f}, out_img_sum={sci_sum_after:.3f}"
                    )

                    # V√©rification des assertions (maintenues)
                    assert (
                        wht_sum_after >= wht_sum_before - 1e-6
                    ), f"WHT sum decreased for Ch{ch_idx}!"
                    logger.debug(
                        f"        Ch{ch_idx} AFTER add_image: out_img range [{np.min(driz_obj.out_img):.3g}, {np.max(driz_obj.out_img):.3g}]"
                    )
                    logger.debug(
                        f"                             out_wht range [{np.min(driz_obj.out_wht):.3g}, {np.max(driz_obj.out_wht):.3g}]"
                    )

                files_added_to_drizzle_this_batch += 1
                self.images_in_cumulative_stack += 1
                logger.debug(
                    f"    === FIN TRAITEMENT FICHIER: '{current_filename_for_log}' (Ajout√©. Total files added: {self.images_in_cumulative_stack}) ==="
                )

            except Exception as e_file:
                self.update_progress(
                    f"      -> ERREUR Drizzle Incr. VRAI sur fichier '{current_filename_for_log}': {e_file}",
                    "WARN",
                )
                logger.error(
                    f"ERREUR QM [ProcIncrDrizLoop {GLOBAL_DRZ_BATCH_VERSION_STRING_ULTRA_DEBUG}]: √âchec fichier '{current_filename_for_log}': {e_file}",
                    exc_info=True,
                )
                print(
                    f"ULTRA-DEBUG: ERREUR NON-FATALE sur fichier '{current_filename_for_log}': {e_file}"
                )

            finally:
                # Nettoyage des variables locales (essentiel pour la m√©moire)
                del (
                    input_image_cxhxw,
                    input_header,
                    wcs_input_from_file,
                    pixmap_for_this_file,
                )
                if "image_hwc_cleaned" in locals():
                    del image_hwc_cleaned
                if "image_hwc" in locals():
                    del image_hwc  # original HxWxC
                if "reprojected_image_hwc" in locals():
                    del reprojected_image_hwc

                # Forcer un garbage collect de temps en temps, surtout si les images sont grandes
                if (i_file + 1) % 10 == 0:
                    gc.collect()

        # --- FIN DE LA BOUCLE DE TRAITEMENT DES FICHIERS ---
        if files_added_to_drizzle_this_batch == 0 and num_files_in_batch > 0:
            self.update_progress(
                f"   -> ERREUR: Aucun fichier du lot Drizzle Incr. VRAI #{current_batch_num} n'a pu √™tre ajout√©.",
                "ERROR",
            )
            self.failed_stack_count += num_files_in_batch
            logger.debug(
                f"  Sortie: Aucun fichier ajout√© au Drizzle cumulatif pour le lot #{current_batch_num}."
            )
        else:
            self.update_progress(
                f"   -> {files_added_to_drizzle_this_batch}/{num_files_in_batch} fichiers du lot Drizzle Incr. VRAI #{current_batch_num} ajout√©s aux objets Drizzle."
            )
            logger.debug(
                f"  Total fichiers ajout√©s au Drizzle cumulatif jusqu'√† pr√©sent: {self.images_in_cumulative_stack}."
            )

        # --- MISE √Ä JOUR DU HEADER DU STACK CUMULATIF ---
        if self.current_stack_header is None:
            self.current_stack_header = fits.Header()
            if self.drizzle_output_wcs:
                try:
                    self.current_stack_header.update(
                        self.drizzle_output_wcs.to_header(relax=True)
                    )
                except Exception as e_hdr_wcs:
                    logger.warning(
                        f"WARN: Erreur copie WCS au header (DrizIncrVrai init): {e_hdr_wcs}"
                    )
            self.current_stack_header["STACKTYP"] = (
                f"Drizzle_Incremental_True_{self.drizzle_scale:.0f}x",
                "True Incremental Drizzle",
            )
            self.current_stack_header["DRZSCALE"] = (
                self.drizzle_scale,
                "Drizzle scale factor",
            )
            self.current_stack_header["DRZKERNEL"] = (
                self.drizzle_kernel,
                "Drizzle kernel used",
            )
            self.current_stack_header["DRZPIXFR"] = (
                self.drizzle_pixfrac,
                "Drizzle pixfrac used",
            )
            self.current_stack_header["CREATOR"] = (
                "SeestarStacker_QM",
                "Processing Software",
            )

        self.current_stack_header["NIMAGES"] = (
            self.images_in_cumulative_stack,
            "Total images drizzled incrementally",
        )

        # --- MISE √Ä JOUR DE L'APER√áU ---
        self.update_progress(
            f"   -> Pr√©paration aper√ßu Drizzle Incr√©mental VRAI (Lot #{current_batch_num})..."
        )
        try:
            if self.preview_callback and self.incremental_drizzle_objects:
                avg_img_channels_preview = []
                # IMPORTANT: driz_obj.out_img contient SCI*WHT, driz_obj.out_wht contient WHT
                # Pour obtenir l'image moyenne, il faut diviser SCI*WHT par WHT.
                for c in range(num_output_channels):
                    driz_obj = self.incremental_drizzle_objects[c]

                    # Obtenir les donn√©es et poids cumulatifs
                    sci_accum = driz_obj.out_img.astype(np.float32)
                    wht_accum = driz_obj.out_wht.astype(np.float32)

                    # √âviter la division par z√©ro
                    wht_safe = np.maximum(wht_accum, 1e-9)

                    # Calculer l'image moyenne pour l'aper√ßu
                    preview_channel_data = np.zeros_like(sci_accum)
                    valid_pixels = (
                        wht_safe > 1e-8
                    )  # Masque pour les pixels o√π il y a eu contribution
                    with np.errstate(divide="ignore", invalid="ignore"):
                        preview_channel_data[valid_pixels] = (
                            sci_accum[valid_pixels] / wht_safe[valid_pixels]
                        )

                    avg_img_channels_preview.append(
                        np.nan_to_num(
                            preview_channel_data, nan=0.0, posinf=0.0, neginf=0.0
                        )
                    )

                preview_data_HWC_raw = np.stack(avg_img_channels_preview, axis=-1)

                # Normalisation de l'aper√ßu √† [0,1] pour l'affichage (cosm√©tique)
                min_p, max_p = np.nanmin(preview_data_HWC_raw), np.nanmax(
                    preview_data_HWC_raw
                )
                preview_data_HWC_norm = preview_data_HWC_raw
                if np.isfinite(min_p) and np.isfinite(max_p) and max_p > min_p + 1e-7:
                    preview_data_HWC_norm = (preview_data_HWC_raw - min_p) / (
                        max_p - min_p
                    )
                elif np.any(
                    np.isfinite(preview_data_HWC_raw)
                ):  # Image constante non nulle
                    preview_data_HWC_norm = np.full_like(preview_data_HWC_raw, 0.5)
                else:  # Image vide ou tout NaN/Inf
                    preview_data_HWC_norm = np.zeros_like(preview_data_HWC_raw)

                preview_data_HWC_final = np.clip(
                    preview_data_HWC_norm, 0.0, 1.0
                ).astype(np.float32)

                # Stocker l'image de pr√©visualisation (potentiellement pour usage UI)
                self.current_stack_data = preview_data_HWC_final
                self.cumulative_drizzle_data = preview_data_HWC_final  # Pour l'aper√ßu
                self._update_preview_incremental_drizzle()  # Appelle le callback GUI
                logger.debug(
                    f"    DEBUG QM [ProcIncrDrizLoop {GLOBAL_DRZ_BATCH_VERSION_STRING_ULTRA_DEBUG}]: Aper√ßu Driz Incr VRAI mis √† jour. Range (0-1): [{np.min(preview_data_HWC_final):.3f}, {np.max(preview_data_HWC_final):.3f}]"
                )
                print(
                    f"ULTRA-DEBUG: Aper√ßu Driz Incr VRAI mis √† jour. Range (0-1): [{np.min(preview_data_HWC_final):.3f}, {np.max(preview_data_HWC_final):.3f}]"
                )
            else:
                logger.debug(
                    f"    WARN QM [ProcIncrDrizLoop {GLOBAL_DRZ_BATCH_VERSION_STRING_ULTRA_DEBUG}]: Impossible de mettre √† jour l'aper√ßu Driz Incr VRAI (callback ou objets Drizzle manquants)."
                )
                print(
                    f"ULTRA-DEBUG: WARN: Impossible de mettre √† jour l'aper√ßu Driz Incr VRAI."
                )
        except Exception as e_prev:
            logger.error(
                f"    ERREUR QM [ProcIncrDrizLoop {GLOBAL_DRZ_BATCH_VERSION_STRING_ULTRA_DEBUG}]: Erreur mise √† jour aper√ßu Driz Incr VRAI: {e_prev}",
                exc_info=True,
            )
            print(f"ULTRA-DEBUG: ERREUR FATALE √† l'aper√ßu Driz Incr VRAI: {e_prev}")

        # --- NETTOYAGE DES FICHIERS TEMPORAIRES DU LOT ---
        if self.perform_cleanup:
            logger.debug(
                f"DEBUG QM [_process_incremental_drizzle_batch {GLOBAL_DRZ_BATCH_VERSION_STRING_ULTRA_DEBUG}]: Nettoyage fichiers temp lot #{current_batch_num}..."
            )
            print(f"ULTRA-DEBUG: Nettoyage fichiers temp lot #{current_batch_num}...")
            self._cleanup_batch_temp_files(batch_temp_filepaths_list)

        logger.debug(
            f"======== FIN M√âTHODE: _process_incremental_drizzle_batch (Lot #{current_batch_num} - {GLOBAL_DRZ_BATCH_VERSION_STRING_ULTRA_DEBUG}) ========\n"
        )
        print(
            f"======== FIN M√âTHODE: _process_incremental_drizzle_batch (Lot #{current_batch_num} - {GLOBAL_DRZ_BATCH_VERSION_STRING_ULTRA_DEBUG}) ========\n"
        )

    #################################################################################################################################################

    def _combine_drizzle_chunks(self, chunk_sci_files, chunk_wht_files):
        """
        Combine les fichiers chunks Drizzle (science et poids) sauvegard√©s sur disque.
        Lit les fichiers et effectue une moyenne pond√©r√©e.

        Args:
            chunk_sci_files (list): Liste des chemins vers les fichiers FITS science des chunks.
            chunk_wht_files (list): Liste des chemins vers les fichiers FITS poids des chunks.

        Returns:
            tuple: (final_sci_image, final_wht_map) ou (None, None) si √©chec.
                   Les tableaux retourn√©s sont au format HxWxC, float32.
        """
        if (
            not chunk_sci_files
            or not chunk_wht_files
            or len(chunk_sci_files) != len(chunk_wht_files)
        ):
            self.update_progress(
                "‚ùå Erreur interne: Listes de fichiers chunks invalides ou incoh√©rentes."
            )
            return None, None
        num_chunks = len(chunk_sci_files)
        if num_chunks == 0:
            self.update_progress("‚ìò Aucun chunk Drizzle √† combiner.")
            return None, None

        self.update_progress(f"‚öôÔ∏è Combinaison finale de {num_chunks} chunks Drizzle...")
        start_time = time.time()

        numerator_sum = None
        denominator_sum = None
        output_shape = None
        output_header = None
        first_chunk_processed_successfully = False

        try:
            # --- Boucle sur les chunks pour lire et accumuler ---
            for i, (sci_path, wht_path) in enumerate(
                zip(chunk_sci_files, chunk_wht_files)
            ):
                if self.stop_processing:
                    self.update_progress("üõë Arr√™t demand√© pendant combinaison chunks.")
                    return None, None
                self.update_progress(
                    f"   -> Lecture et accumulation chunk {i+1}/{num_chunks}..."
                )
                sci_chunk, wht_chunk = None, None
                sci_chunk_cxhxw, wht_chunk_cxhxw = None, None

                try:
                    # Lire Science Chunk
                    with fits.open(sci_path, memmap=False) as hdul_sci:
                        if not hdul_sci or hdul_sci[0].data is None:
                            raise IOError(f"Chunk science invalide: {sci_path}")
                        sci_chunk_cxhxw = hdul_sci[0].data
                        if sci_chunk_cxhxw.ndim != 3 or sci_chunk_cxhxw.shape[0] != 3:
                            raise ValueError(f"Chunk science {sci_path} non CxHxW.")
                        sci_chunk = np.moveaxis(sci_chunk_cxhxw, 0, -1).astype(
                            np.float32
                        )
                        if i == 0:
                            output_header = hdul_sci[0].header  # Garder header

                    # Lire Poids Chunk
                    with fits.open(wht_path, memmap=False) as hdul_wht:
                        if not hdul_wht or hdul_wht[0].data is None:
                            raise IOError(f"Chunk poids invalide: {wht_path}")
                        wht_chunk_cxhxw = hdul_wht[0].data
                        if wht_chunk_cxhxw.ndim != 3 or wht_chunk_cxhxw.shape[0] != 3:
                            raise ValueError(f"Chunk poids {wht_path} non CxHxW.")
                        wht_chunk = np.moveaxis(wht_chunk_cxhxw, 0, -1).astype(
                            np.float32
                        )

                    # Initialiser les accumulateurs
                    if numerator_sum is None:
                        output_shape = sci_chunk.shape
                        if output_shape is None:
                            raise ValueError("Shape du premier chunk est None.")
                        numerator_sum = np.zeros(
                            output_shape, dtype=np.float64
                        )  # float64 pour somme
                        denominator_sum = np.zeros(output_shape, dtype=np.float64)
                        logger.debug(
                            f"      - Initialisation accumulateurs (Shape: {output_shape})"
                        )
                        first_chunk_processed_successfully = True

                    # V√©rifier Shapes
                    if (
                        sci_chunk.shape != output_shape
                        or wht_chunk.shape != output_shape
                    ):
                        self.update_progress(
                            f"      -> ‚ö†Ô∏è Shape incoh√©rente chunk {i+1}. Ignor√©."
                        )
                        continue

                    # --- Accumulation ---
                    sci_chunk_clean = np.nan_to_num(sci_chunk, nan=0.0)
                    wht_chunk_clean = np.nan_to_num(wht_chunk, nan=0.0)
                    wht_chunk_clean = np.maximum(wht_chunk_clean, 0.0)
                    numerator_sum += sci_chunk_clean * wht_chunk_clean
                    denominator_sum += wht_chunk_clean
                    # --- Fin Accumulation ---

                except (FileNotFoundError, IOError, ValueError) as read_err:
                    self.update_progress(
                        f"      -> ‚ùå ERREUR lecture/validation chunk {i+1}: {read_err}. Ignor√©."
                    )
                    if i == 0:
                        first_chunk_processed_successfully = False
                        continue
                finally:
                    del sci_chunk, wht_chunk, sci_chunk_cxhxw, wht_chunk_cxhxw
                    if (i + 1) % 5 == 0:
                        gc.collect()
            # --- Fin Boucle Chunks ---

            if not first_chunk_processed_successfully or numerator_sum is None:
                raise RuntimeError(
                    "Aucun chunk valide n'a pu √™tre lu pour initialiser la combinaison."
                )

            # --- Calcul final ---
            self.update_progress("   -> Calcul de l'image finale combin√©e...")
            epsilon = 1e-12
            final_sci_combined = np.zeros_like(numerator_sum, dtype=np.float32)
            valid_mask = denominator_sum > epsilon
            with np.errstate(divide="ignore", invalid="ignore"):
                final_sci_combined[valid_mask] = (
                    numerator_sum[valid_mask] / denominator_sum[valid_mask]
                )
            final_sci_combined = np.nan_to_num(
                final_sci_combined, nan=0.0, posinf=0.0, neginf=0.0
            ).astype(np.float32)
            final_wht_combined = denominator_sum.astype(np.float32)
            # --- Fin Calcul ---

        except MemoryError:
            self.update_progress("‚ùå ERREUR M√âMOIRE pendant combinaison chunks.")
            traceback.print_exc(limit=1)
            return None, None
        except Exception as e:
            self.update_progress(
                f"‚ùå Erreur inattendue pendant combinaison chunks: {e}"
            )
            traceback.print_exc(limit=2)
            return None, None

        if final_sci_combined is None or final_wht_combined is None:
            self.update_progress("‚ùå Combinaison chunks n'a produit aucun r√©sultat.")
            return None, None

        end_time = time.time()
        self.update_progress(
            f"‚úÖ Combinaison chunks termin√©e en {end_time - start_time:.2f}s."
        )
        return final_sci_combined, final_wht_combined

    ###############################################################################################################################################

    def _combine_batch_result(
        self,
        stacked_batch_data_np,
        stack_info_header,
        batch_coverage_map_2d,
        batch_wcs=None,
    ):
        """
        [MODE SUM/W - CLASSIQUE] Accumule le r√©sultat d'un batch classique
        (image moyenne du lot et sa carte de couverture/poids 2D)
        dans les accumulateurs memmap globaux SUM et WHT.

        Args:
            stacked_batch_data_np (np.ndarray): Image MOYENNE du lot (HWC ou HW, float32, m√™me √©chelle que les entr√©es).
            stack_info_header (fits.Header): En-t√™te info du lot (contient NIMAGES physiques).
            batch_coverage_map_2d (np.ndarray): Carte de poids/couverture 2D (HW, float32)
                                                pour ce lot sp√©cifique.
        """
        logger.debug(
            f"DEBUG QM [_combine_batch_result SUM/W]: D√©but accumulation lot classique avec carte de couverture 2D."
        )
        current_batch_num = self.stacked_batches_count
        if batch_coverage_map_2d is not None:
            logger.debug(
                f"  -> Re√ßu de _stack_batch -> batch_coverage_map_2d - Shape: {batch_coverage_map_2d.shape}, "
                f"Range: [{np.min(batch_coverage_map_2d):.2f}-{np.max(batch_coverage_map_2d):.2f}], "
                f"Mean: {np.mean(batch_coverage_map_2d):.2f}"
            )
        else:
            logger.debug(
                f"  -> Re√ßu de _stack_batch -> batch_coverage_map_2d est None."
            )

        # --- V√©rifications initiales ---

        if (
            stacked_batch_data_np is None
            or stack_info_header is None
            or batch_coverage_map_2d is None
        ):
            self.update_progress(
                f"‚ö†Ô∏è Accumulation lot #{current_batch_num} ignor√©e: donn√©es ou couverture manquantes.",
                "WARN",
            )
            logger.debug(
                "DEBUG QM [_combine_batch_result SUM/W]: Sortie pr√©coce (donn√©es batch/couverture invalides) "
                f"stacked_batch_data_np is None? {stacked_batch_data_np is None}, "
                f"header is None? {stack_info_header is None}, "
                f"coverage is None? {batch_coverage_map_2d is None}"
            )
            return

        if (
            self.cumulative_sum_memmap is None
            or self.cumulative_wht_memmap is None
            or self.memmap_shape is None
        ):
            self.update_progress(
                f"‚ùå Accumulation lot #{current_batch_num} impossible: memmap SUM/WHT non initialis√©s.",
                "ERROR",
            )
            logger.debug(
                f"ERREUR QM [_combine_batch_result SUM/W]: Memmap non initialis√©. "
                f"cumulative_sum_memmap is None? {self.cumulative_sum_memmap is None}, "
                f"cumulative_wht_memmap is None? {self.cumulative_wht_memmap is None}, "
                f"memmap_shape is None? {self.memmap_shape is None}"
            )
            self.processing_error = "Memmap non initialis√©"
            self.stop_processing = True
            return

        # --- Ajustement dynamique de la taille des memmaps si n√©cessaire ---
        incoming_shape_hw = (
            stacked_batch_data_np.shape[:2]
            if stacked_batch_data_np.ndim >= 2
            else self.memmap_shape[:2]
        )
        current_shape_hw = self.memmap_shape[:2]
        if (
            incoming_shape_hw[0] > current_shape_hw[0]
            or incoming_shape_hw[1] > current_shape_hw[1]
        ):
            logger.debug(
                "DEBUG QM [_combine_batch_result]: incoming image larger than memmap, reallocating"
            )
            self._close_memmaps()
            self._create_sum_wht_memmaps(incoming_shape_hw)

        # V√©rifier la coh√©rence des shapes
        # stacked_batch_data_np peut √™tre HWC ou HW. memmap_shape est HWC.
        # batch_coverage_map_2d doit √™tre HW.

        expected_shape_hw = self.memmap_shape[:2]

        try:
            logger.debug(
                f"DEBUG QM [_combine_batch_result]: stacked_batch_data_np shape={stacked_batch_data_np.shape}, "
                f"min={np.min(stacked_batch_data_np):.3f}, max={np.max(stacked_batch_data_np):.3f}"
            )
            logger.debug(
                f"DEBUG QM [_combine_batch_result]: batch_coverage_map_2d shape={batch_coverage_map_2d.shape}, "
                f"min={np.min(batch_coverage_map_2d):.3f}, max={np.max(batch_coverage_map_2d):.3f}"
            )
        except Exception as dbg_err:
            logger.debug(
                f"DEBUG QM [_combine_batch_result]: erreur stats initiales: {dbg_err}"
            )

        if self.reproject_between_batches:
            input_wcs = batch_wcs
            if input_wcs is None and self.reference_wcs_object:
                try:
                    input_wcs = WCS(stack_info_header, naxis=2)
                except Exception:
                    input_wcs = None

            if self.reference_wcs_object and input_wcs is not None:
                try:
                    self.update_progress(
                        f"‚û°Ô∏è [Reproject] Reprojection du lot empil√© {self.stacked_batches_count}/{self.total_batches_estimated}",
                        "INFO_DETAIL",
                    )
                    stacked_batch_data_np, _ = self._reproject_to_reference(
                        stacked_batch_data_np, input_wcs
                    )
                    batch_coverage_map_2d, _ = self._reproject_to_reference(
                        batch_coverage_map_2d, input_wcs
                    )
                    self.update_progress(
                        f"‚úÖ [Reproject] Lot {self.stacked_batches_count}/{self.total_batches_estimated} reproject√© vers r√©f√©rence (shape {expected_shape_hw})",
                        "INFO_DETAIL",
                    )
                except Exception as e:
                    self.update_progress(
                        f"‚ö†Ô∏è [Reproject] Batch {self.stacked_batches_count} ignor√© : {type(e).__name__}: {e}",
                        "WARN",
                    )
            else:
                self.update_progress(
                    f"‚ÑπÔ∏è [Reproject] Ignor√© pour le lot {self.stacked_batches_count} (enable={self.reproject_between_batches}, ref={bool(self.reference_wcs_object)}, wcs={'ok' if input_wcs is not None else 'none'})",
                    "INFO_DETAIL",
                )

        if batch_coverage_map_2d.shape != expected_shape_hw:
            handled_cov = False
            if batch_coverage_map_2d.shape == expected_shape_hw[::-1]:
                batch_coverage_map_2d = batch_coverage_map_2d.T
                handled_cov = True
                logger.debug(
                    "DEBUG QM [_combine_batch_result]: transposed coverage map to match memmap_shape"
                )
            if not handled_cov:
                self.update_progress(
                    f"‚ùå Batch #{current_batch_num} ignor√©: shape carte couverture {batch_coverage_map_2d.shape} au lieu de {expected_shape_hw}.",
                    "ERROR",
                )
                logger.debug(
                    f"ERREUR QM [_combine_batch_result SUM/W]: Incompatibilit√© shape carte couverture lot. "
                    f"expected={expected_shape_hw}, got={batch_coverage_map_2d.shape}"
                )
                try:
                    batch_n_error = int(stack_info_header.get("NIMAGES", 1))
                    self.failed_stack_count += batch_n_error
                except:
                    self.failed_stack_count += 1  # Au moins une image
                return

        # S'assurer que stacked_batch_data_np a la bonne dimension pour la multiplication (HWC ou HW)
        is_color_batch_data = (
            stacked_batch_data_np.ndim == 3 and stacked_batch_data_np.shape[2] == 3
        )
        if is_color_batch_data and stacked_batch_data_np.shape != self.memmap_shape:
            handled_img = False
            if stacked_batch_data_np.shape[:2] == self.memmap_shape[:2][::-1]:
                stacked_batch_data_np = stacked_batch_data_np.transpose(1, 0, 2)
                handled_img = True
                logger.debug(
                    "DEBUG QM [_combine_batch_result]: transposed stacked_batch_data_np from WHC to HWC"
                )
            elif (
                stacked_batch_data_np.shape[0] == 3
                and stacked_batch_data_np.shape[1:] == self.memmap_shape[:2]
            ):
                stacked_batch_data_np = stacked_batch_data_np.transpose(1, 2, 0)
                handled_img = True
                logger.debug(
                    "DEBUG QM [_combine_batch_result]: rearranged stacked_batch_data_np from CHW to HWC"
                )
            if not handled_img:
                self.update_progress(
                    f"‚ùå Batch #{current_batch_num} ignor√©: image couleur shape {stacked_batch_data_np.shape} au lieu de {self.memmap_shape}.",
                    "ERROR",
                )
                logger.debug(
                    f"ERREUR QM [_combine_batch_result SUM/W]: Incompatibilit√© shape image lot (couleur). "
                    f"expected={self.memmap_shape}, got={stacked_batch_data_np.shape}"
                )
                try:
                    batch_n_error = int(stack_info_header.get("NIMAGES", 1))
                    self.failed_stack_count += batch_n_error
                except:
                    self.failed_stack_count += 1
                return
        elif (
            not is_color_batch_data
            and stacked_batch_data_np.ndim == 2
            and stacked_batch_data_np.shape != expected_shape_hw
        ):
            handled_gray = False
            if stacked_batch_data_np.shape == expected_shape_hw[::-1]:
                stacked_batch_data_np = stacked_batch_data_np.T
                handled_gray = True
                logger.debug(
                    "DEBUG QM [_combine_batch_result]: transposed gray image to match memmap_shape"
                )
            if not handled_gray:
                self.update_progress(
                    f"‚ùå Batch #{current_batch_num} ignor√©: image N&B shape {stacked_batch_data_np.shape} au lieu de {expected_shape_hw}.",
                    "ERROR",
                )
                logger.debug(
                    f"ERREUR QM [_combine_batch_result SUM/W]: Incompatibilit√© shape image lot (N&B). "
                    f"expected={expected_shape_hw}, got={stacked_batch_data_np.shape}"
                )
                try:
                    batch_n_error = int(stack_info_header.get("NIMAGES", 1))
                    self.failed_stack_count += batch_n_error
                except:
                    self.failed_stack_count += 1
                return
        elif (
            not is_color_batch_data and stacked_batch_data_np.ndim != 2
        ):  # Cas N&B mais pas 2D
            self.update_progress(
                f"‚ùå Batch #{current_batch_num} ignor√©: dimensions image N&B inattendues {stacked_batch_data_np.shape}.",
                "ERROR",
            )
            logger.debug(
                f"ERREUR QM [_combine_batch_result SUM/W]: Shape image lot N&B inattendue - got {stacked_batch_data_np.shape}"
            )
            try:
                batch_n_error = int(stack_info_header.get("NIMAGES", 1))
                self.failed_stack_count += batch_n_error
            except:
                self.failed_stack_count += 1
            return

        try:
            num_physical_images_in_batch = int(stack_info_header.get("NIMAGES", 1))
            batch_exposure = float(stack_info_header.get("TOTEXP", 0.0))

            # V√©rifier si la carte de couverture a des poids significatifs

            if (
                np.sum(batch_coverage_map_2d) < 1e-6
                and num_physical_images_in_batch > 0
            ):
                self.update_progress(
                    f"‚ö†Ô∏è Batch #{current_batch_num} ignor√©: somme de couverture quasi nulle ({np.sum(batch_coverage_map_2d):.3e}).",
                    "WARN",
                )
                logger.debug(
                    f"DEBUG QM [_combine_batch_result SUM/W]: Sortie pr√©coce (somme couverture quasi nulle). "
                    f"sum={np.sum(batch_coverage_map_2d):.3e}"
                )
                self.failed_stack_count += num_physical_images_in_batch  # Compter ces images comme √©chec d'empilement
                return

            # Pr√©parer les donn√©es pour l'accumulation (types et shapes)
            # stacked_batch_data_np est d√©j√† en float32
            # batch_coverage_map_2d est d√©j√† float32

            # Calculer le signal total √† ajouter √† SUM: ImageMoyenneDuLot * SaCarteDeCouverturePond√©r√©e
            # Si stacked_batch_data_np est HWC et batch_coverage_map_2d est HW, il faut broadcaster.
            signal_to_add_to_sum_float64 = (
                None  # Utiliser float64 pour la multiplication et l'accumulation
            )
            if is_color_batch_data:  # Image couleur HWC
                signal_to_add_to_sum_float64 = (
                    stacked_batch_data_np.astype(np.float64)
                    * batch_coverage_map_2d.astype(np.float64)[:, :, np.newaxis]
                )
            else:  # Image N&B HW
                # Si SUM memmap est HWC (ce qui est le cas avec memmap_shape), il faut adapter
                if self.memmap_shape[2] == 3:  # Si l'accumulateur global est couleur
                    # On met l'image N&B dans les 3 canaux de l'accumulateur
                    temp_hwc = np.stack([stacked_batch_data_np] * 3, axis=-1)
                    signal_to_add_to_sum_float64 = (
                        temp_hwc.astype(np.float64)
                        * batch_coverage_map_2d.astype(np.float64)[:, :, np.newaxis]
                    )
                else:  # Si l'accumulateur global est N&B (ne devrait pas arriver avec memmap_shape HWC)
                    signal_to_add_to_sum_float64 = stacked_batch_data_np.astype(
                        np.float64
                    ) * batch_coverage_map_2d.astype(np.float64)

            logger.debug(
                f"DEBUG QM [_combine_batch_result SUM/W]: Accumulation pour {num_physical_images_in_batch} images physiques."
            )
            logger.debug(
                f"  -> signal_to_add_to_sum_float64 - Shape: {signal_to_add_to_sum_float64.shape}, "
                f"Range: [{np.min(signal_to_add_to_sum_float64):.2f} - {np.max(signal_to_add_to_sum_float64):.2f}], "
                f"Mean: {np.mean(signal_to_add_to_sum_float64):.2f}"
            )

            batch_sum = signal_to_add_to_sum_float64.astype(np.float32)
            batch_wht = batch_coverage_map_2d.astype(np.float32)

            pre_sum_min = float(np.min(self.cumulative_sum_memmap))
            pre_sum_max = float(np.max(self.cumulative_sum_memmap))
            pre_wht_min = float(np.min(self.cumulative_wht_memmap))
            pre_wht_max = float(np.max(self.cumulative_wht_memmap))

            # Ensure shapes match exactly to avoid silent broadcasting
            if batch_sum.shape != tuple(self.memmap_shape):
                self.update_progress(
                    f"‚ö†Ô∏è Batch #{current_batch_num} shape {batch_sum.shape} incompatible with memmap {self.memmap_shape}.",
                    "WARN",
                )
                batch_sum = batch_sum.reshape(self.memmap_shape)
            if batch_wht.shape != tuple(self.memmap_shape[:2]):
                self.update_progress(
                    f"‚ö†Ô∏è Batch #{current_batch_num} coverage shape {batch_wht.shape} incompatible with memmap {self.memmap_shape[:2]}",
                    "WARN",
                )
                batch_wht = batch_wht.reshape(self.memmap_shape[:2])

            self.cumulative_sum_memmap[:] += batch_sum.astype(self.memmap_dtype_sum)
            self.cumulative_wht_memmap[:] += batch_wht.astype(self.memmap_dtype_wht)
            if hasattr(self.cumulative_sum_memmap, "flush"):
                self.cumulative_sum_memmap.flush()
            if hasattr(self.cumulative_wht_memmap, "flush"):
                self.cumulative_wht_memmap.flush()
            try:
                post_sum_min = float(np.min(self.cumulative_sum_memmap))
                post_sum_max = float(np.max(self.cumulative_sum_memmap))
                post_wht_min = float(np.min(self.cumulative_wht_memmap))
                post_wht_max = float(np.max(self.cumulative_wht_memmap))
                logger.debug(
                    f"DEBUG QM [_combine_batch_result SUM/W]: after += flush -> SUM min={post_sum_min:.3f}, max={post_sum_max:.3f}; "
                    f"WHT min={post_wht_min:.3f}, max={post_wht_max:.3f}"
                )
                logger.debug(
                    f"DEBUG QM [_combine_batch_result]: memmap change SUM {pre_sum_min:.3f}->{post_sum_min:.3f}, {pre_sum_max:.3f}->{post_sum_max:.3f}; "
                    f"WHT {pre_wht_min:.3f}->{post_wht_min:.3f}, {pre_wht_max:.3f}->{post_wht_max:.3f}"
                )
                if np.isclose(pre_sum_min, post_sum_min) and np.isclose(
                    pre_sum_max, post_sum_max
                ):
                    warn_msg = (
                        f"‚ö†Ô∏è Batch #{current_batch_num} addition produced no change to cumulative SUM. "
                        "Possible dtype/broadcast issue."
                    )
                    logger.debug(
                        "WARNING QM [_combine_batch_result]: cumulative SUM memmap unchanged after +=, possible dtype/broadcasting issue"
                    )
                    self.update_progress(warn_msg, "WARN")
            except Exception as dbg_e:
                logger.debug(
                    f"DEBUG QM [_combine_batch_result SUM/W]: erreur stats apres += : {dbg_e}"
                )
            logger.debug(
                "DEBUG QM [_combine_batch_result SUM/W]: Addition SUM/WHT termin√©e."
            )

            try:
                sum_min = float(np.min(self.cumulative_sum_memmap))
                sum_max = float(np.max(self.cumulative_sum_memmap))
                wht_min = float(np.min(self.cumulative_wht_memmap))
                wht_max = float(np.max(self.cumulative_wht_memmap))
                self.update_progress(
                    f"‚ÑπÔ∏è SUM min={sum_min:.2f}, max={sum_max:.2f}",
                    "INFO_DETAIL",
                )
                self.update_progress(
                    f"‚ÑπÔ∏è WHT min={wht_min:.2f}, max={wht_max:.2f}",
                    "INFO_DETAIL",
                )
                if np.allclose(self.cumulative_wht_memmap, 0.0):
                    self.update_progress(
                        "‚ö†Ô∏è Carte de poids cumul√©e enti√®rement nulle", "WARN"
                    )
                    warnings.warn("Cumulative weight map sums to zero", UserWarning)
            except Exception as e:
                self.update_progress(f"‚ö†Ô∏è Erreur calcul stats stack: {e}", "WARN")

            # Mise √† jour des compteurs globaux

            self.images_in_cumulative_stack += (
                num_physical_images_in_batch  # Compte les images physiques
            )
            self.total_exposure_seconds += batch_exposure
            logger.debug(
                f"DEBUG QM [_combine_batch_result SUM/W]: {num_physical_images_in_batch} images ajout√©es -> "
                f"images_in_cumulative_stack={self.images_in_cumulative_stack}"
            )
            logger.debug(
                f"DEBUG QM [_combine_batch_result SUM/W]: Compteurs mis √† jour: images_in_cumulative_stack={self.images_in_cumulative_stack}, total_exposure_seconds={self.total_exposure_seconds:.1f}"
            )
            self.update_progress(
                f"üìä images_in_cumulative_stack={self.images_in_cumulative_stack}",
                "INFO_DETAIL",
            )

            # --- Mise √† jour Header Cumulatif (comme avant) ---
            if self.current_stack_header is None:
                self.current_stack_header = fits.Header()
                first_header_from_batch = stack_info_header
                keys_to_copy = [
                    "INSTRUME",
                    "TELESCOP",
                    "OBJECT",
                    "FILTER",
                    "DATE-OBS",
                    "GAIN",
                    "OFFSET",
                    "CCD-TEMP",
                    "RA",
                    "DEC",
                    "SITELAT",
                    "SITELONG",
                    "FOCALLEN",
                    "BAYERPAT",
                ]
                for key_iter in keys_to_copy:
                    if first_header_from_batch and key_iter in first_header_from_batch:
                        try:
                            self.current_stack_header[key_iter] = (
                                first_header_from_batch[key_iter],
                                (
                                    first_header_from_batch.comments[key_iter]
                                    if key_iter in first_header_from_batch.comments
                                    else ""
                                ),
                            )
                        except Exception:
                            self.current_stack_header[key_iter] = (
                                first_header_from_batch[key_iter]
                            )
                self.current_stack_header["STACKTYP"] = (
                    f"Classic SUM/W ({self.stacking_mode})",
                    "Stacking method",
                )
                self.current_stack_header["CREATOR"] = (
                    "SeestarStacker (SUM/W)",
                    "Processing Software",
                )
                if self.correct_hot_pixels:
                    self.current_stack_header["HISTORY"] = (
                        "Hot pixel correction applied"
                    )
                if self.use_quality_weighting:
                    self.current_stack_header["HISTORY"] = (
                        "Quality weighting (SNR/Stars) with per-pixel coverage for SUM/W"
                    )
                else:
                    self.current_stack_header["HISTORY"] = (
                        "Uniform weighting (by image count) with per-pixel coverage for SUM/W"
                    )
                self.current_stack_header["HISTORY"] = "SUM/W Accumulation Initialized"

            self.current_stack_header["NIMAGES"] = (
                self.images_in_cumulative_stack,
                "Physical images processed for stack",
            )
            self.current_stack_header["TOTEXP"] = (
                round(self.total_exposure_seconds, 2),
                "[s] Approx total exposure time",
            )

            # Mettre √† jour SUMWGHTS avec la somme des poids max de WHT (approximation de l'exposition pond√©r√©e)
            # self.cumulative_wht_memmap est HW, float32
            if self.cumulative_wht_memmap.size > 0:
                with np.errstate(all="ignore"):
                    current_total_wht_center = np.nanmax(self.cumulative_wht_memmap)
                if not np.isfinite(current_total_wht_center):
                    current_total_wht_center = 0.0
            else:
                current_total_wht_center = 0.0
            self.current_stack_header["SUMWGHTS"] = (
                float(current_total_wht_center),
                "Approx. max sum of weights in WHT map",
            )

            logger.debug(
                "DEBUG QM [_combine_batch_result SUM/W]: Accumulation batch classique termin√©e."
            )

        except MemoryError as mem_err:
            logger.debug(
                f"ERREUR QM [_combine_batch_result SUM/W]: ERREUR M√âMOIRE - {mem_err}"
            )
            self.update_progress(
                f"‚ùå ERREUR M√âMOIRE lors de l'accumulation du batch classique."
            )
            traceback.print_exc(limit=1)
            self.processing_error = "Erreur M√©moire Accumulation"
            self.stop_processing = True
        except Exception as e:
            logger.debug(
                f"ERREUR QM [_combine_batch_result SUM/W]: Exception inattendue - {e}"
            )
            self.update_progress(
                f"‚ùå Erreur pendant l'accumulation du r√©sultat du batch: {e}"
            )
            traceback.print_exc(limit=3)
            try:
                batch_n_error_acc = int(
                    stack_info_header.get("NIMAGES", 1)
                )  # Nombre d'images du lot qui a √©chou√©
            except:
                batch_n_error_acc = 1
            self.failed_stack_count += batch_n_error_acc

    ################################################################################################################################################
    def _save_intermediate_stack(self):
        if self.current_stack_data is None or self.output_folder is None:
            return
        stack_path = os.path.join(self.output_folder, "stack_cumulative.fit")
        preview_path = os.path.join(self.output_folder, "stack_cumulative.png")
        try:
            header_to_save = (
                self.current_stack_header.copy()
                if self.current_stack_header
                else fits.Header()
            )
            try:
                if "HISTORY" in header_to_save:
                    history_entries = list(header_to_save["HISTORY"])
                    filtered_history = [
                        h for h in history_entries if "Intermediate save" not in str(h)
                    ]
                    while "HISTORY" in header_to_save:
                        del header_to_save["HISTORY"]
                    for entry in filtered_history:
                        header_to_save.add_history(entry)
            except Exception:
                pass
            header_to_save.add_history(
                f"Intermediate save after combining {self.images_in_cumulative_stack} images"
            )
            save_fits_image(
                self.current_stack_data, stack_path, header_to_save, overwrite=True
            )
            save_preview_image(
                self.current_stack_data, preview_path, apply_stretch=False
            )
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur sauvegarde stack interm√©diaire: {e}")

    def _move_to_stacked(self, paths: list[str]):
        """D√©place chaque fichier vers un sous-dossier 'stacked'."""
        for p in paths:
            if not p or not os.path.exists(p):
                continue
            src_dir = os.path.dirname(os.path.abspath(p))
            dst_dir = os.path.join(src_dir, self.stacked_subdir_name)
            os.makedirs(dst_dir, exist_ok=True)
            base = os.path.basename(p)
            dest = os.path.join(dst_dir, base)
            if os.path.exists(dest):
                stem, ext = os.path.splitext(base)
                dest = os.path.join(dst_dir, f"{stem}_dup_{int(time.time())}{ext}")
            try:
                if os.stat(src_dir).st_dev == os.stat(dst_dir).st_dev:
                    os.rename(p, dest)
                else:
                    shutil.copy2(p, dest)
                    os.remove(p)
                self.update_progress(f"üì¶ Moved to stacked: {base}", "INFO_DETAIL")
            except Exception as e:
                self.update_progress(f"‚ö†Ô∏è Move failed for {base}: {e}", "WARN")

    def _save_partial_stack(self):
        if (
            self.partial_save_interval <= 0
            or self.stacked_batches_count % self.partial_save_interval != 0
        ):
            return
        if (
            self.cumulative_sum_memmap is None
            or self.cumulative_wht_memmap is None
            or self.output_folder is None
        ):
            return
        sum_arr = np.array(self.cumulative_sum_memmap, dtype=np.float32)
        wht_arr = np.array(self.cumulative_wht_memmap, dtype=np.float32)
        with np.errstate(divide="ignore", invalid="ignore"):
            stack = np.nan_to_num(sum_arr / np.maximum(wht_arr, 1e-6))
        base = (
            Path(self.output_folder)
            / f"{self.output_filename}_batch{self.stacked_batches_count:03d}.fit"
        )
        tmp = base.with_suffix(".tmp")
        try:
            fits.PrimaryHDU(data=np.moveaxis(stack, -1, 0)).writeto(tmp, overwrite=True)
            os.replace(tmp, base)

            if base.exists():
                prev_idx = self.stacked_batches_count - 1
                if prev_idx > 0:
                    prev = base.with_name(
                        f"{self.output_filename}_batch{prev_idx:03d}.fit"
                    )
                    try:
                        prev.unlink()
                    except FileNotFoundError:
                        pass
                    except Exception as e:
                        self.update_progress(
                            f"‚ö†Ô∏è Erreur suppression ancien stack: {e}", "WARN"
                        )

            self.update_progress(f"üíæ Saved {base.name}")

            if hasattr(self, "gui") and getattr(self.gui, "last_stack_path", None):
                try:
                    self.gui.last_stack_path.set(str(base))
                except Exception:
                    pass
        except Exception as e:
            self.update_progress(f"‚ö†Ô∏è Erreur sauvegarde partielle: {e}", "WARN")

    def _update_batch_count_file(self):
        if not self.batch_count_path:
            return
        try:
            with open(self.batch_count_path, "w") as f:
                f.write(str(self.stacked_batches_count))
        except Exception as e:
            self.update_progress(f"‚ö†Ô∏è Erreur √©criture compteur batch: {e}", "WARN")

    def _stack_winsorized_sigma(
        self,
        images,
        weights,
        kappa=3.0,
        winsor_limits=(0.05, 0.05),
        apply_rewinsor=True,
    ):
        """Run winsorized sigma clipping in a separate process."""
        self.update_progress(
            f"RejWinsor: kappa={kappa}, limits={winsor_limits}, apply_rewinsor={apply_rewinsor}",
            None,
        )
        stack_args = (
            "winsorized-sigma",
            images,
            weights.tolist() if hasattr(weights, "tolist") else weights,
            kappa,
            kappa,
            winsor_limits,
            apply_rewinsor,
        )
        with ProcessPoolExecutor(max_workers=self.max_stack_workers) as exe:
            stacked, rejected_pct = exe.submit(_stack_worker, stack_args).result()
        self.update_progress(
            f"RejWinsor: done - {rejected_pct:.2f}% pixels rejected",
            None,
        )
        return stacked, rejected_pct

    def _combine_hq_by_tiles(
        self, images_list, weights, kappa, winsor_limits, tile_h=512
    ):
        """Combine les mini-stacks en bandes pour limiter la RAM."""
        H, W, _ = images_list[0].shape
        final = np.zeros_like(images_list[0], dtype=np.float32)
        wht = np.zeros((H, W), dtype=np.float32)

        for y0 in range(0, H, tile_h):
            y1 = min(y0 + tile_h, H)
            cube = np.stack([img[y0:y1] for img in images_list], axis=0)
            w_cube = np.stack([cov[y0:y1] for cov in weights], axis=0)
            if self.stack_final_combine == "winsorized_sigma_clip":
                stacked, _ = self._stack_winsorized_sigma(
                    cube,
                    w_cube,
                    kappa=kappa,
                    winsor_limits=winsor_limits,
                )
            elif self.stack_final_combine == "median":
                stacked, _ = _stack_median(cube, w_cube)
            else:
                stacked, _ = _stack_mean(cube, w_cube)
            final[y0:y1] += stacked * np.sum(w_cube, axis=0)[..., None]
            wht[y0:y1] += np.sum(w_cube, axis=0)

        return np.nan_to_num(final / np.maximum(wht[..., None], 1e-6))

    def _stack_batch(
        self, batch_items_with_masks, current_batch_num=0, total_batches_est=0
    ):
        """
        Combine un lot d'images align√©es en utilisant ZeMosaic.
        La mosa√Øque finale est produite par la fonction create_master_tile
        de ZeMosaic plut√¥t que par ccdproc.combine.
        Calcule et applique les poids qualit√© scalaires si activ√©.
        NOUVEAU: Calcule et retourne une carte de couverture/poids 2D pour le lot.

        Args:
            batch_items_with_masks (list): Liste de tuples:
                [(aligned_data, header, scores, wcs_obj, valid_pixel_mask_2d), ...].
                - aligned_data: HWC ou HW, float32, dans une √©chelle coh√©rente (ADU ou 0-1).
                - valid_pixel_mask_2d: HW bool, True o√π aligned_data a des pixels valides.
            current_batch_num (int): Num√©ro du lot pour les logs.
            total_batches_est (int): Estimation totale des lots pour les logs.

        Returns:
            tuple: (stacked_image_np, stack_info_header, batch_coverage_map_2d)
                   ou (None, None, None) en cas d'√©chec.
                   batch_coverage_map_2d: Carte HxW float32 des poids/couverture pour ce lot.
        """
        if not batch_items_with_masks:
            self.update_progress(
                f"‚ùå Erreur interne: _stack_batch re√ßu un lot vide (batch_items_with_masks)."
            )
            return None, None, None

        num_physical_images_in_batch_initial = len(batch_items_with_masks)
        progress_info = f"(Lot {current_batch_num}/{total_batches_est if total_batches_est > 0 else '?'})"
        self.update_progress(
            f"‚ú® Combinaison ccdproc du batch {progress_info} ({num_physical_images_in_batch_initial} images physiques initiales)..."
        )
        self.update_progress(
            f"    -> mode={self.stacking_mode}, norm={self.normalize_method}, weight={self.weighting_method}"
        )
        logger.debug(
            f"DEBUG QM [_stack_batch]: D√©but pour lot #{current_batch_num} avec {num_physical_images_in_batch_initial} items."
        )

        # --- 1. Filtrer les items valides et extraire les composants ---
        # Un item est valide si image, header, scores, et valid_pixel_mask sont non None
        # et si la shape de l'image est coh√©rente.

        valid_images_for_ccdproc = []  # Liste des arrays image (HWC ou HW)
        valid_headers_for_ccdproc = []
        valid_scores_for_quality_weights = []
        valid_pixel_masks_for_coverage = []  # Liste des masques 2D (HW bool)
        valid_wcs_objs_for_ccdproc = []

        ref_shape_check = None  # Shape de la premi√®re image valide (HWC ou HW)
        is_color_batch = False  # Sera d√©termin√© par la premi√®re image valide

        for idx, item_tuple in enumerate(batch_items_with_masks):
            if len(item_tuple) != 5:  # S'assurer qu'on a bien les 5 √©l√©ments
                self.update_progress(
                    f"   -> Item {idx+1} du lot {current_batch_num} ignor√© (format de tuple incorrect)."
                )
                continue

            img_np, hdr, score, _wcs_obj, mask_2d = item_tuple  # D√©baller

            if img_np is None or hdr is None or score is None or mask_2d is None:
                self.update_progress(
                    f"   -> Item {idx+1} (img/hdr/score/mask None) du lot {current_batch_num} ignor√©."
                )
                continue

            # D√©terminer la shape de r√©f√©rence et si le lot est couleur avec le premier item valide
            if ref_shape_check is None:
                ref_shape_check = img_np.shape
                is_color_batch = img_np.ndim == 3 and img_np.shape[2] == 3
                logger.debug(
                    f"     - R√©f√©rence shape pour lot: {ref_shape_check}, Couleur: {is_color_batch}"
                )

            # V√©rifier la coh√©rence des dimensions avec la r√©f√©rence
            is_current_item_valid_shape = False
            if is_color_batch:
                if (
                    img_np.ndim == 3
                    and img_np.shape == ref_shape_check
                    and mask_2d.shape == ref_shape_check[:2]
                ):
                    is_current_item_valid_shape = True
            else:  # N&B
                if (
                    img_np.ndim == 2
                    and img_np.shape == ref_shape_check
                    and mask_2d.shape == ref_shape_check
                ):
                    is_current_item_valid_shape = True

            if is_current_item_valid_shape:
                valid_images_for_ccdproc.append(img_np)
                valid_headers_for_ccdproc.append(hdr)
                valid_scores_for_quality_weights.append(score)
                valid_pixel_masks_for_coverage.append(mask_2d)
                valid_wcs_objs_for_ccdproc.append(_wcs_obj)
            else:
                self.update_progress(
                    f"   -> Item {idx+1} du lot {current_batch_num} ignor√© (shape image {img_np.shape} ou masque {mask_2d.shape} incompatible avec r√©f {ref_shape_check})."
                )

        num_valid_images_for_processing = len(valid_images_for_ccdproc)
        logger.debug(
            f"DEBUG QM [_stack_batch]: {num_valid_images_for_processing}/{num_physical_images_in_batch_initial} images valides pour traitement dans ce lot."
        )

        if num_valid_images_for_processing == 0:
            self.update_progress(
                f"‚ùå Aucune image valide trouv√©e dans le lot {current_batch_num} apr√®s filtrage. Lot ignor√©."
            )
            return None, None, None

        # --- V√©rification WCS seulement si n√©cessaire ---
        if self.reproject_between_batches and (
            self.drizzle_active_session or self.is_mosaic_run
        ):
            all_have_wcs = all(
                wcs is not None and getattr(wcs, "is_celestial", False)
                for wcs in valid_wcs_objs_for_ccdproc
            )
            if not all_have_wcs:
                self.update_progress(
                    f"‚ùå Lot #{current_batch_num} annul√© : WCS manquant sur au moins une image (requis pour reprojection).",
                    "ERROR",
                )
                logger.error(
                    f"Stacking Batch (Reproject Mode): Lot #{current_batch_num} a des images sans WCS valide. Annulation du lot."
                )
                return None, None, None

        # La shape 2D pour la carte de couverture (H, W)
        shape_2d_for_coverage_map = (
            ref_shape_check[:2] if is_color_batch else ref_shape_check
        )

        # --- 2. Calculer les poids scalaires qualit√© pour les images VALIDES ---
        weight_scalars_for_ccdproc = None  # Sera un array NumPy ou None
        sum_of_quality_weights_applied = float(
            num_valid_images_for_processing
        )  # D√©faut si pas de pond√©ration
        quality_weighting_was_effectively_applied = False

        if self.use_quality_weighting:
            self.update_progress(
                f"   -> Calcul des poids qualit√© pour {num_valid_images_for_processing} images valides..."
            )
            try:
                calculated_weights = self._calculate_weights(
                    valid_scores_for_quality_weights
                )  # Renvoie d√©j√† un array NumPy
                if (
                    calculated_weights is not None
                    and calculated_weights.size == num_valid_images_for_processing
                ):
                    weight_scalars_for_ccdproc = calculated_weights
                    sum_of_quality_weights_applied = np.sum(weight_scalars_for_ccdproc)
                    quality_weighting_was_effectively_applied = True
                    self.update_progress(
                        f"   -> Poids qualit√© (scalaires) calcul√©s. Somme: {sum_of_quality_weights_applied:.2f}. Range: [{np.min(weight_scalars_for_ccdproc):.2f}-{np.max(weight_scalars_for_ccdproc):.2f}]"
                    )
                else:
                    self.update_progress(
                        f"   ‚ö†Ô∏è Erreur calcul poids scalaires. Utilisation poids uniformes (1.0)."
                    )
                    # sum_of_quality_weights_applied reste num_valid_images_for_processing
            except Exception as w_err:
                self.update_progress(
                    f"   ‚ö†Ô∏è Erreur pendant calcul poids scalaires: {w_err}. Utilisation poids uniformes (1.0)."
                )
                # sum_of_quality_weights_applied reste num_valid_images_for_processing
        else:
            self.update_progress(
                f"   -> Pond√©ration Qualit√© (scalaire) d√©sactiv√©e. Poids uniformes (1.0) seront utilis√©s par ccdproc."
            )
            # sum_of_quality_weights_applied reste num_valid_images_for_processing

        try:
            self.update_progress(
                f"‚ú® Combinaison NumPy du batch (Lot {current_batch_num}/{total_batches_est})"
                f" ({num_valid_images_for_processing} images)"
                f" [mode={self.stacking_mode}, norm={self.normalize_method}, weight={self.weighting_method}]..."
            )

            image_data_list = valid_images_for_ccdproc
            coverage_maps_list = valid_pixel_masks_for_coverage
            coverage_stack_for_numpy = np.stack(coverage_maps_list, axis=0)

            quality_weights = weight_scalars_for_ccdproc
            if quality_weights is None:
                quality_weights = np.ones(
                    num_valid_images_for_processing, dtype=np.float32
                )

            # Apply normalization
            if self.normalize_method == "linear_fit":
                image_data_list = _normalize_images_linear_fit(image_data_list, 0)
            elif self.normalize_method == "sky_mean":
                image_data_list = _normalize_images_sky_mean(image_data_list, 0)

            extra_w = None
            if self.weighting_method == "variance":
                w_maps = _calculate_image_weights_noise_variance(image_data_list)
                extra_w = np.array(
                    [float(np.nanmean(w)) if w is not None else 1.0 for w in w_maps],
                    dtype=np.float32,
                )
            elif self.weighting_method == "fwhm":
                w_maps = _calculate_image_weights_noise_fwhm(image_data_list)
                extra_w = np.array(
                    [float(np.nanmean(w)) if w is not None else 1.0 for w in w_maps],
                    dtype=np.float32,
                )
            if extra_w is not None and extra_w.size == quality_weights.size:
                quality_weights = quality_weights * extra_w

            mode = getattr(self, "stacking_mode", "")
            if (
                mode == "winsorized-sigma"
                or getattr(self, "stack_reject_algo", "") == "winsorized_sigma_clip"
            ):
                images_for_stack = [
                    img * (mask[..., None] if img.ndim == 3 else mask)
                    for img, mask in zip(image_data_list, coverage_maps_list)
                ]
                stacked_batch_data_np, _ = self._stack_winsorized_sigma(
                    images_for_stack,
                    quality_weights,
                    kappa=max(self.stack_kappa_low, self.stack_kappa_high),
                    winsor_limits=self.winsor_limits,
                )
                batch_coverage_map_2d = np.sum(coverage_stack_for_numpy, axis=0).astype(
                    np.float32
                )
                stack_note = "winsorized sigma clip"
            elif (
                mode == "kappa-sigma"
                or getattr(self, "stack_reject_algo", "") == "kappa_sigma"
            ):
                images_for_stack = [
                    img * (mask[..., None] if img.ndim == 3 else mask)
                    for img, mask in zip(image_data_list, coverage_maps_list)
                ]
                stacked_batch_data_np, _ = _stack_kappa_sigma(
                    images_for_stack,
                    quality_weights,
                    sigma_low=self.stack_kappa_low,
                    sigma_high=self.stack_kappa_high,
                )
                batch_coverage_map_2d = np.sum(coverage_stack_for_numpy, axis=0).astype(
                    np.float32
                )
                stack_note = "kappa sigma"
            elif (
                mode == "linear_fit_clip"
                or getattr(self, "stack_reject_algo", "") == "linear_fit_clip"
            ):
                images_for_stack = [
                    img * (mask[..., None] if img.ndim == 3 else mask)
                    for img, mask in zip(image_data_list, coverage_maps_list)
                ]
                stacked_batch_data_np, _ = _stack_linear_fit_clip(
                    images_for_stack,
                    quality_weights,
                )
                batch_coverage_map_2d = np.sum(coverage_stack_for_numpy, axis=0).astype(
                    np.float32
                )
                stack_note = "linear fit clip"
            elif mode == "median":
                images_for_stack = [
                    img * (mask[..., None] if img.ndim == 3 else mask)
                    for img, mask in zip(image_data_list, coverage_maps_list)
                ]
                stacked_batch_data_np, _ = _stack_median(
                    images_for_stack,
                    quality_weights,
                )
                batch_coverage_map_2d = np.sum(coverage_stack_for_numpy, axis=0).astype(
                    np.float32
                )
                stack_note = "median"
            else:
                # ------------------------------------------------------------------
                # üÜï Impl√©mentation m√©moire-efficient & multithread
                # ------------------------------------------------------------------
                # Pr√©pare les listes d√©j√† filtr√©es : image_data_list, coverage_maps_list,
                # et le tableau quality_weights (shape = (N,))

                N = num_valid_images_for_processing
                img0 = image_data_list[0]
                is_color = img0.ndim == 3  # (H,W,3)   sinon (H,W)

                # Accumulateurs (float32 pour limiter la RAM)
                sum_signal = np.zeros_like(img0, dtype=np.float32)
                sum_weights = np.zeros(
                    img0.shape[:2] + ((1,) if is_color else ()), dtype=np.float32
                )

                def weigh_one(arg):
                    """Calcule (signal √ó poids, poids) pour une image."""
                    img, cov, w = arg
                    cov_b = cov[..., None] if is_color else cov
                    weighted = img * (cov_b * w)
                    return weighted.astype(np.float32), (cov_b * w).astype(np.float32)

                max_workers = min(8, os.cpu_count() or 2)
                with ThreadPoolExecutor(max_workers=max_workers) as exe:
                    for sig, wgt in exe.map(
                        weigh_one,
                        zip(image_data_list, coverage_maps_list, quality_weights),
                    ):
                        sum_signal += sig
                        sum_weights += wgt

                stacked_batch_data_np = np.divide(
                    sum_signal,
                    np.maximum(sum_weights, 1e-9),
                    out=np.zeros_like(sum_signal, dtype=np.float32),
                    where=sum_weights > 1e-9,
                ).astype(np.float32)

                batch_coverage_map_2d = sum_weights.squeeze().astype(np.float32)

                stack_note = f"mean ({max_workers} threads)"
            stack_info_header = fits.Header()
            stack_info_header["NIMAGES"] = (
                num_valid_images_for_processing,
                "Images in this batch stack",
            )
            stack_info_header["STK_NOTE"] = f"Stacked with {stack_note}"

            if self.reproject_between_batches and self.reference_wcs_object is not None:
                try:
                    wcs_hdr = self.reference_wcs_object.to_header(relax=True)
                    for k, v in wcs_hdr.items():
                        if k not in stack_info_header:
                            stack_info_header[k] = v
                    stack_info_header.setdefault("NAXIS1", ref_shape_check[1])
                    stack_info_header.setdefault("NAXIS2", ref_shape_check[0])
                except Exception:
                    pass

            self.update_progress(
                f"‚úÖ Combinaison lot (Lot {current_batch_num}/{total_batches_est}) termin√©e (Shape: {stacked_batch_data_np.shape})"
            )

        except Exception as e:
            self.update_progress(
                f"‚ùå Erreur lors de la combinaison NumPy du lot #{current_batch_num}: {e}",
                "ERROR",
            )
            logger.error(f"Erreur stacking NumPy batch #{current_batch_num}: {e}")
            traceback.print_exc(limit=2)
            return None, None, None
        return stacked_batch_data_np, stack_info_header, batch_coverage_map_2d

    #########################################################################################################################################

    # --- DANS LA CLASSE SeestarQueuedStacker DANS seestar/queuep/queue_manager.py ---

    def _combine_intermediate_drizzle_batches(
        self,
        intermediate_files_list,
        output_wcs_final_target,
        output_shape_final_target_hw,
    ):
        """
        Combine les r√©sultats Drizzle interm√©diaires (par lot) sauvegard√©s sur disque.
        MODIFIED V4_CombineFixAPI: Correction initialisation Drizzle et utilisation pixfrac.
        MODIFIED DebugDrizzleFinal_1: Comment√© le clipping Lanczos agressif, ajout logs.
        """
        final_sci_image_HWC = None
        final_wht_map_HWC = (
            None  # Sera HWC aussi, car les poids sont par canal pour Drizzle
        )

        num_batches_to_combine = len(intermediate_files_list)
        if num_batches_to_combine == 0:
            self.update_progress("‚ìò Aucun lot Drizzle interm√©diaire √† combiner.")
            return final_sci_image_HWC, final_wht_map_HWC

        # --- DEBUG DRIZZLE FINAL 1: Log d'entr√©e ---
        logger.debug("\n" + "=" * 70)
        logger.debug(
            f"DEBUG QM [_combine_intermediate_drizzle_batches V4_CombineFixAPI_DebugDrizzleFinal_1]:"
        )
        logger.debug(f"  D√©but pour {num_batches_to_combine} lots.")
        logger.debug(
            f"  Shape Sortie CIBLE: {output_shape_final_target_hw}, Drizzle Kernel: {self.drizzle_kernel}, Pixfrac: {self.drizzle_pixfrac}"
        )
        # --- FIN DEBUG ---
        self.update_progress(
            f"üíß [CombineBatches V4] D√©but combinaison {num_batches_to_combine} lots Drizzle..."
        )

        if output_wcs_final_target is None or output_shape_final_target_hw is None:
            self.update_progress(
                "   [CombineBatches V4] ERREUR: WCS ou Shape de sortie final manquant.",
                "ERROR",
            )
            return None, None

        num_output_channels = 3
        final_drizzlers = []
        final_output_images_list = []  # Liste des arrays SCI (H,W) par canal
        final_output_weights_list = []  # Liste des arrays WHT (H,W) par canal

        try:
            self.update_progress(
                f"   [CombineBatches V4] Initialisation Drizzle final (Shape: {output_shape_final_target_hw})..."
            )
            for _ in range(num_output_channels):
                final_output_images_list.append(
                    np.zeros(output_shape_final_target_hw, dtype=np.float32)
                )
                final_output_weights_list.append(
                    np.zeros(output_shape_final_target_hw, dtype=np.float32)
                )

            for i in range(num_output_channels):
                driz_ch = Drizzle(
                    kernel=self.drizzle_kernel,
                    fillval=str(
                        getattr(self, "drizzle_fillval", "0.0")
                    ),  # Utiliser l'attribut si existe
                    out_img=final_output_images_list[i],
                    out_wht=final_output_weights_list[i],
                    out_shape=output_shape_final_target_hw,
                )
                final_drizzlers.append(driz_ch)
            self.update_progress(
                f"   [CombineBatches V4] Objets Drizzle finaux initialis√©s."
            )
        except Exception as init_err:
            self.update_progress(
                f"   [CombineBatches V4] ERREUR: √âchec init Drizzle final: {init_err}",
                "ERROR",
            )
            logger.debug(
                f"ERREUR QM [_combine_intermediate_drizzle_batches]: √âchec init Drizzle: {init_err}"
            )
            traceback.print_exc(limit=1)
            return None, None

        total_contributing_ninputs_for_final_header = 0
        batches_successfully_added_to_final_drizzle = 0

        for i_batch_loop, (sci_fpath, wht_fpaths_list_for_batch) in enumerate(
            intermediate_files_list
        ):
            if self.stop_processing:
                self.update_progress(
                    "üõë Arr√™t demand√© pendant combinaison lots Drizzle."
                )
                break

            self.update_progress(
                f"   [CombineBatches V4] Ajout lot interm√©diaire {i_batch_loop+1}/{num_batches_to_combine}: {os.path.basename(sci_fpath)}..."
            )
            # --- DEBUG DRIZZLE FINAL 1: Log chemin lot ---
            logger.debug(
                f"  Processing batch {i_batch_loop+1}: SCI='{sci_fpath}', WHT0='{wht_fpaths_list_for_batch[0] if wht_fpaths_list_for_batch else 'N/A'}'"
            )
            # --- FIN DEBUG ---

            if len(wht_fpaths_list_for_batch) != num_output_channels:
                self.update_progress(
                    f"      -> ERREUR: Nb incorrect de cartes poids ({len(wht_fpaths_list_for_batch)}) pour lot {i_batch_loop+1}. Ignor√©.",
                    "WARN",
                )
                continue

            sci_data_cxhxw_lot = None
            wcs_lot_intermediaire = None
            wht_maps_2d_list_for_lot = None
            header_sci_lot = None
            pixmap_batch_to_final_grid = None

            try:
                with fits.open(sci_fpath, memmap=False) as hdul_sci:
                    sci_data_cxhxw_lot = hdul_sci[0].data.astype(np.float32)
                    header_sci_lot = hdul_sci[0].header
                    with warnings.catch_warnings():
                        warnings.simplefilter("ignore")
                        wcs_lot_intermediaire = WCS(header_sci_lot, naxis=2)
                if not wcs_lot_intermediaire.is_celestial:
                    raise ValueError("WCS lot interm√©diaire non c√©leste.")
                wht_maps_2d_list_for_lot = []
                for ch_idx_w, wht_fpath_ch in enumerate(wht_fpaths_list_for_batch):
                    with fits.open(wht_fpath_ch, memmap=False) as hdul_wht:
                        wht_map_2d_ch = hdul_wht[0].data.astype(np.float32)
                    wht_maps_2d_list_for_lot.append(
                        np.nan_to_num(np.maximum(wht_map_2d_ch, 0.0))
                    )
                # --- DEBUG DRIZZLE FINAL 1: Log donn√©es lot charg√©es ---
                logger.debug(
                    f"    Lot {i_batch_loop+1} SCI charg√© - Shape CxHxW: {sci_data_cxhxw_lot.shape}, Range Ch0: [{np.min(sci_data_cxhxw_lot[0]):.3g}, {np.max(sci_data_cxhxw_lot[0]):.3g}]"
                )
                logger.debug(
                    f"    Lot {i_batch_loop+1} WHT0 charg√© - Shape HW: {wht_maps_2d_list_for_lot[0].shape}, Range: [{np.min(wht_maps_2d_list_for_lot[0]):.3g}, {np.max(wht_maps_2d_list_for_lot[0]):.3g}]"
                )
                # --- FIN DEBUG ---

                shape_lot_intermediaire_hw = sci_data_cxhxw_lot.shape[1:]
                y_lot_intermed, x_lot_intermed = np.indices(shape_lot_intermediaire_hw)
                sky_coords_lot_ra, sky_coords_lot_dec = (
                    wcs_lot_intermediaire.all_pix2world(
                        x_lot_intermed.ravel(), y_lot_intermed.ravel(), 0
                    )
                )
                x_final_output_pix, y_final_output_pix = (
                    output_wcs_final_target.all_world2pix(
                        sky_coords_lot_ra, sky_coords_lot_dec, 0
                    )
                )
                x_final_output_pix = np.nan_to_num(
                    x_final_output_pix, nan=-1e9, posinf=-1e9, neginf=-1e9
                )
                y_final_output_pix = np.nan_to_num(
                    y_final_output_pix, nan=-1e9, posinf=-1e9, neginf=-1e9
                )
                x_final_output_pix = np.clip(
                    x_final_output_pix,
                    0,
                    output_shape_final_target_hw[1] - 1,
                )
                y_final_output_pix = np.clip(
                    y_final_output_pix,
                    0,
                    output_shape_final_target_hw[0] - 1,
                )
                pixmap_batch_to_final_grid = np.dstack(
                    (
                        x_final_output_pix.reshape(shape_lot_intermediaire_hw),
                        y_final_output_pix.reshape(shape_lot_intermediaire_hw),
                    )
                ).astype(np.float32)

                if pixmap_batch_to_final_grid is not None:
                    ninputs_this_batch = int(header_sci_lot.get("NINPUTS", 0))
                    for ch_idx_add in range(num_output_channels):
                        data_ch_sci_2d_lot = np.nan_to_num(
                            sci_data_cxhxw_lot[ch_idx_add, :, :]
                        )
                        data_ch_wht_2d_lot = wht_maps_2d_list_for_lot[ch_idx_add]
                        # --- DEBUG DRIZZLE FINAL 1: Log avant add_image ---
                        logger.debug(
                            f"      Ch{ch_idx_add} add_image: data SCI min/max [{np.min(data_ch_sci_2d_lot):.3g}, {np.max(data_ch_sci_2d_lot):.3g}], data WHT min/max [{np.min(data_ch_wht_2d_lot):.3g}, {np.max(data_ch_wht_2d_lot):.3g}], pixfrac={self.drizzle_pixfrac}"
                        )
                        # --- FIN DEBUG ---
                        final_drizzlers[ch_idx_add].add_image(
                            data=data_ch_sci_2d_lot,
                            pixmap=pixmap_batch_to_final_grid,
                            weight_map=data_ch_wht_2d_lot,
                            exptime=1.0,  # Les lots sont d√©j√† en counts/sec
                            pixfrac=self.drizzle_pixfrac,
                            in_units="cps",  # Confirm√© par BUNIT='Counts/s' dans les fichiers de lot
                        )
                    batches_successfully_added_to_final_drizzle += 1
                    total_contributing_ninputs_for_final_header += ninputs_this_batch

            except Exception as e_lot_proc:
                self.update_progress(
                    f"   [CombineBatches V4] ERREUR traitement lot {i_batch_loop+1}: {e_lot_proc}",
                    "ERROR",
                )
                continue
            finally:
                del (
                    sci_data_cxhxw_lot,
                    wcs_lot_intermediaire,
                    wht_maps_2d_list_for_lot,
                    header_sci_lot,
                    pixmap_batch_to_final_grid,
                )
                gc.collect()

        if batches_successfully_added_to_final_drizzle == 0:
            self.update_progress(
                "   [CombineBatches V4] ERREUR: Aucun lot Drizzle interm√©diaire n'a pu √™tre ajout√© √† la combinaison finale.",
                "ERROR",
            )
            return None, None

        # --- DEBUG DRIZZLE FINAL 1: Log des donn√©es brutes accumul√©es PAR CANAL ---
        for ch_log_idx in range(num_output_channels):
            temp_ch_data = final_output_images_list[ch_log_idx]
            temp_ch_wht = final_output_weights_list[ch_log_idx]
            logger.debug(
                f"  DEBUG [CombineBatches V4]: DONN√âES ACCUMUL√âES BRUTES (avant division/clipping) - Canal {ch_log_idx}:"
            )
            if temp_ch_data is not None and temp_ch_data.size > 0:
                logger.debug(
                    f"    SCI_ACCUM (out_img): Min={np.min(temp_ch_data):.4g}, Max={np.max(temp_ch_data):.4g}, Mean={np.mean(temp_ch_data):.4g}, Std={np.std(temp_ch_data):.4g}"
                )
                logger.debug(f"      N√©gatifs SCI_ACCUM: {np.sum(temp_ch_data < 0)}")
            else:
                logger.debug("    SCI_ACCUM: Donn√©es vides ou invalides.")
            if temp_ch_wht is not None and temp_ch_wht.size > 0:
                logger.debug(
                    f"    WHT_ACCUM (out_wht): Min={np.min(temp_ch_wht):.4g}, Max={np.max(temp_ch_wht):.4g}, Mean={np.mean(temp_ch_wht):.4g}"
                )
            else:
                logger.debug("    WHT_ACCUM: Donn√©es vides ou invalides.")
        # --- FIN DEBUG ---

        try:
            # Les `final_output_images_list` contiennent la somme(data*wht) et `final_output_weights_list` contient la somme(wht)
            # La division se fera dans _save_final_stack. Ici, on stack juste pour retourner.
            cube = np.stack(final_output_images_list, axis=0)
            w_cube = np.stack(final_output_weights_list, axis=0)
            if cube.nbytes > self.max_hq_mem:
                self.update_progress(
                    "HQ combine : trop de RAM, bascule en passe 2 par bandes"
                )
                final_sci_image_HWC = self._combine_hq_by_tiles(
                    final_output_images_list,
                    final_output_weights_list,
                    kappa=self.stack_kappa_high,
                    winsor_limits=self.winsor_limits,
                )
            else:
                if self.stack_final_combine == "winsorized_sigma_clip":
                    final_sci_image_HWC, _ = self._stack_winsorized_sigma(
                        cube,
                        w_cube,
                        kappa=self.stack_kappa_high,
                        winsor_limits=self.winsor_limits,
                    )
                elif self.stack_final_combine == "median":
                    final_sci_image_HWC, _ = _stack_median(cube, w_cube)
                else:
                    final_sci_image_HWC, _ = _stack_mean(cube, w_cube)
            final_wht_map_HWC = np.sum(w_cube, axis=0).astype(np.float32)

            # --- SECTION CLIPPING CONDITIONNEL POUR LANCZOS COMMENT√âE ---
            # if self.drizzle_kernel.lower() in ["lanczos2", "lanczos3"]:
            #     logger.debug(f"DEBUG [CombineBatches V4]: CLIPPING LANCZOS TEMPORAIREMENT D√âSACTIV√â.")
            #     # logger.debug(f"DEBUG [CombineBatches V4]: Application du clipping sp√©cifique pour kernel {self.drizzle_kernel}.")
            #     # self.update_progress(f"   Appli. clipping sp√©cifique pour Lanczos...", "DEBUG_DETAIL")
            #     # clip_min_lanczos = 0.0
            #     # clip_max_lanczos = 2.0 # Exemple, √† ajuster.
            #     # logger.debug(f"  [CombineBatches V4]: Clipping Lanczos: Min={clip_min_lanczos}, Max={clip_max_lanczos}")
            #     # logger.debug(f"    Avant clip (Ch0): Min={np.min(final_sci_image_HWC[...,0]):.4g}, Max={np.max(final_sci_image_HWC[...,0]):.4g}")
            #     # final_sci_image_HWC = np.clip(final_sci_image_HWC, clip_min_lanczos, clip_max_lanczos)
            #     # logger.debug(f"    Apr√®s clip (Ch0): Min={np.min(final_sci_image_HWC[...,0]):.4g}, Max={np.max(final_sci_image_HWC[...,0]):.4g}")
            # --- FIN SECTION CLIPPING COMMENT√âE ---

            # Nettoyage NaN/Inf et s'assurer que les poids sont non-n√©gatifs
            final_sci_image_HWC = np.nan_to_num(
                final_sci_image_HWC, nan=0.0, posinf=0.0, neginf=0.0
            )
            final_wht_map_HWC = np.nan_to_num(
                final_wht_map_HWC, nan=0.0, posinf=0.0, neginf=0.0
            )
            final_wht_map_HWC = np.maximum(
                final_wht_map_HWC, 0.0
            )  # Poids doivent √™tre >= 0

            self.update_progress(
                f"   -> Assemblage final Drizzle termin√© (Shape Sci HWC: {final_sci_image_HWC.shape}, Wht HWC: {final_wht_map_HWC.shape})"
            )
            self.images_in_cumulative_stack = (
                total_contributing_ninputs_for_final_header
            )
        except Exception as e_final_asm:
            self.update_progress(
                f"   - ERREUR pendant assemblage final Drizzle: {e_final_asm}", "ERROR"
            )
            final_sci_image_HWC = None
            final_wht_map_HWC = None
        finally:
            del final_drizzlers, final_output_images_list, final_output_weights_list
            gc.collect()

        logger.debug("=" * 70 + "\n")
        return final_sci_image_HWC, final_wht_map_HWC

    def _run_astap_and_update_header(self, fits_path: str) -> bool:
        """Solve the provided FITS with ASTAP and update its header in place."""
        try:
            header = fits.getheader(fits_path)
        except Exception as e:
            self.update_progress(f"   [ASTAP] √âchec lecture header: {e}", "ERROR")
            return False

        solver_settings = {
            "local_solver_preference": self.local_solver_preference,
            "api_key": self.api_key,
            "astap_path": self.astap_path,
            "astap_data_dir": self.astap_data_dir,
            "astap_search_radius": self.astap_search_radius,
            "astap_downsample": self.astap_downsample,
            "astap_sensitivity": self.astap_sensitivity,
            "local_ansvr_path": self.local_ansvr_path,
            "scale_est_arcsec_per_pix": getattr(
                self, "reference_pixel_scale_arcsec", None
            ),
            "scale_tolerance_percent": 20,
            "ansvr_timeout_sec": getattr(self, "ansvr_timeout_sec", 120),
            "astap_timeout_sec": getattr(self, "astap_timeout_sec", 120),
            "astrometry_net_timeout_sec": getattr(
                self, "astrometry_net_timeout_sec", 300
            ),
            "use_radec_hints": getattr(self, "use_radec_hints", False),
        }

        self.update_progress(f"   [ASTAP] Solve {os.path.basename(fits_path)}‚Ä¶")
        wcs = solve_image_wcs(
            fits_path, header, solver_settings, update_header_with_solution=True
        )
        if wcs is None:
            self.update_progress("   [ASTAP] √âchec r√©solution", "WARN")
            return False
        try:
            with fits.open(fits_path, mode="update") as hdul:
                hdul[0].header = header
                hdul.flush()
        except Exception as e:
            self.update_progress(f"   [ASTAP] Erreur √©criture header: {e}", "WARN")
        return True

    def _cache_solved_image(self, data, header, wcs_obj, idx):
        """Cache solved image data to a temporary FITS and return the path."""
        cache_dir = os.path.join(self.output_folder, "reproj_cache")
        os.makedirs(cache_dir, exist_ok=True)
        cache_path = os.path.join(cache_dir, f"solved_{idx:05d}.fits")
        hdr = header.copy()
        if wcs_obj is not None:
            try:
                hdr.update(wcs_obj.to_header())
            except Exception:
                pass
        data_to_save = np.moveaxis(data, -1, 0) if data.ndim == 3 else data
        fits.PrimaryHDU(data=data_to_save.astype(np.float32), header=hdr).writeto(
            cache_path, overwrite=True
        )
        return cache_path

    def _solve_cumulative_stack(self):
        """Solve the current cumulative stack with ASTAP and update reference WCS."""

        if (
            self.cumulative_sum_memmap is None
            or self.cumulative_wht_memmap is None
            or self.reference_header_for_wcs is None
        ):
            return None, None

        sum_arr = np.array(self.cumulative_sum_memmap, dtype=np.float32)
        wht_arr = np.array(self.cumulative_wht_memmap, dtype=np.float32)
        with np.errstate(divide="ignore", invalid="ignore"):
            wht_safe = np.maximum(wht_arr, 1e-6)
            stack = np.nan_to_num(sum_arr / wht_safe[:, :, np.newaxis])

        hdr = self.reference_header_for_wcs.copy()

        # If the reference WCS is frozen and already defined, skip solving
        # additional stacked batches and simply return the current stack using
        # the existing reference header.
        if self.freeze_reference_wcs and self.reference_wcs_object is not None:
            self.reference_header_for_wcs = hdr.copy()
            self.ref_wcs_header = hdr.copy()
            logger.debug(
                "DEBUG QM [_solve_cumulative_stack]: Skipping ASTAP solve (freeze_reference_wcs)."
            )
            return stack.astype(np.float32), hdr

        tmp = tempfile.NamedTemporaryFile(suffix=".fits", delete=False)
        tmp.close()
        fits.PrimaryHDU(data=np.moveaxis(stack, -1, 0), header=hdr).writeto(
            tmp.name, overwrite=True
        )
        solved_ok = self._run_astap_and_update_header(tmp.name)
        if solved_ok:
            hdr = fits.getheader(tmp.name)
        os.remove(tmp.name)

        try:
            new_wcs = WCS(hdr, naxis=2)
            new_wcs.pixel_shape = (
                stack.shape[1],
                stack.shape[0],
            )
        except Exception:
            new_wcs = None

        if self.reference_wcs_object is None or not self.freeze_reference_wcs:
            if new_wcs is not None:
                self.reference_wcs_object = new_wcs

        self.reference_header_for_wcs = hdr.copy()
        self.ref_wcs_header = hdr.copy()

        return stack.astype(np.float32), hdr

    def _load_and_prepare_simple(self, fits_path: str):
        data = fits.getdata(fits_path, memmap=False).astype(np.float32)
        hdr = fits.getheader(fits_path)
        try:
            input_wcs = WCS(hdr)
        except Exception:
            input_wcs = None
        if data.ndim == 2:
            data = data[:, :, None]
        wht = np.ones(data.shape[:2], dtype=np.float32)
        return data, wht, hdr, input_wcs

    def _can_resume(self, out_dir: Path) -> bool:
        req = [
            "memmap_accumulators/cumulative_SUM.npy",
            "memmap_accumulators/cumulative_WHT.npy",
            "batches_count.txt",
        ]
        return all((out_dir / r).exists() for r in req)

    def _open_existing_memmaps(self) -> bool:
        try:
            memmap_dir = Path(self.output_folder) / "memmap_accumulators"
            self.sum_memmap_path = memmap_dir / "cumulative_SUM.npy"
            self.wht_memmap_path = memmap_dir / "cumulative_WHT.npy"
            self.cumulative_sum_memmap = np.lib.format.open_memmap(
                self.sum_memmap_path, mode="r+"
            )
            self.cumulative_wht_memmap = np.lib.format.open_memmap(
                self.wht_memmap_path, mode="r+"
            )
            self.memmap_shape = self.cumulative_sum_memmap.shape
            if self.batch_count_path and Path(self.batch_count_path).exists():
                try:
                    self.stacked_batches_count = int(
                        Path(self.batch_count_path).read_text().strip()
                    )
                except Exception:
                    self.stacked_batches_count = 0
            return True
        except Exception as e:
            self.update_progress(f"‚ö†Ô∏è Reprise impossible: {e}", "WARN")
            return False

    def _create_sum_wht_memmaps(self, shape_hw):
        """(Re)create SUM/WHT memmaps for the given output shape."""
        memmap_dir = os.path.join(self.output_folder, "memmap_accumulators")
        os.makedirs(memmap_dir, exist_ok=True)
        self.sum_memmap_path = os.path.join(memmap_dir, "cumulative_SUM.npy")
        self.wht_memmap_path = os.path.join(memmap_dir, "cumulative_WHT.npy")
        self.memmap_shape = (shape_hw[0], shape_hw[1], 3)
        self.batch_count_path = os.path.join(self.output_folder, "batches_count.txt")
        mode = "w+"
        self.cumulative_sum_memmap = np.lib.format.open_memmap(
            self.sum_memmap_path,
            mode=mode,
            dtype=self.memmap_dtype_sum,
            shape=self.memmap_shape,
        )
        self.cumulative_wht_memmap = np.lib.format.open_memmap(
            self.wht_memmap_path,
            mode=mode,
            dtype=self.memmap_dtype_wht,
            shape=shape_hw,
        )
        if mode == "w+":
            self.cumulative_sum_memmap[:] = 0.0
            self.cumulative_wht_memmap[:] = 0.0
            self.stacked_batches_count = 0
            self._update_batch_count_file()
        else:
            if os.path.exists(self.batch_count_path):
                try:
                    with open(self.batch_count_path, "r") as f:
                        self.stacked_batches_count = int(f.read().strip())
                except Exception:
                    self.stacked_batches_count = 0

    def _ensure_memmaps_match_reference(self) -> None:
        """Ensure SUM/WHT memmaps match ``self.reference_shape``."""
        if self.reference_shape is None:
            return

        expected_sum_shape = (self.reference_shape[0], self.reference_shape[1], 3)
        expected_wht_shape = (self.reference_shape[0], self.reference_shape[1])

        need_recreate = (
            self.cumulative_sum_memmap is None
            or self.cumulative_wht_memmap is None
            or self.cumulative_sum_memmap.shape != expected_sum_shape
            or self.cumulative_wht_memmap.shape != expected_wht_shape
        )

        if need_recreate:
            self._close_memmaps()
            memmap_dir = os.path.join(self.output_folder, "memmap_accumulators")
            os.makedirs(memmap_dir, exist_ok=True)
            self.sum_memmap_path = os.path.join(memmap_dir, "cumulative_SUM.npy")
            self.wht_memmap_path = os.path.join(memmap_dir, "cumulative_WHT.npy")
            self.cumulative_sum_memmap = np.lib.format.open_memmap(
                self.sum_memmap_path,
                mode="w+",
                dtype=self.memmap_dtype_sum,
                shape=expected_sum_shape,
            )
            self.cumulative_sum_memmap[:] = 0.0
            self.cumulative_wht_memmap = np.lib.format.open_memmap(
                self.wht_memmap_path,
                mode="w+",
                dtype=self.memmap_dtype_wht,
                shape=expected_wht_shape,
            )
            self.cumulative_wht_memmap[:] = 0.0
            self.memmap_shape = expected_sum_shape
            self.update_progress(f"Re-init memmaps ‚Üí new shape {self.memmap_shape[:2]}")

    def finalize_continuous_stack(self):
        wht_safe = np.maximum(self.cumulative_wht_memmap, 1e-9)
        avg = self.cumulative_sum_memmap / wht_safe[..., None]
        avg = np.nan_to_num(avg, nan=0.0)

        hdu = fits.PrimaryHDU(
            data=avg.astype(np.float32), header=self.reference_header_for_wcs
        )
        fits.writeto(
            'master_stack_classic_nodriz.fits', hdu.data, hdu.header, overwrite=True
        )

    def _final_reproject_cached_files(self, cache_list):
        """Reproject cached solved images and accumulate them."""
        if not cache_list:
            self.update_progress(
                "‚ö†Ô∏è Aucun fichier r√©solu pour reprojection finale.", "WARN"
            )
            return

        wcs_list = [w for _, w, _ in cache_list if w is not None]
        headers = [h for _, _, h in cache_list]
        out_wcs, out_shape = self._calculate_final_mosaic_grid(
            wcs_list,
            headers,
            scale_factor=self.drizzle_scale if self.drizzle_active_session else 1.0,
        )
        if out_wcs is None or out_shape is None:
            self.update_progress("‚ö†Ô∏è √âchec du calcul de la grille finale.", "WARN")
            return

        self.reference_wcs_object = out_wcs
        self._close_memmaps()
        self._create_sum_wht_memmaps(out_shape)

        for path, wcs_obj, hdr in cache_list:
            try:
                with fits.open(path, memmap=False) as hdul:
                    dat = hdul[0].data.astype(np.float32)
                if dat.ndim == 3 and dat.shape[0] in (3, 4):
                    dat = np.moveaxis(dat, 0, -1)
                cov = np.ones(dat.shape[:2], dtype=np.float32)
                reproj_img, cov = self._reproject_to_reference(dat, wcs_obj)
                self._combine_batch_result(reproj_img, hdr, cov, batch_wcs=None)
                if hasattr(self.cumulative_sum_memmap, "flush"):
                    self.cumulative_sum_memmap.flush()
                if hasattr(self.cumulative_wht_memmap, "flush"):
                    self.cumulative_wht_memmap.flush()
            except Exception as e:
                self.update_progress(
                    f"‚ö†Ô∏è Reprojection finale ignor√©e pour {os.path.basename(path)}: {e}",
                    "WARN",
                )

        self._save_final_stack(output_filename_suffix="_classic_sumw")

    def _save_and_solve_classic_batch(self, stacked_np, wht_2d, header, batch_idx):
        """Save a classic batch and optionally solve/reproject it."""
        out_dir = os.path.join(self.output_folder, "classic_batch_outputs")
        os.makedirs(out_dir, exist_ok=True)

        sci_fits = os.path.join(out_dir, f"classic_batch_{batch_idx:03d}.fits")
        wht_paths: list[str] = []

        final_stacked = stacked_np
        final_wht = wht_2d
        np.nan_to_num(final_wht, copy=False)

        if self.solve_batches:
            # Always attempt to solve the intermediate batch with ASTAP so that a
            # valid WCS is present on each stacked batch file. This is required for
            # the optional inter-batch reprojection step (performed on stacked batches).
            # When solving fails we fall back to the reference header WCS if available.
            luminance = (
                stacked_np[..., 0] * 0.299
                + stacked_np[..., 1] * 0.587
                + stacked_np[..., 2] * 0.114
            ).astype(np.float32)
            tmp = tempfile.NamedTemporaryFile(suffix=".fits", delete=False)
            tmp.close()
            fits.PrimaryHDU(
                data=luminance, header=header
            ).writeto(tmp.name, overwrite=True, output_verify="ignore")
            solved_ok = self._run_astap_and_update_header(tmp.name)
            if solved_ok:
                solved_hdr = fits.getheader(tmp.name)
                header.update(solved_hdr)
            else:
                if self.reference_header_for_wcs is not None:
                    header.update(
                        {
                            k: self.reference_header_for_wcs[k]
                            for k in [
                                "CRPIX1",
                                "CRPIX2",
                                "CDELT1",
                                "CDELT2",
                                "CD1_1",
                                "CD1_2",
                                "CD2_1",
                                "CD2_2",
                                "CTYPE1",
                                "CTYPE2",
                                "CRVAL1",
                                "CRVAL2",
                            ]
                            if k in self.reference_header_for_wcs
                        }
                    )
                    header["NAXIS1"] = stacked_np.shape[1]
                    header["NAXIS2"] = stacked_np.shape[0]
                else:
                    os.remove(tmp.name)
                    return None, None
            os.remove(tmp.name)
        else:
            if self.reference_header_for_wcs is not None:
                header.update(
                    {
                        k: self.reference_header_for_wcs[k]
                        for k in [
                            "CRPIX1",
                            "CRPIX2",
                            "CDELT1",
                            "CDELT2",
                            "CD1_1",
                            "CD1_2",
                            "CD2_1",
                            "CD2_2",
                            "CTYPE1",
                            "CTYPE2",
                            "CRVAL1",
                            "CRVAL2",
                        ]
                        if k in self.reference_header_for_wcs
                    }
                )
                header["NAXIS1"] = stacked_np.shape[1]
                header["NAXIS2"] = stacked_np.shape[0]

        final_stacked = stacked_np
        final_wht = wht_2d
        np.nan_to_num(final_wht, copy=False)

        fits.PrimaryHDU(
            data=np.moveaxis(final_stacked, -1, 0), header=header
        ).writeto(sci_fits, overwrite=True, output_verify="ignore")
        for ch_i in range(final_stacked.shape[2]):
            wht_path = os.path.join(
                out_dir, f"classic_batch_{batch_idx:03d}_wht_{ch_i}.fits"
            )
            fits.PrimaryHDU(data=final_wht.astype(np.float32)).writeto(
                wht_path, overwrite=True, output_verify="ignore"
            )
            wht_paths.append(wht_path)

        return sci_fits, wht_paths

    def _reproject_classic_batches(self, batch_files):
        """Reproject saved classic batches to a common grid using reproject_and_coadd."""

        from seestar.enhancement.reproject_utils import (
            reproject_and_coadd,
            reproject_interp,
        )

        channel_arrays_wcs = [[] for _ in range(3)]
        channel_footprints = [[] for _ in range(3)]
        wcs_for_grid = []
        headers_for_grid = []

        for sci_path, wht_paths in batch_files:
            try:
                with fits.open(sci_path, memmap=False) as hdul:
                    data_cxhxw = hdul[0].data.astype(np.float32)
                    hdr = hdul[0].header
                batch_wcs = WCS(hdr, naxis=2)
                h, w = data_cxhxw.shape[-2:]
                batch_wcs.pixel_shape = (w, h)
            except Exception:
                continue

            try:
                coverage = fits.getdata(wht_paths[0]).astype(np.float32)
                np.nan_to_num(coverage, copy=False)
            except Exception:
                coverage = np.ones((h, w), dtype=np.float32)

            img_hwc = np.moveaxis(data_cxhxw, 0, -1)
            wcs_for_grid.append(batch_wcs)
            headers_for_grid.append(hdr)
            for ch in range(img_hwc.shape[2]):
                channel_arrays_wcs[ch].append((img_hwc[:, :, ch], batch_wcs))
                channel_footprints[ch].append(coverage)

        if len(wcs_for_grid) < 2:
            self.update_progress(
                f"‚ö†Ô∏è Reprojection ignor√©e: seulement {len(wcs_for_grid)} WCS valides.",
                "WARN",
            )
            return

        if (
            self.freeze_reference_wcs
            and self.reproject_between_batches
            and self.reference_wcs_object is not None
        ):
            out_wcs, out_shape = self._calculate_fixed_orientation_grid(
                self.reference_wcs_object,
                scale_factor=self.drizzle_scale if self.drizzle_active_session else 1.0,
            )
        else:
            out_wcs, out_shape = self._calculate_final_mosaic_grid(
                wcs_for_grid,
                headers_for_grid,
                scale_factor=self.drizzle_scale if self.drizzle_active_session else 1.0,
            )
        if out_wcs is None or out_shape is None:
            self.update_progress(
                "‚ö†Ô∏è Reprojection ignor√©e: √©chec du calcul de la grille finale.",
                "WARN",
            )
            return

        final_channels = []
        final_cov = None
        for ch in range(3):
            sci, cov = reproject_and_coadd(
                channel_arrays_wcs[ch],
                output_projection=out_wcs,
                shape_out=out_shape,
                input_weights=channel_footprints[ch],
                reproject_function=reproject_interp,
                combine_function="mean",
                match_background=True,
            )
            final_channels.append(sci.astype(np.float32))
            if final_cov is None:
                final_cov = cov.astype(np.float32)

        final_img_hwc = np.stack(final_channels, axis=-1)
        self._save_final_stack(
            "_classic_reproject",
            drizzle_final_sci_data=final_img_hwc,
            drizzle_final_wht_data=final_cov,
        )

    ############################################################################################################################################

    def _save_final_stack(
        self,
        output_filename_suffix: str = "",
        stopped_early: bool = False,
        drizzle_final_sci_data=None,
        drizzle_final_wht_data=None,
        preserve_linear_output: bool = False,
    ):
        """
        Calcule l'image finale, applique les post-traitements et sauvegarde.
        MODIFIED:
        - self.last_saved_data_for_preview (pour GUI) est maintenant l'image normalis√©e [0,1] SANS stretch cosm√©tique du backend.
        - save_preview_image (pour PNG) est appel√© avec apply_stretch=True sur ces donn√©es [0,1].
        - La sauvegarde FITS reste bas√©e sur self.raw_adu_data_for_ui_histogram (si float32) ou les donn√©es cosm√©tiques [0,1] (si uint16).
        Parameters
        ----------
        output_filename_suffix : str, optional
            Suffixe ajout√© au nom du fichier de sortie.
        stopped_early : bool, optional
            Indique si le traitement s'est arr√™t√© pr√©matur√©ment.
        drizzle_final_sci_data : ndarray, optional
            Donn√©es science fournies pour les modes Drizzle/Mosa√Øque.
        drizzle_final_wht_data : ndarray, optional
            Carte de poids correspondante.
        preserve_linear_output : bool, optional
            Si ``True``, saute la normalisation par percentiles et conserve la
            dynamique lin√©aire de ``final_image_initial_raw``.

        Version: V_SaveFinal_CorrectedDataFlow_1
        """
        logger.debug("\n" + "=" * 80)
        self.update_progress(
            f"DEBUG QM [_save_final_stack V_SaveFinal_CorrectedDataFlow_1]: D√©but. Suffixe: '{output_filename_suffix}', Arr√™t pr√©coce: {stopped_early}"
        )
        logger.debug(
            f"DEBUG QM [_save_final_stack V_SaveFinal_CorrectedDataFlow_1]: D√©but. Suffixe: '{output_filename_suffix}', Arr√™t pr√©coce: {stopped_early}"
        )

        save_as_float32_setting = getattr(self, "save_final_as_float32", False)
        preserve_linear_output_setting = getattr(self, "preserve_linear_output", False)
        # Retro-compatibilit√© : certaines versions utilisaient le nom
        # `preserve_linear_output_flag`. On cr√©e un alias pour √©viter
        # un NameError si d'anciens appels ou du code externe s'y r√©f√®rent.
        preserve_linear_output_flag = preserve_linear_output_setting
        self.update_progress(
            f"  DEBUG QM: Option de sauvegarde FITS effective (self.save_final_as_float32): {save_as_float32_setting}"
        )
        logger.debug(
            f"  DEBUG QM: Option de sauvegarde FITS effective (self.save_final_as_float32): {save_as_float32_setting}"
        )
        logger.debug(
            f"  DEBUG QM: preserve_linear_output active?: {preserve_linear_output_setting}"
        )

        is_reproject_mosaic_mode = (
            output_filename_suffix == "_mosaic_reproject"
            and drizzle_final_sci_data is not None
            and drizzle_final_wht_data is not None
        )
        is_drizzle_final_mode_with_data = (
            self.drizzle_active_session
            and self.drizzle_mode == "Final"
            and not self.is_mosaic_run
            and drizzle_final_sci_data is not None
            and drizzle_final_wht_data is not None
            and not is_reproject_mosaic_mode
        )
        is_true_incremental_drizzle_from_objects = (
            self.drizzle_active_session
            and self.drizzle_mode == "Incremental"
            and not self.is_mosaic_run
            and drizzle_final_sci_data is None
        )
        is_classic_reproject_mode = (
            self.reproject_between_batches
            and drizzle_final_sci_data is not None
            and drizzle_final_wht_data is not None
        )
        is_classic_stacking_mode = (
            self.cumulative_sum_memmap is not None
            and self.cumulative_wht_memmap is not None
            and not (
                is_reproject_mosaic_mode
                or is_drizzle_final_mode_with_data
                or is_true_incremental_drizzle_from_objects
                or is_classic_reproject_mode
            )
        )

        current_operation_mode_log_desc = "Unknown"
        current_operation_mode_log_fits = "Unknown"

        if is_reproject_mosaic_mode:
            current_operation_mode_log_desc = "Mosa√Øque (reproject_and_coadd)"
            current_operation_mode_log_fits = "Mosaic (reproject_and_coadd)"
        elif is_true_incremental_drizzle_from_objects:
            current_operation_mode_log_desc = (
                "Drizzle Incr√©mental VRAI (objets Drizzle)"
            )
            current_operation_mode_log_fits = (
                "True Incremental Drizzle (Drizzle objects)"
            )
        elif is_drizzle_final_mode_with_data:
            current_operation_mode_log_desc = (
                f"Drizzle Standard Final (donn√©es lot fournies)"
            )
            current_operation_mode_log_fits = "Drizzle Standard Final (from batch data)"
        elif is_classic_reproject_mode:
            current_operation_mode_log_desc = "Stacking Classique Reproject"
            current_operation_mode_log_fits = "Classic Stacking Reproject"
        elif is_classic_stacking_mode:
            current_operation_mode_log_desc = "Stacking Classique SUM/W (memmaps)"
            current_operation_mode_log_fits = "Classic Stacking SUM/W (memmaps)"
        else:
            if not self.drizzle_active_session and not self.is_mosaic_run:
                current_operation_mode_log_desc = (
                    "Stacking Classique SUM/W (memmaps) - Fallback"
                )
                current_operation_mode_log_fits = (
                    "Classic Stacking SUM/W (memmaps) - Fallback"
                )
                is_classic_stacking_mode = True

        self.update_progress(
            f"  DEBUG QM: Mode d'op√©ration d√©tect√© pour sauvegarde: {current_operation_mode_log_desc}"
        )
        logger.debug(
            f"  DEBUG QM: Mode d'op√©ration d√©tect√© pour sauvegarde: {current_operation_mode_log_desc}"
        )
        logger.debug("=" * 80 + "\n")
        self.update_progress(
            f"üíæ Pr√©paration sauvegarde finale (Mode: {current_operation_mode_log_desc})..."
        )

        final_image_initial_raw = None  # Donn√©es "brutes" apr√®s combinaison (ADU ou [0,1] si classique d√©j√† normalis√©)
        final_wht_map_for_postproc = (
            None  # Carte de poids 2D pour certains post-traitements
        )
        background_model_photutils = None  # Mod√®le de fond si Photutils BN est appliqu√©

        self.raw_adu_data_for_ui_histogram = (
            None  # Sera les donn√©es ADU-like pour l'histogramme de l'UI
        )
        # self.last_saved_data_for_preview est celui qui sera envoy√© √† l'UI pour son affichage
        # Il doit √™tre normalis√© [0,1] MAIS NON STRETCH√â COSM√âTIQUEMENT par le backend.

        try:
            # --- √âTAPE 1: Obtenir final_image_initial_raw et final_wht_map_for_postproc ---
            # (La logique pour obtenir ces donn√©es reste la m√™me que votre version pr√©c√©dente)
            # ... (Bloc if/elif/else pour les modes reproject, drizzle, classique) ...
            # (Je reprends la logique de votre dernier log `taraceback.txt` pour cette partie)
            if is_reproject_mosaic_mode:
                self.update_progress(
                    "  DEBUG QM [SaveFinalStack] Mode: Mosa√Øque Reproject"
                )
                logger.debug("  DEBUG QM [SaveFinalStack] Mode: Mosa√Øque Reproject")
                final_image_initial_raw = drizzle_final_sci_data.astype(np.float32)
                if drizzle_final_wht_data.ndim == 3:
                    final_wht_map_for_postproc = np.mean(
                        drizzle_final_wht_data, axis=2
                    ).astype(np.float32)
                else:
                    final_wht_map_for_postproc = drizzle_final_wht_data.astype(
                        np.float32
                    )
                final_wht_map_for_postproc = np.maximum(final_wht_map_for_postproc, 0.0)
                self._close_memmaps()
                self.update_progress(
                    f"    DEBUG QM: Mosaic Reproject - final_image_initial_raw - Range: [{np.nanmin(final_image_initial_raw):.4g} - {np.nanmax(final_image_initial_raw):.4g}]"
                )
                logger.debug(
                    f"    DEBUG QM: Mosaic Reproject - final_image_initial_raw - Range: [{np.nanmin(final_image_initial_raw):.4g} - {np.nanmax(final_image_initial_raw):.4g}]"
                )

            elif is_true_incremental_drizzle_from_objects:
                self.update_progress(
                    "  DEBUG QM [SaveFinalStack] Mode: Drizzle Incr√©mental VRAI"
                )
                logger.debug(
                    "  DEBUG QM [SaveFinalStack] Mode: Drizzle Incr√©mental VRAI"
                )
                if (
                    not self.incremental_drizzle_objects
                    or len(self.incremental_drizzle_objects) != 3
                ):
                    raise ValueError(
                        "Objets Drizzle incremental invalides ou manquants."
                    )
                sci_arrays_hw_list = [
                    d.out_img for d in self.incremental_drizzle_objects
                ]
                wht_arrays_hw_list = [
                    d.out_wht for d in self.incremental_drizzle_objects
                ]

                if not any(
                    np.any(np.asarray(w, dtype=float) != 0) for w in wht_arrays_hw_list
                ):
                    self.update_progress(
                        "‚ùå Drizzle Incremental: all weight maps are zero. Aborting final stack.",
                        "ERROR",
                    )
                    logger.error(
                        "ERROR QM [_save_final_stack]: All drizzle weights are zero."
                    )
                    self.final_stacked_path = None
                    return

                avg_img_channels_list = []
                processed_wht_channels_list_for_mean = []
                for c in range(3):
                    sci_ch_accum_float64 = sci_arrays_hw_list[c].astype(np.float64)
                    wht_ch_accum_raw_float64 = wht_arrays_hw_list[c].astype(np.float64)
                    wht_ch_clipped_positive = np.maximum(wht_ch_accum_raw_float64, 0.0)
                    processed_wht_channels_list_for_mean.append(
                        wht_ch_clipped_positive.astype(np.float32)
                    )
                    wht_ch_for_division = np.maximum(wht_ch_clipped_positive, 1e-9)
                    channel_mean_image_adu = np.zeros_like(
                        sci_ch_accum_float64, dtype=np.float32
                    )
                    valid_pixels_mask = wht_ch_for_division > 1e-8
                    with np.errstate(divide="ignore", invalid="ignore"):
                        channel_mean_image_adu[valid_pixels_mask] = (
                            sci_ch_accum_float64[valid_pixels_mask]
                            / wht_ch_for_division[valid_pixels_mask]
                        )
                    avg_img_channels_list.append(
                        np.nan_to_num(
                            channel_mean_image_adu, nan=0.0, posinf=0.0, neginf=0.0
                        ).astype(np.float32)
                    )
                final_image_initial_raw = np.stack(avg_img_channels_list, axis=-1)
                final_wht_map_for_postproc = np.mean(
                    np.stack(processed_wht_channels_list_for_mean, axis=-1), axis=2
                ).astype(np.float32)
                final_wht_map_for_postproc = np.maximum(final_wht_map_for_postproc, 0.0)
                self.update_progress(
                    f"    DEBUG QM: Drizzle Incr VRAI - final_image_initial_raw - Range: [{np.nanmin(final_image_initial_raw):.4g} - {np.nanmax(final_image_initial_raw):.4g}]"
                )
                logger.debug(
                    f"    DEBUG QM: Drizzle Incr VRAI - final_image_initial_raw - Range: [{np.nanmin(final_image_initial_raw):.4g} - {np.nanmax(final_image_initial_raw):.4g}]"
                )

            elif is_drizzle_final_mode_with_data:
                self.update_progress(
                    "  DEBUG QM [SaveFinalStack] Mode: Drizzle Standard Final (depuis donn√©es de lot)"
                )
                logger.debug(
                    "  DEBUG QM [SaveFinalStack] Mode: Drizzle Standard Final (depuis donn√©es de lot)"
                )
                if drizzle_final_sci_data is None or drizzle_final_wht_data is None:
                    raise ValueError(
                        "Donnees de lot Drizzle final (sci/wht) manquantes."
                    )
                sci_data_float64 = drizzle_final_sci_data.astype(np.float64)
                wht_data_float64 = drizzle_final_wht_data.astype(np.float64)
                wht_data_clipped_positive = np.maximum(wht_data_float64, 0.0)
                if drizzle_final_wht_data.ndim == 3:
                    wht3d = (
                        wht_data_clipped_positive
                        if drizzle_final_wht_data.shape[-1] == 3
                        else np.moveaxis(wht_data_clipped_positive, 0, -1)
                    )
                    final_wht_map_for_postproc = np.mean(wht3d, axis=2).astype(
                        np.float32
                    )
                    wht_for_div = np.maximum(wht3d, 1e-9)
                else:
                    final_wht_map_for_postproc = wht_data_clipped_positive.astype(
                        np.float32
                    )
                    wht_for_div = np.maximum(
                        wht_data_clipped_positive[:, :, np.newaxis], 1e-9
                    )
                with np.errstate(divide="ignore", invalid="ignore"):
                    final_image_initial_raw = sci_data_float64 / wht_for_div
                final_image_initial_raw = np.nan_to_num(
                    final_image_initial_raw, nan=0.0, posinf=0.0, neginf=0.0
                ).astype(np.float32)
                self._close_memmaps()
                self.update_progress(
                    f"    DEBUG QM: Drizzle Std Final - final_image_initial_raw - Range: [{np.nanmin(final_image_initial_raw):.4g} - {np.nanmax(final_image_initial_raw):.4g}]"
                )
                logger.debug(
                    f"    DEBUG QM: Drizzle Std Final - final_image_initial_raw - Range: [{np.nanmin(final_image_initial_raw):.4g} - {np.nanmax(final_image_initial_raw):.4g}]"
                )

            elif is_classic_reproject_mode:
                self.update_progress(
                    "  DEBUG QM [SaveFinalStack] Mode: Stacking Classique Reproject"
                )
                logger.debug(
                    "  DEBUG QM [SaveFinalStack] Mode: Stacking Classique Reproject"
                )
                final_image_initial_raw = drizzle_final_sci_data.astype(np.float32)
                if drizzle_final_wht_data.ndim == 3:
                    final_wht_map_for_postproc = np.mean(
                        drizzle_final_wht_data, axis=2
                    ).astype(np.float32)
                else:
                    final_wht_map_for_postproc = drizzle_final_wht_data.astype(
                        np.float32
                    )
                final_wht_map_for_postproc = np.maximum(final_wht_map_for_postproc, 0.0)
                self._close_memmaps()
                self.update_progress(
                    f"    DEBUG QM: Classic Reproject - final_image_initial_raw - Range: [{np.nanmin(final_image_initial_raw):.4g} - {np.nanmax(final_image_initial_raw):.4g}]"
                )
                logger.debug(
                    f"    DEBUG QM: Classic Reproject - final_image_initial_raw - Range: [{np.nanmin(final_image_initial_raw):.4g} - {np.nanmax(final_image_initial_raw):.4g}]"
                )

            else:  # SUM/W Classique
                self.update_progress(
                    "  DEBUG QM [SaveFinalStack] Mode: Stacking Classique SUM/W"
                )
                logger.debug(
                    "  DEBUG QM [SaveFinalStack] Mode: Stacking Classique SUM/W"
                )
                if (
                    self.cumulative_sum_memmap is None
                    or self.cumulative_wht_memmap is None
                ):
                    raise ValueError(
                        "Accumulateurs memmap SUM/WHT non disponibles pour stacking classique."
                    )

                final_sum = np.array(self.cumulative_sum_memmap, dtype=np.float64)
                self.update_progress(
                    f"    DEBUG QM: Classic Mode - final_sum (HWC, from memmap) - Shape: {final_sum.shape}, Range: [{np.nanmin(final_sum):.4g} - {np.nanmax(final_sum):.4g}]"
                )
                logger.debug(
                    f"    DEBUG QM: Classic Mode - final_sum (HWC, from memmap) - Shape: {final_sum.shape}, Range: [{np.nanmin(final_sum):.4g} - {np.nanmax(final_sum):.4g}]"
                )

                final_wht_map_2d_from_memmap = np.array(
                    self.cumulative_wht_memmap, dtype=np.float32
                )
                self.update_progress(
                    f"    DEBUG QM: Classic Mode - final_wht_map_2d_from_memmap (HW) - Shape: {final_wht_map_2d_from_memmap.shape}, Range: [{np.nanmin(final_wht_map_2d_from_memmap):.4g} - {np.nanmax(final_wht_map_2d_from_memmap):.4g}]"
                )
                logger.debug(
                    f"    DEBUG QM: Classic Mode - final_wht_map_2d_from_memmap (HW) - Shape: {final_wht_map_2d_from_memmap.shape}, Range: [{np.nanmin(final_wht_map_2d_from_memmap):.4g} - {np.nanmax(final_wht_map_2d_from_memmap):.4g}]"
                )

                self._close_memmaps()

                eps = 1e-9
                final_wht_map_for_postproc = np.maximum(
                    final_wht_map_2d_from_memmap, 0.0
                )
                wht_safe = np.maximum(final_wht_map_2d_from_memmap, eps)[
                    ..., np.newaxis
                ]

                with np.errstate(divide="ignore", invalid="ignore"):
                    final_image_initial_raw = final_sum / wht_safe
                final_image_initial_raw = np.nan_to_num(
                    final_image_initial_raw, nan=0.0, posinf=0.0, neginf=0.0
                )
                final_image_initial_raw = final_image_initial_raw.astype(np.float32)
                self.update_progress(
                    f"    DEBUG QM: Classic Mode - final_image_initial_raw (HWC, apr√®s SUM/WHT et nan_to_num) - Range: [{np.nanmin(final_image_initial_raw):.4g} - {np.nanmax(final_image_initial_raw):.4g}]"
                )
                logger.debug(
                    f"    DEBUG QM: Classic Mode - final_image_initial_raw (HWC, apr√®s SUM/WHT et nan_to_num) - Range: [{np.nanmin(final_image_initial_raw):.4g} - {np.nanmax(final_image_initial_raw):.4g}]"
                )

        except Exception as e_get_raw:
            self.processing_error = (
                f"Erreur obtention donnees brutes finales: {e_get_raw}"
            )
            self.update_progress(f"‚ùå {self.processing_error}", "ERROR")
            traceback.print_exc(limit=2)
            self.final_stacked_path = None
            return

        if final_image_initial_raw is None:
            self.final_stacked_path = None
            self.update_progress("‚ìò Aucun stack final (donnees brutes sont None).")
            return

        # √Ä ce stade, final_image_initial_raw contient les donn√©es "ADU-like"
        self.update_progress(
            f"  DEBUG QM [SaveFinalStack] final_image_initial_raw (AVANT post-traitements) - Range: [{np.nanmin(final_image_initial_raw):.4g}, {np.nanmax(final_image_initial_raw):.4g}], Shape: {final_image_initial_raw.shape}, Dtype: {final_image_initial_raw.dtype}"
        )
        logger.debug(
            f"  DEBUG QM [SaveFinalStack] final_image_initial_raw (AVANT post-traitements) - Range: [{np.nanmin(final_image_initial_raw):.4g}, {np.nanmax(final_image_initial_raw):.4g}], Shape: {final_image_initial_raw.shape}, Dtype: {final_image_initial_raw.dtype}"
        )

        if final_wht_map_for_postproc is not None and (
            is_classic_reproject_mode
            or is_reproject_mosaic_mode
            or is_true_incremental_drizzle_from_objects
            or is_drizzle_final_mode_with_data
        ):
            rows, cols = np.where(final_wht_map_for_postproc > 0)
            if rows.size and cols.size:
                y0, y1 = rows.min(), rows.max() + 1
                x0, x1 = cols.min(), cols.max() + 1
                if final_image_initial_raw.ndim == 3:
                    final_image_initial_raw = final_image_initial_raw[y0:y1, x0:x1, :]
                else:
                    final_image_initial_raw = final_image_initial_raw[y0:y1, x0:x1]
                final_wht_map_for_postproc = final_wht_map_for_postproc[y0:y1, x0:x1]
                if self.current_stack_header:
                    if "CRPIX1" in self.current_stack_header:
                        self.current_stack_header["CRPIX1"] -= x0
                    if "CRPIX2" in self.current_stack_header:
                        self.current_stack_header["CRPIX2"] -= y0
                if self.drizzle_output_wcs is not None:
                    try:
                        self.drizzle_output_wcs.wcs.crpix = [
                            self.drizzle_output_wcs.wcs.crpix[0] - x0,
                            self.drizzle_output_wcs.wcs.crpix[1] - y0,
                        ]
                        new_w = x1 - x0
                        new_h = y1 - y0
                        self.drizzle_output_wcs.pixel_shape = (new_w, new_h)
                        self.drizzle_output_wcs._naxis1 = new_w
                        self.drizzle_output_wcs._naxis2 = new_h
                    except Exception:
                        pass

        final_image_initial_raw = np.clip(final_image_initial_raw, 0.0, None)
        self.update_progress(
            f"    DEBUG QM: Apr√®s clip >=0 des valeurs n√©gatives, final_image_initial_raw - Range: [{np.nanmin(final_image_initial_raw):.4g}, {np.nanmax(final_image_initial_raw):.4g}]"
        )
        logger.debug(
            f"    DEBUG QM: Apr√®s clip >=0 des valeurs n√©gatives, final_image_initial_raw - Range: [{np.nanmin(final_image_initial_raw):.4g}, {np.nanmax(final_image_initial_raw):.4g}]"
        )

        # Appliquer le seuil WHT (si activ√©) aux donn√©es "ADU-like"
        if self.drizzle_wht_threshold > 0 and final_wht_map_for_postproc is not None:
            self.update_progress(
                f"  DEBUG QM [SaveFinalStack] Application du seuil WHT ({self.drizzle_wht_threshold}) sur final_wht_map_for_postproc √† final_image_initial_raw."
            )
            logger.debug(
                f"  DEBUG QM [SaveFinalStack] Application du seuil WHT ({self.drizzle_wht_threshold}) sur final_wht_map_for_postproc √† final_image_initial_raw."
            )
            invalid_wht_pixels = final_wht_map_for_postproc < self.drizzle_wht_threshold
            if final_image_initial_raw.ndim == 3:
                final_image_initial_raw = np.where(
                    invalid_wht_pixels[..., np.newaxis], np.nan, final_image_initial_raw
                )
            else:
                final_image_initial_raw = np.where(
                    invalid_wht_pixels, np.nan, final_image_initial_raw
                )

        # Stocker les donn√©es ADU pour histogramme UI uniquement si n√©cessaire
        self.raw_adu_data_for_ui_histogram = (
            np.nan_to_num(final_image_initial_raw, nan=0.0).astype(np.float32).copy()
        )
        logger.debug(
            f"  DEBUG QM [_save_final_stack]: self.raw_adu_data_for_ui_histogram STOCKE (ADU). Range: [{np.min(self.raw_adu_data_for_ui_histogram):.3f}, {np.max(self.raw_adu_data_for_ui_histogram):.3f}]"
        )

        # --- Normalisation par percentiles pour obtenir final_image_normalized_for_cosmetics (0-1) ---
        if preserve_linear_output_setting:
            logger.debug(
                "  DEBUG QM [_save_final_stack]: preserve_linear_output actif - saut de la normalisation par percentiles."
            )
            final_image_normalized_for_cosmetics = np.nan_to_num(
                final_image_initial_raw, nan=0.0
            ).astype(np.float32)
        else:
            logger.debug(
                f"  DEBUG QM [_save_final_stack]: Normalisation (0-1) par percentiles de final_image_initial_raw..."
            )
            data_for_percentile_norm = np.nan_to_num(
                final_image_initial_raw, nan=0.0
            ).astype(np.float32)
            if data_for_percentile_norm.ndim == 3:
                luminance = (
                    0.299 * data_for_percentile_norm[..., 0]
                    + 0.587 * data_for_percentile_norm[..., 1]
                    + 0.114 * data_for_percentile_norm[..., 2]
                )
            else:
                luminance = data_for_percentile_norm
            finite_luminance = luminance[np.isfinite(luminance) & (luminance > 1e-9)]

            if finite_luminance.size > 20:
                bp_val = np.percentile(finite_luminance, 0.1)
                wp_val = np.percentile(finite_luminance, 99.9)
                if wp_val <= bp_val + 1e-7:
                    min_finite, max_finite = np.min(finite_luminance), np.max(
                        finite_luminance
                    )
                    if max_finite > min_finite + 1e-7:
                        bp_val, wp_val = min_finite, max_finite
                    else:
                        bp_val, wp_val = 0.0, max(1e-7, max_finite)
                if wp_val <= bp_val:
                    wp_val = bp_val + 1e-7
                final_image_normalized_for_cosmetics = (
                    data_for_percentile_norm - bp_val
                ) / (wp_val - bp_val)
                logger.debug(
                    f"  DEBUG QM [_save_final_stack]: Normalisation (0-1) bas√©e sur percentiles. BP={bp_val:.4g}, WP={wp_val:.4g}."
                )
            else:
                max_overall = np.nanmax(data_for_percentile_norm)
                if max_overall > 1e-9:
                    final_image_normalized_for_cosmetics = (
                        data_for_percentile_norm / max_overall
                    )
                else:
                    final_image_normalized_for_cosmetics = np.zeros_like(
                        data_for_percentile_norm
                    )
                logger.debug(
                    "  DEBUG QM [_save_final_stack]: Normalisation (0-1) par max (peu de donn√©es/dynamique pour percentiles)."
                )

            final_image_normalized_for_cosmetics = np.clip(
                final_image_normalized_for_cosmetics, 0.0, 1.0
            )

        final_image_normalized_for_cosmetics = (
            final_image_normalized_for_cosmetics.astype(np.float32)
        )
        logger.debug(
            f"    Range apr√®s normalisation (0-1): [{np.nanmin(final_image_normalized_for_cosmetics):.3f}, {np.nanmax(final_image_normalized_for_cosmetics):.3f}]"
        )

        effective_image_count = self.images_in_cumulative_stack

        # data_after_postproc est la version 0-1 qui subira les post-traitements cosm√©tiques.
        data_after_postproc = final_image_normalized_for_cosmetics.copy()

        self.update_progress(
            f"  DEBUG QM [SaveFinalStack] data_after_postproc (AVANT post-traitements) - Range: [{np.nanmin(data_after_postproc):.4f}, {np.nanmax(data_after_postproc):.4f}]"
        )
        logger.debug(
            f"  DEBUG QM [SaveFinalStack] data_after_postproc (AVANT post-traitements) - Range: [{np.nanmin(data_after_postproc):.4f}, {np.nanmax(data_after_postproc):.4f}]"
        )

        # --- D√©but du Pipeline de Post-Traitement (identique √† votre version pr√©c√©dente) ---
        # Ici nous n'impl√©mentons que le Feathering et le Low WHT Mask pour
        # d√©montrer la connexion avec les r√©glages de l'onglet Expert.
        if (
            hasattr(self, "apply_feathering")
            and self.apply_feathering
            and final_wht_map_for_postproc is not None
        ):
            if _FEATHERING_AVAILABLE:
                self.update_progress("   [Feathering] Application au stack final...")
                data_after_postproc = feather_by_weight_map(
                    data_after_postproc,
                    final_wht_map_for_postproc.astype(np.float32),
                    blur_px=getattr(self, "feather_blur_px", 256),
                )
                self.feathering_applied_in_session = True
            else:
                self.update_progress(
                    "   [Feathering] Fonction non disponible.",
                    None,
                )

        if (
            hasattr(self, "apply_low_wht_mask")
            and self.apply_low_wht_mask
            and final_wht_map_for_postproc is not None
        ):
            if _LOW_WHT_MASK_AVAILABLE:
                self.update_progress("   [LowWHTMask] Application au stack final...")
                data_after_postproc = apply_low_wht_mask(
                    data_after_postproc,
                    final_wht_map_for_postproc.astype(np.float32),
                    percentile=getattr(self, "low_wht_percentile", 5),
                    soften_px=getattr(self, "low_wht_soften_px", 128),
                    progress_callback=self.update_progress,
                )
                self.low_wht_mask_applied_in_session = True
            else:
                self.update_progress(
                    "   [LowWHTMask] Fonction non disponible.",
                    None,
                )
        # --- Fin du Pipeline de Post-Traitement ---
        self.update_progress(
            f"  DEBUG QM [SaveFinalStack] data_after_postproc (APRES post-traitements, si activ√©s) - Range: [{np.nanmin(data_after_postproc):.4f}, {np.nanmax(data_after_postproc):.4f}], Dtype: {data_after_postproc.dtype}"
        )
        logger.debug(
            f"  DEBUG QM [SaveFinalStack] data_after_postproc (APRES post-traitements, si activ√©s) - Range: [{np.nanmin(data_after_postproc):.4f}, {np.nanmax(data_after_postproc):.4f}], Dtype: {data_after_postproc.dtype}"
        )

        # Les donn√©es post-trait√©es 0-1 seront utilis√©es pour l'aper√ßu UI
        self.last_saved_data_for_preview = data_after_postproc.copy()
        logger.debug(
            "DEBUG QM [_save_final_stack]: self.last_saved_data_for_preview = DONN√âES 0-1 POST-TRAIT√âES (pour l'aper√ßu UI)."
        )

        # --- √âTAPE 4: Pr√©paration du header FITS final et du nom de fichier ---
        # (Logique identique)
        effective_image_count = (
            self.images_in_cumulative_stack
            if self.images_in_cumulative_stack > 0
            else (
                getattr(self, "aligned_files_count", 1)
                if (is_drizzle_final_mode_with_data or is_reproject_mosaic_mode)
                else 1
            )
        )
        final_header = (
            self.current_stack_header.copy()
            if self.current_stack_header
            else fits.Header()
        )
        if (
            is_true_incremental_drizzle_from_objects
            or is_drizzle_final_mode_with_data
            or is_reproject_mosaic_mode
        ):
            if self.drizzle_output_wcs and not is_reproject_mosaic_mode:
                final_header.update(self.drizzle_output_wcs.to_header(relax=True))
            elif (
                is_reproject_mosaic_mode
                and self.current_stack_header
                and self.current_stack_header.get("CTYPE1")
            ):
                pass
        final_header["NIMAGES"] = (
            effective_image_count,
            "Effective images/Total Weight for final stack",
        )
        final_header["TOTEXP"] = (
            round(self.total_exposure_seconds, 2),
            "[s] Approx total exposure",
        )
        final_header["HISTORY"] = f"Final stack type: {current_operation_mode_log_fits}"
        if getattr(self, "output_filename", ""):
            base_name = self.output_filename.strip()
            if not base_name.lower().endswith(".fit"):
                base_name += ".fit"
            fits_path = os.path.join(self.output_folder, base_name)
            preview_path = os.path.splitext(fits_path)[0] + ".png"
        else:
            base_name = "stack_final"
            run_type_suffix = (
                output_filename_suffix if output_filename_suffix else "_unknown_mode"
            )
            if stopped_early:
                run_type_suffix += "_stopped"
            elif self.processing_error:
                run_type_suffix += "_error"
            fits_path = os.path.join(
                self.output_folder, f"{base_name}{run_type_suffix}.fit"
            )
            preview_path = os.path.splitext(fits_path)[0] + ".png"
        self.final_stacked_path = fits_path
        self.update_progress(f"Chemin FITS final: {os.path.basename(fits_path)}")

        # --- √âTAPE 5: Pr√©paration des donn√©es pour la SAUVEGARDE FITS ---
        data_for_primary_hdu_save = None
        if save_as_float32_setting:
            self.update_progress(
                "   DEBUG QM: Preparation sauvegarde FITS en float32 (brut ADU-like)..."
            )
            logger.debug(
                "   DEBUG QM: Preparation sauvegarde FITS en float32 (brut ADU-like)..."
            )
            data_for_primary_hdu_save = (
                self.raw_adu_data_for_ui_histogram
            )  # Utilise les donn√©es "ADU-like" (non-normalis√©es 0-1 cosm√©tiquement)
            self.update_progress(
                f"     DEBUG QM: -> FITS float32: Utilisation self.raw_adu_data_for_ui_histogram. Shape: {data_for_primary_hdu_save.shape}, Range: [{np.min(data_for_primary_hdu_save):.4f}, {np.max(data_for_primary_hdu_save):.4f}]"
            )
            logger.debug(
                f"     DEBUG QM: -> FITS float32: Utilisation self.raw_adu_data_for_ui_histogram. Shape: {data_for_primary_hdu_save.shape}, Range: [{np.min(data_for_primary_hdu_save):.4f}, {np.max(data_for_primary_hdu_save):.4f}]"
            )
            final_header["BITPIX"] = -32
            if "BSCALE" in final_header:
                del final_header["BSCALE"]
            if "BZERO" in final_header:
                del final_header["BZERO"]
        else:  # Sauvegarde en int16 d√©cal√© (repr√©sentation FITS "unsigned")
            self.update_progress(
                "   DEBUG QM: Preparation sauvegarde FITS en int16 (depuis donn√©es ADU -> 0-65535)..."
            )
            logger.debug(
                "   DEBUG QM: Preparation sauvegarde FITS en int16 (depuis donn√©es ADU -> 0-65535)..."
            )
            raw_data = self.raw_adu_data_for_ui_histogram
            if np.nanmax(raw_data) <= 1.0 + 1e-5:
                data_scaled_uint16 = (np.clip(raw_data, 0.0, 1.0) * 65535.0).astype(
                    np.uint16
                )
            else:
                data_scaled_uint16 = np.clip(raw_data, 0.0, 65535.0).astype(np.uint16)
            # Convertir en int16 d√©cal√© pour conformit√© FITS
            data_for_primary_hdu_save = (
                data_scaled_uint16.astype(np.int32) - 32768
            ).astype(np.int16)
            self.update_progress(
                f"     DEBUG QM: -> FITS int16: Utilisation donn√©es ADU. Shape: {data_for_primary_hdu_save.shape}, Range: [{np.min(data_for_primary_hdu_save)}, {np.max(data_for_primary_hdu_save)}]"
            )
            logger.debug(
                f"     DEBUG QM: -> FITS int16: Utilisation donn√©es ADU. Shape: {data_for_primary_hdu_save.shape}, Range: [{np.min(data_for_primary_hdu_save)}, {np.max(data_for_primary_hdu_save)}]"
            )
            final_header["BITPIX"] = 16
            final_header["BSCALE"] = 1
            final_header["BZERO"] = 32768

        if (
            data_for_primary_hdu_save.ndim == 3
            and data_for_primary_hdu_save.shape[2] == 3
        ):
            data_for_primary_hdu_save_cxhxw = np.moveaxis(
                data_for_primary_hdu_save, -1, 0
            )
        else:
            data_for_primary_hdu_save_cxhxw = data_for_primary_hdu_save
        self.update_progress(
            f"     DEBUG QM: Donn√©es FITS pr√™tes (Shape HDU: {data_for_primary_hdu_save_cxhxw.shape}, Dtype: {data_for_primary_hdu_save_cxhxw.dtype})"
        )
        logger.debug(
            f"     DEBUG QM: Donn√©es FITS pr√™tes (Shape HDU: {data_for_primary_hdu_save_cxhxw.shape}, Dtype: {data_for_primary_hdu_save_cxhxw.dtype})"
        )

        # --- √âTAPE 6: Sauvegarde FITS effective ---
        try:
            primary_hdu = fits.PrimaryHDU(
                data=data_for_primary_hdu_save_cxhxw, header=final_header
            )
            hdus_list = [primary_hdu]
            # ... (logique HDU background_model si besoin) ...
            fits.HDUList(hdus_list).writeto(
                fits_path, overwrite=True, checksum=True, output_verify="ignore"
            )
            # Astropy peut retirer BSCALE/BZERO lorsque des donn√©es int16 sont
            # fournies. Les r√©tablir uniquement dans ce cas.
            if not save_as_float32_setting:
                with fits.open(fits_path, mode="update", memmap=False) as hdul_fix:
                    hd0 = hdul_fix[0]
                    hd0.header["BSCALE"] = 1
                    hd0.header["BZERO"] = 32768
                    hdul_fix.flush()
            self.update_progress(
                f"   ‚úÖ Sauvegarde FITS ({'float32' if save_as_float32_setting else 'uint16'}) terminee."
            )
            try:
                renormalize_fits(
                    fits_path,
                    getattr(self, "drizzle_renorm_method", "none"),
                    getattr(self, "images_in_cumulative_stack", 0),
                )
            except Exception as ren_err:
                self.update_progress(f"   ‚ö†Ô∏è Renormalisation √©chou√©e: {ren_err}", "WARN")
        except Exception as save_err:
            self.update_progress(f"   ‚ùå Erreur Sauvegarde FITS: {save_err}")
            self.final_stacked_path = None

        # --- √âTAPE 7: Sauvegarde preview PNG ---
        # Utiliser data_after_postproc (qui est l'image [0,1] apr√®s tous les post-traitements)
        # et laisser save_preview_image appliquer son propre stretch par d√©faut.
        if data_after_postproc is not None:
            self.update_progress(
                f"  DEBUG QM (_save_final_stack): Donn√©es pour save_preview_image (data_after_postproc) - Range: [{np.nanmin(data_after_postproc):.4f}, {np.nanmax(data_after_postproc):.4f}], Shape: {data_after_postproc.shape}, Dtype: {data_after_postproc.dtype}"
            )
            logger.debug(
                f"  DEBUG QM (_save_final_stack): Donn√©es pour save_preview_image (data_after_postproc) - Range: [{np.nanmin(data_after_postproc):.4f}, {np.nanmax(data_after_postproc):.4f}], Shape: {data_after_postproc.shape}, Dtype: {data_after_postproc.dtype}"
            )
            try:
                save_preview_image(
                    data_after_postproc, preview_path, enhanced_stretch=False
                )  # ou True si vous pr√©f√©rez le stretch "enhanced" pour le PNG
                self.update_progress("     ‚úÖ Sauvegarde Preview PNG terminee.")
            except Exception as prev_err:
                self.update_progress(
                    f"     ‚ùå Erreur Sauvegarde Preview PNG: {prev_err}."
                )
        else:
            self.update_progress(
                "‚ìò Aucune image a sauvegarder pour preview PNG (data_after_postproc est None)."
            )

        self.update_progress(
            f"DEBUG QM [_save_final_stack V_SaveFinal_CorrectedDataFlow_1]: Fin methode (mode: {current_operation_mode_log_desc})."
        )
        logger.debug("\n" + "=" * 80)
        logger.debug(
            f"DEBUG QM [_save_final_stack V_SaveFinal_CorrectedDataFlow_1]: Fin methode (mode: {current_operation_mode_log_desc})."
        )
        logger.debug("=" * 80 + "\n")

    #############################################################################################################################################################

    # Le message de Pylance "is not accessed" concerne uniquement les variables locales closed_sum et closed_wht √† l'int√©rieur
    # de la m√©thode _close_memmaps() elle-m√™me. Ces variables sont d√©finies, mais leur valeur n'est jamais lue par le code de cette m√©thode
    # apr√®s leur assignation. Elles sont donc inutiles et peuvent √™tre supprim√©es.
    # Mais cela ne remet absolument pas en question :
    # Le fait que la m√©thode _close_memmaps() est appel√©e.
    # Le fait que le code √† l'int√©rieur de cette m√©thode (fermeture et suppression des r√©f√©rences self.cumulative_sum_memmap
    # et self.cumulative_wht_memmap) s'ex√©cute quand la m√©thode est appel√©e.
    # L'utilit√© de cette m√©thode pour lib√©rer les ressources li√©es aux fichiers memmap.

    def _close_memmaps(self):
        """Ferme proprement les objets memmap s'ils existent."""
        logger.debug("DEBUG QM [_close_memmaps]: Tentative de fermeture des memmaps...")
        closed_sum = False
        if (
            hasattr(self, "cumulative_sum_memmap")
            and self.cumulative_sum_memmap is not None
        ):
            try:
                # La documentation sugg√®re que la suppression de la r√©f√©rence devrait suffire
                # mais un appel explicite √† close() existe sur certaines versions/objets
                if (
                    hasattr(self.cumulative_sum_memmap, "_mmap")
                    and self.cumulative_sum_memmap._mmap is not None
                ):
                    self.cumulative_sum_memmap._mmap.close()
                # Supprimer la r√©f√©rence pour permettre la lib√©ration des ressources
                del self.cumulative_sum_memmap
                self.cumulative_sum_memmap = None
                closed_sum = True
                logger.debug(
                    "DEBUG QM [_close_memmaps]: R√©f√©rence memmap SUM supprim√©e."
                )
            except Exception as e_close_sum:
                logger.debug(
                    f"WARN QM [_close_memmaps]: Erreur fermeture/suppression memmap SUM: {e_close_sum}"
                )

        closed_wht = False
        if (
            hasattr(self, "cumulative_wht_memmap")
            and self.cumulative_wht_memmap is not None
        ):
            try:
                if (
                    hasattr(self.cumulative_wht_memmap, "_mmap")
                    and self.cumulative_wht_memmap._mmap is not None
                ):
                    self.cumulative_wht_memmap._mmap.close()
                del self.cumulative_wht_memmap
                self.cumulative_wht_memmap = None
                closed_wht = True
                logger.debug(
                    "DEBUG QM [_close_memmaps]: R√©f√©rence memmap WHT supprim√©e."
                )
            except Exception as e_close_wht:
                logger.debug(
                    f"WARN QM [_close_memmaps]: Erreur fermeture/suppression memmap WHT: {e_close_wht}"
                )

        # Optionnel: Essayer de supprimer les fichiers .npy si le nettoyage est activ√©
        # Cela devrait √™tre fait dans le bloc finally de _worker apr√®s l'appel √† _save_final_stack
        # if self.perform_cleanup:
        #      if self.sum_memmap_path and os.path.exists(self.sum_memmap_path):
        #          try: os.remove(self.sum_memmap_path); logger.debug("DEBUG: Fichier SUM.npy supprim√©.")
        #          except Exception as e: logger.debug(f"WARN: Erreur suppression SUM.npy: {e}")
        #      if self.wht_memmap_path and os.path.exists(self.wht_memmap_path):
        #          try: os.remove(self.wht_memmap_path); logger.debug("DEBUG: Fichier WHT.npy supprim√©.")
        #          except Exception as e: logger.debug(f"WARN: Erreur suppression WHT.npy: {e}")

    # --- FIN de _save_final_stack et ajout de _close_memmaps ---

    #########################################################################################################################################

    def _cleanup_batch_temp_files(self, batch_filepaths):
        """Supprime les fichiers FITS temporaires d'un lot Drizzle incr√©mental."""
        if not batch_filepaths:
            return

        deleted_count = 0
        self.update_progress(
            f"   -> Nettoyage {len(batch_filepaths)} fichier(s) temp du lot..."
        )
        for fpath in batch_filepaths:
            try:
                if os.path.isfile(fpath):
                    os.remove(fpath)
                    deleted_count += 1
            except OSError as e:
                # Log l'erreur mais continue le nettoyage des autres fichiers
                self.update_progress(
                    f"      ‚ö†Ô∏è Erreur suppression fichier temp {os.path.basename(fpath)}: {e}"
                )
            except Exception as e_gen:
                self.update_progress(
                    f"      ‚ö†Ô∏è Erreur inattendue suppression {os.path.basename(fpath)}: {e_gen}"
                )

        if deleted_count > 0:
            self.update_progress(
                f"   -> {deleted_count}/{len(batch_filepaths)} fichier(s) temp nettoy√©(s)."
            )
        elif len(batch_filepaths) > 0:
            self.update_progress(
                f"   -> Aucun fichier temp du lot n'a pu √™tre nettoy√© (d√©j√† supprim√©s ou erreur)."
            )

    ##########################################################################################################################################

    def cleanup_unaligned_files(self):
        """
        NOTE: Cette m√©thode ne supprime PLUS le contenu du dossier unaligned_files.
        Les fichiers non align√©s sont intentionnellement conserv√©s pour l'utilisateur.
        Le dossier lui-m√™me est cr√©√© s'il n'existe pas, mais son contenu n'est pas purg√© ici.
        """
        if self.unaligned_folder:  # V√©rifier si le chemin est d√©fini
            if not os.path.isdir(self.unaligned_folder):
                try:
                    os.makedirs(self.unaligned_folder, exist_ok=True)
                    # Optionnel: loguer la cr√©ation si elle a lieu ici
                    # self.update_progress(f"‚ìò Dossier pour fichiers non align√©s cr√©√©: {self.unaligned_folder}")
                except OSError as e:
                    self.update_progress(
                        f"‚ö†Ô∏è Erreur cr√©ation dossier pour non-align√©s '{self.unaligned_folder}': {e}"
                    )
            # else:
            # Optionnel: loguer que le dossier existe d√©j√†
            # self.update_progress(f"‚ìò Dossier pour fichiers non align√©s existe d√©j√†: {self.unaligned_folder}")

    def _update_batches_meta(self):
        self._update_batch_count_file()

    def _save_partial_stack(self):
        if (
            self.partial_save_interval <= 0
            or self.stacked_batches_count % self.partial_save_interval != 0
        ):
            return
        if self.cumulative_sum_memmap is None or self.cumulative_wht_memmap is None:
            return

        base_name = self.output_filename or "stack"
        out_path = os.path.join(
            self.output_folder,
            f"{base_name}_batch{self.stacked_batches_count:03d}.fit",
        )
        tmp = out_path + ".tmp"
        sum_data = np.array(self.cumulative_sum_memmap, dtype=np.float32)
        wht_data = np.array(self.cumulative_wht_memmap, dtype=np.float32)
        eps = 1e-9
        with np.errstate(divide="ignore", invalid="ignore"):
            avg = sum_data / np.maximum(wht_data[..., None], eps)
        avg = np.nan_to_num(avg, nan=0.0, posinf=0.0, neginf=0.0)
        fits.PrimaryHDU(data=np.moveaxis(avg, -1, 0)).writeto(tmp, overwrite=True)
        os.replace(tmp, out_path)

        if os.path.exists(out_path):
            prev_idx = self.stacked_batches_count - 1
            if prev_idx > 0:
                prev_path = os.path.join(
                    self.output_folder,
                    f"{base_name}_batch{prev_idx:03d}.fit",
                )
                try:
                    os.remove(prev_path)
                except FileNotFoundError:
                    pass
                except Exception as e:
                    self.update_progress(
                        f"‚ö†Ô∏è Erreur suppression ancien stack: {e}", "WARN"
                    )

        self.update_progress(f"üíæ Saved {os.path.basename(out_path)}")

        if hasattr(self, "gui") and getattr(self.gui, "last_stack_path", None):
            try:
                self.gui.last_stack_path.set(out_path)
            except Exception:
                pass

    ################################################################################################################################################

    def cleanup_temp_reference(self):
        if self.output_folder is None:  # <--- AJOUTER CETTE V√âRIFICATION
            logger.debug(
                "WARN QM [cleanup_temp_reference]: self.output_folder non d√©fini, nettoyage r√©f√©rence annul√©."
            )
            return
        try:
            aligner_temp_folder = os.path.join(self.output_folder, "temp_processing")
            if os.path.isdir(aligner_temp_folder):
                ref_fit = os.path.join(aligner_temp_folder, "reference_image.fit")
                ref_png = os.path.join(aligner_temp_folder, "reference_image.png")
                deleted_ref = 0
                if os.path.exists(ref_fit):
                    try:
                        os.remove(ref_fit)
                        deleted_ref += 1
                    except Exception:
                        pass
                if os.path.exists(ref_png):
                    try:
                        os.remove(ref_png)
                        deleted_ref += 1
                    except Exception:
                        pass
                if deleted_ref > 0:
                    self.update_progress(
                        f"üßπ Fichier(s) r√©f√©rence temporaire(s) supprim√©(s)."
                    )
                try:
                    os.rmdir(aligner_temp_folder)
                except OSError:
                    pass
        except Exception as e:
            self.update_progress(f"‚ö†Ô∏è Erreur nettoyage r√©f√©rence temp: {e}")

    ############################################################################
    ####################################################################

    def _cleanup_memmap_files(self):
        """Supprime le dossier memmap_accumulators en fin de traitement."""
        if self.output_folder is None:
            logger.debug(
                "WARN QM [_cleanup_memmap_files]: self.output_folder non d√©fini, nettoyage annul√©."
            )
            return
        memmap_dir = os.path.join(self.output_folder, "memmap_accumulators")
        if os.path.isdir(memmap_dir):
            try:
                shutil.rmtree(memmap_dir)
                self.update_progress(
                    f"üßπ Dossier memmap supprim√©: {os.path.basename(memmap_dir)}"
                )
            except Exception as e:
                self.update_progress(
                    f"‚ö†Ô∏è Erreur suppression dossier memmap ({os.path.basename(memmap_dir)}): {e}"
                )

    ################################################################################################################################################

    def add_folder(self, folder_path):
        if not self.processing_active:
            self.update_progress(
                "‚ìò Impossible d'ajouter un dossier, traitement non actif."
            )
            return False
        if self.reproject_between_batches:
            self.update_progress("‚ö†Ô∏è Reprojection active : ajout de dossier d√©sactiv√©")
            return False
        abs_path = os.path.abspath(folder_path)
        if not os.path.isdir(abs_path):
            self.update_progress(f"‚ùå Dossier non trouv√©: {folder_path}")
            return False
        output_abs = os.path.abspath(self.output_folder) if self.output_folder else None
        if output_abs:
            norm_abs_path = os.path.normcase(abs_path)
            norm_output_path = os.path.normcase(output_abs)
            if norm_abs_path == norm_output_path or norm_abs_path.startswith(
                norm_output_path + os.sep
            ):
                self.update_progress(
                    f"‚ö†Ô∏è Impossible d'ajouter le dossier de sortie: {os.path.basename(folder_path)}"
                )
                return False
        with self.folders_lock:
            current_abs = (
                os.path.abspath(self.current_folder) if self.current_folder else None
            )
            existing_abs = [os.path.abspath(p) for p in self.additional_folders]
            if (current_abs and abs_path == current_abs) or abs_path in existing_abs:
                self.update_progress(
                    f"‚ìò Dossier d√©j√† en cours ou ajout√©: {os.path.basename(folder_path)}"
                )
                return False
            self.additional_folders.append(abs_path)
            folder_count = len(self.additional_folders)
        self.update_progress(
            f"‚úÖ Dossier ajout√© √† la file d'attente : {os.path.basename(folder_path)}"
        )
        self.update_progress(f"folder_count_update:{folder_count}")
        return True

    ################################################################################################################################################

    def _add_files_to_queue(self, folder_path):
        count_added = 0
        try:
            abs_folder_path = os.path.abspath(folder_path)
            # ---> AJOUTER CETTE LIGNE <---
            logger.debug(
                f"DEBUG [_add_files_to_queue]: Scanning absolute path: '{abs_folder_path}'"
            )
            # ------------------------------
            self.update_progress(
                f"üîç Scan du dossier: {os.path.basename(folder_path)}..."
            )
            files_in_folder = sorted(os.listdir(abs_folder_path))
            # ---> AJOUTER CETTE LIGNE <---
            logger.debug(
                f"DEBUG [_add_files_to_queue]: os.listdir found: {files_in_folder}"
            )
            # ------------------------------
            new_files_found_in_folder = []
            for fname in files_in_folder:
                # ---> AJOUTER CETTE LIGNE (optionnel mais peut aider) <---
                logger.debug(f"DEBUG [_add_files_to_queue]: Checking file: '{fname}'")
                # ---------------------------------------------------------
                if self.stop_processing:
                    self.update_progress("‚õî Scan interrompu.")
                    break
                if fname.lower().endswith((".fit", ".fits")):
                    fpath = os.path.join(abs_folder_path, fname)
                    if self.stacked_subdir_name in os.path.relpath(
                        fpath, abs_folder_path
                    ).split(os.sep):
                        continue
                    abs_fpath = os.path.abspath(fpath)
                    if self.stacked_subdir_name in Path(abs_fpath).parts:
                        continue
                    if abs_fpath not in self.processed_files:
                        # ---> AJOUTER CETTE LIGNE <---
                        logger.debug(
                            f"DEBUG [_add_files_to_queue]: ADDING to queue and processed_files: '{fpath}'"
                        )
                        # ------------------------------
                        self.queue.put(fpath)
                        self.processed_files.add(abs_fpath)
                        count_added += 1
            if count_added > 0:
                self.files_in_queue += count_added
                self._recalculate_total_batches()
            return count_added
        except FileNotFoundError:
            self.update_progress(
                f"‚ùå Erreur scan: Dossier introuvable {os.path.basename(folder_path)}"
            )
            return 0
        except PermissionError:
            self.update_progress(
                f"‚ùå Erreur scan: Permission refus√©e {os.path.basename(folder_path)}"
            )
            return 0
        except Exception as e:
            self.update_progress(
                f"‚ùå Erreur scan dossier {os.path.basename(folder_path)}: {e}"
            )
            return 0

    ################################################################################################################################################

    # --- DANS LA CLASSE SeestarQueuedStacker DANS seestar/queuep/queue_manager.py ---

    def start_processing(
        self,
        input_dir,
        output_dir,
        reference_path_ui=None,
        output_filename="",
        initial_additional_folders=None,
        stacking_mode="kappa-sigma",
        kappa=2.5,
        stack_kappa_low=2.5,
        stack_kappa_high=2.5,
        winsor_limits=(0.05, 0.05),
        normalize_method="none",
        weighting_method="none",
        batch_size=10,
        correct_hot_pixels=True,
        hot_pixel_threshold=3.0,
        neighborhood_size=5,
        bayer_pattern="GRBG",
        perform_cleanup=True,
        use_weighting=False,
        weight_by_snr=True,
        weight_by_stars=True,
        snr_exp=1.0,
        stars_exp=0.5,
        min_w=0.1,
        use_drizzle=False,
        drizzle_scale=2.0,
        drizzle_wht_threshold=0.7,
        drizzle_mode="Final",
        drizzle_kernel="square",
        drizzle_pixfrac=1.0,
        apply_chroma_correction=True,
        apply_final_scnr=False,
        final_scnr_target_channel="green",
        final_scnr_amount=0.8,
        final_scnr_preserve_luminosity=True,
        bn_grid_size_str="16x16",
        bn_perc_low=5,
        bn_perc_high=30,
        bn_std_factor=1.0,
        bn_min_gain=0.2,
        bn_max_gain=7.0,
        cb_border_size=25,
        cb_blur_radius=8,
        cb_min_b_factor=0.4,
        cb_max_b_factor=1.5,
        final_edge_crop_percent=2.0,
        apply_photutils_bn=False,
        photutils_bn_box_size=128,
        photutils_bn_filter_size=5,
        photutils_bn_sigma_clip=3.0,
        photutils_bn_exclude_percentile=98.0,
        apply_feathering=False,
        feather_blur_px=256,
        apply_low_wht_mask=False,
        low_wht_percentile=5,
        low_wht_soften_px=128,
        is_mosaic_run=False,
        api_key=None,
        mosaic_settings=None,
        use_local_solver_priority=False,  # DEPRECATED - kept for signature compat
        astap_path="",
        astap_data_dir="",
        local_ansvr_path="",
        astap_search_radius=3.0,
        astap_downsample=1,
        astap_sensitivity=100,
        local_solver_preference="none",
        move_stacked=False,
        partial_save_interval=1,
        zoom_percent=0,
        *,
        save_as_float32=False,
        preserve_linear_output=False,
        reproject_between_batches=False,
    ):
        logger.debug(
            f"!!!!!!!!!! VALEUR BRUTE ARGUMENT astap_search_radius RE√áU : {astap_search_radius} !!!!!!!!!!"
        )
        logger.debug(
            f"!!!!!!!!!! VALEUR BRUTE ARGUMENT save_as_float32 RE√áU : {save_as_float32} !!!!!!!!!!"
        )  # DEBUG

        """
        D√©marre le thread de traitement principal avec la configuration sp√©cifi√©e.
        MODIFIED: Ajout arguments save_as_float32 et reproject_between_batches.
        Version: V_StartProcessing_SaveDtypeOption_1
        """

        logger.debug(
            "DEBUG QM (start_processing V_StartProcessing_SaveDtypeOption_1): D√©but tentative d√©marrage..."
        )  # Version Log

        logger.debug("  --- BACKEND ARGS RE√áUS (depuis GUI/SettingsManager) ---")
        logger.debug(f"    input_dir='{input_dir}', output_dir='{output_dir}'")
        logger.debug(f"    is_mosaic_run (arg de func): {is_mosaic_run}")
        logger.debug(f"    use_drizzle (global arg de func): {use_drizzle}")

        logger.debug(f"    drizzle_mode (global arg de func): {drizzle_mode}")
        logger.debug(f"    mosaic_settings (dict brut): {mosaic_settings}")
        logger.debug(
            f"    save_as_float32 (arg de func): {save_as_float32}"
        )  # Log du nouvel argument
        logger.debug(
            f"    reproject_between_batches (arg de func): {reproject_between_batches}"
        )
        logger.debug(f"    normalize_method: {normalize_method}")
        logger.debug(f"    weighting_method: {weighting_method}")
        logger.debug(f"    output_filename (arg de func): {output_filename}")
        logger.debug("  --- FIN BACKEND ARGS RE√áUS ---")

        if self.processing_active:
            self.update_progress("‚ö†Ô∏è Tentative de d√©marrer un traitement d√©j√† en cours.")
            return False

        self.stop_processing = False
        self.user_requested_stop = False
        if hasattr(self, "aligner") and self.aligner is not None:
            self.aligner.stop_processing = False
        else:
            self.update_progress(
                "‚ùå Erreur interne critique: Aligner principal non initialis√©. D√©marrage annul√©."
            )
            logger.debug("ERREUR QM (start_processing): self.aligner non initialis√©.")
            return False

        self.current_folder = os.path.abspath(input_dir) if input_dir else None
        self.output_folder = os.path.abspath(output_dir) if output_dir else None

        if self.autotuner:
            self.autotuner.start()

        # =========================================================================================
        # === √âTAPE 1 : CONFIGURATION DES PARAM√àTRES DE SESSION SUR L'INSTANCE (AVANT TOUT LE RESTE) ===
        # =========================================================================================
        logger.debug(
            "DEBUG QM (start_processing): √âtape 1 - Configuration des param√®tres de session sur l'instance..."
        )

        if not self.current_folder or not os.path.isdir(self.current_folder):
            self.update_progress(
                f"‚ùå Dossier d'entr√©e principal '{input_dir}' invalide ou non d√©fini.",
                "ERROR",
            )
            return False
        if not self.output_folder:
            self.update_progress(
                f"‚ùå Dossier de sortie '{output_dir}' non d√©fini.", "ERROR"
            )
            return False
        try:
            os.makedirs(self.output_folder, exist_ok=True)
        except OSError as e_mkdir:
            self.update_progress(
                f"‚ùå Erreur cr√©ation dossier de sortie '{self.output_folder}': {e_mkdir}",
                "ERROR",
            )
            return False
        self._resume_requested = self._can_resume(Path(self.output_folder))
        logger.debug(
            f"    [Paths] Input: '{self.current_folder}', Output: '{self.output_folder}'"
        )

        self.output_filename = str(output_filename).strip()

        self.local_solver_preference = str(local_solver_preference)
        self.astap_path = str(astap_path)
        self.astap_data_dir = str(astap_data_dir)
        self.astap_search_radius = float(astap_search_radius)
        self.astap_downsample = int(astap_downsample)
        self.astap_sensitivity = int(astap_sensitivity)
        self.local_ansvr_path = str(local_ansvr_path)

        logger.debug(
            f"    [Solver Settings sur self via start_processing args] Pref: '{self.local_solver_preference}'"
        )
        logger.debug(
            f"    [Solver Settings sur self via start_processing args] ASTAP Path: '{self.astap_path}'"
        )
        logger.debug(
            f"    [Solver Settings sur self via start_processing args] ASTAP Data Dir: '{self.astap_data_dir}'"
        )
        logger.debug(
            f"    [Solver Settings sur self via start_processing args] ASTAP Search Radius: {self.astap_search_radius}"
        )
        logger.debug(
            f"    [Solver Settings sur self via start_processing args] ASTAP Downsample: {self.astap_downsample}"
        )
        logger.debug(
            f"    [Solver Settings sur self via start_processing args] ASTAP Sensitivity: {self.astap_sensitivity}"
        )
        logger.debug(
            f"    [Solver Settings sur self via start_processing args] Ansvr Path: '{self.local_ansvr_path}'"
        )

        try:
            self.astap_search_radius_config = float(astap_search_radius)
        except (ValueError, TypeError):
            logger.debug(
                f"  WARN QM (start_processing): Valeur astap_search_radius ('{astap_search_radius}') invalide. Utilisation de 5.0¬∞ par d√©faut."
            )
            self.astap_search_radius_config = 5.0

        # self.use_local_solver_priority (attribut de self) n'est plus utilis√©, la variable locale de la fonction l'est.
        # logger.debug(f"    [Solver Settings sur self] Priorit√© Locale: {self.use_local_solver_priority}")
        logger.debug(f"    [Solver Settings sur self] ASTAP Exe: '{self.astap_path}'")
        logger.debug(
            f"    [Solver Settings sur self] ASTAP Data: '{self.astap_data_dir}'"
        )
        logger.debug(
            f"    [Solver Settings sur self] Ansvr Local: '{self.local_ansvr_path}'"
        )
        logger.debug(
            f"    [Solver Settings sur self] ASTAP Search Radius Config: {self.astap_search_radius_config}¬∞"
        )

        self.is_mosaic_run = is_mosaic_run
        self.drizzle_active_session = use_drizzle or self.is_mosaic_run
        self.drizzle_mode = str(drizzle_mode)

        self.api_key = api_key if isinstance(api_key, str) else ""
        if getattr(self, "reference_pixel_scale_arcsec", None) is None:
            self.reference_pixel_scale_arcsec = None

        self.stacking_mode = str(stacking_mode)
        self.kappa = float(kappa)
        self.stack_kappa_low = float(stack_kappa_low)
        self.stack_kappa_high = float(stack_kappa_high)
        try:
            self.winsor_limits = (
                float(winsor_limits[0]),
                float(winsor_limits[1]),
            )
        except Exception:
            self.winsor_limits = (0.05, 0.05)
        self.normalize_method = str(normalize_method)
        self.weighting_method = str(weighting_method)
        # If weighting method 'quality' is selected, ensure quality weighting flag is set
        self.use_quality_weighting = (
            bool(use_weighting) or self.weighting_method == "quality"
        )
        self.correct_hot_pixels = bool(correct_hot_pixels)
        self.hot_pixel_threshold = float(hot_pixel_threshold)
        self.neighborhood_size = int(neighborhood_size)
        self.zoom_percent = int(zoom_percent)
        self.bayer_pattern = str(bayer_pattern) if bayer_pattern else "GRBG"
        self.perform_cleanup = bool(perform_cleanup)
        self.weight_by_snr = bool(weight_by_snr)
        self.weight_by_stars = bool(weight_by_stars)
        self.snr_exponent = float(snr_exp)
        self.stars_exponent = float(stars_exp)
        self.min_weight = float(max(0.01, min(1.0, min_w)))

        self.drizzle_scale = float(drizzle_scale) if drizzle_scale else 2.0
        self.drizzle_wht_threshold = float(drizzle_wht_threshold)

        self.apply_chroma_correction = bool(apply_chroma_correction)
        self.apply_final_scnr = bool(apply_final_scnr)
        self.final_scnr_target_channel = str(final_scnr_target_channel).lower()
        self.final_scnr_amount = float(final_scnr_amount)
        self.final_scnr_preserve_luminosity = bool(final_scnr_preserve_luminosity)
        self.bn_grid_size_str = str(bn_grid_size_str)
        self.bn_perc_low = int(bn_perc_low)
        self.bn_perc_high = int(bn_perc_high)
        self.bn_std_factor = float(bn_std_factor)
        self.bn_min_gain = float(bn_min_gain)
        self.bn_max_gain = float(bn_max_gain)
        self.cb_border_size = int(cb_border_size)
        self.cb_blur_radius = int(cb_blur_radius)
        self.cb_min_b_factor = float(cb_min_b_factor)
        self.cb_max_b_factor = float(cb_max_b_factor)
        self.final_edge_crop_percent_decimal = float(final_edge_crop_percent) / 100.0
        self.apply_photutils_bn = bool(apply_photutils_bn)
        self.photutils_bn_box_size = int(photutils_bn_box_size)
        self.photutils_bn_filter_size = int(photutils_bn_filter_size)
        self.photutils_bn_sigma_clip = float(photutils_bn_sigma_clip)
        self.photutils_bn_exclude_percentile = float(photutils_bn_exclude_percentile)
        self.apply_feathering = bool(apply_feathering)
        self.feather_blur_px = int(feather_blur_px)
        self.apply_low_wht_mask = bool(apply_low_wht_mask)
        self.low_wht_percentile = int(low_wht_percentile)
        self.low_wht_soften_px = int(low_wht_soften_px)

        self.move_stacked = bool(move_stacked)
        self.partial_save_interval = max(1, int(partial_save_interval))

        # --- NOUVEAU : Assignation du param√®tre de sauvegarde √† l'attribut de l'instance ---

        self.save_final_as_float32 = bool(save_as_float32)
        logger.debug(
            f"    [OutputFormat] self.save_final_as_float32 (attribut d'instance) mis √† : {self.save_final_as_float32} (depuis argument {save_as_float32})"
        )
        self.preserve_linear_output = bool(preserve_linear_output)
        logger.debug(
            f"    [OutputFormat] self.preserve_linear_output (attribut d'instance) mis √† : {self.preserve_linear_output} (depuis argument {preserve_linear_output})"
        )

        self.reproject_between_batches = bool(reproject_between_batches)
        # When inter-batch reprojection is requested we typically want to keep
        # the reference WCS stable. If the caller did not explicitly set
        # ``freeze_reference_wcs`` beforehand, enable it automatically so that
        # intermediate batches are not solved again.
        if self.reproject_between_batches and not self.freeze_reference_wcs:
            self.freeze_reference_wcs = True

        # Disable solving of intermediate batches when reprojection is active
        # and the reference WCS should remain fixed.
        self.solve_batches = not (
            self.reproject_between_batches and self.freeze_reference_wcs
        )

        # Determine if we should keep the original input frame size when
        # reprojection between batches is enabled (to avoid changing the
        # reference size and breaking alignment).
        self.keep_input_size_for_reproject = (
            self.reproject_between_batches and not is_mosaic_run
        )

        # --- FIN NOUVEAU ---

        self.mosaic_settings_dict = (
            mosaic_settings if isinstance(mosaic_settings, dict) else {}
        )
        if self.is_mosaic_run:
            logger.debug(
                f"DEBUG QM (start_processing): Application des param√®tres de Mosa√Øque depuis mosaic_settings_dict: {self.mosaic_settings_dict}"
            )
            self.mosaic_alignment_mode = self.mosaic_settings_dict.get(
                "alignment_mode", "local_fast_fallback"
            )
            self.fa_orb_features = int(
                self.mosaic_settings_dict.get("fastalign_orb_features", 5000)
            )
            self.fa_min_abs_matches = int(
                self.mosaic_settings_dict.get("fastalign_min_abs_matches", 10)
            )
            self.fa_min_ransac_raw = int(
                self.mosaic_settings_dict.get("fastalign_min_ransac", 4)
            )
            self.fa_ransac_thresh = float(
                self.mosaic_settings_dict.get("fastalign_ransac_thresh", 3.0)
            )
            self.fa_daofind_fwhm = float(
                self.mosaic_settings_dict.get("fastalign_dao_fwhm", 3.5)
            )
            self.fa_daofind_thr_sig = float(
                self.mosaic_settings_dict.get("fastalign_dao_thr_sig", 4.0)
            )
            self.fa_max_stars_descr = int(
                self.mosaic_settings_dict.get("fastalign_dao_max_stars", 750)
            )
            self.use_wcs_fallback_for_mosaic = (
                self.mosaic_alignment_mode == "local_fast_fallback"
            )
            self.mosaic_drizzle_kernel = str(
                self.mosaic_settings_dict.get("kernel", "square")
            )
            self.mosaic_drizzle_pixfrac = float(
                self.mosaic_settings_dict.get("pixfrac", 1.0)
            )
            self.mosaic_drizzle_fillval = str(
                self.mosaic_settings_dict.get("fillval", "0.0")
            )
            self.drizzle_fillval = (
                self.mosaic_drizzle_fillval
            )  # override global drizzle fill value
            self.mosaic_drizzle_wht_threshold = float(
                self.mosaic_settings_dict.get("wht_threshold", 0.01)
            )
            # Surcharge du facteur d'√©chelle global pour la mosa√Øque
            self.drizzle_scale = float(
                self.mosaic_settings_dict.get("mosaic_scale_factor", self.drizzle_scale)
            )
            logger.debug(
                f"  -> Mode Mosa√Øque ACTIF. Align Mode: '{self.mosaic_alignment_mode}', Fallback WCS: {self.use_wcs_fallback_for_mosaic}"
            )
            logger.debug(
                f"     Mosaic Drizzle: Kernel='{self.mosaic_drizzle_kernel}', Pixfrac={self.mosaic_drizzle_pixfrac:.2f}, Scale(global)={self.drizzle_scale}x"
            )

        if self.drizzle_active_session and not self.is_mosaic_run:
            self.drizzle_kernel = str(drizzle_kernel)
            self.drizzle_pixfrac = float(drizzle_pixfrac)
            logger.debug(
                f"   -> Drizzle ACTIF (Standard). Mode: '{self.drizzle_mode}', Scale: {self.drizzle_scale:.1f}, Kernel: {self.drizzle_kernel}, Pixfrac: {self.drizzle_pixfrac:.2f}, WHT Thresh: {self.drizzle_wht_threshold:.3f}"
            )

        requested_batch_size = batch_size
        if requested_batch_size <= 0:
            sample_img_path_for_bsize = None
            if input_dir and os.path.isdir(input_dir):
                fits_files_bsize = [
                    f
                    for f in os.listdir(input_dir)
                    if f.lower().endswith((".fit", ".fits"))
                ]
                sample_img_path_for_bsize = (
                    os.path.join(input_dir, fits_files_bsize[0])
                    if fits_files_bsize
                    else None
                )
            try:
                estimated_size = estimate_batch_size(
                    sample_image_path=sample_img_path_for_bsize
                )
                self.batch_size = max(3, estimated_size)
                self.update_progress(
                    f"‚úÖ Taille lot auto estim√©e et appliqu√©e: {self.batch_size}", None
                )
            except Exception as est_err:
                self.update_progress(
                    f"‚ö†Ô∏è Erreur estimation taille lot: {est_err}. Utilisation d√©faut (10).",
                    None,
                )
                self.batch_size = 10
        else:
            self.batch_size = max(3, int(requested_batch_size))
        self.update_progress(
            f"‚ìò Taille de lot effective pour le traitement : {self.batch_size}"
        )
        logger.debug(
            "DEBUG QM (start_processing): Fin √âtape 1 - Configuration des param√®tres de session."
        )

        # --- √âTAPE 2 : PR√âPARATION DE L'IMAGE DE R√âF√âRENCE (shape ET WCS global si n√©cessaire) ---
        # ... (le reste de la m√©thode est inchang√©) ...
        logger.debug(
            "DEBUG QM (start_processing): √âtape 2 - Pr√©paration r√©f√©rence (shape ET WCS global si Drizzle/Mosa√Øque)..."
        )
        reference_image_data_for_shape_determination = None
        reference_header_for_shape_determination = None
        ref_shape_hwc = None

        try:
            potential_folders_for_shape = []
            if self.current_folder and os.path.isdir(self.current_folder):
                potential_folders_for_shape.append(self.current_folder)
            if initial_additional_folders:
                for add_f in initial_additional_folders:
                    abs_add_f = os.path.abspath(str(add_f))
                    if (
                        abs_add_f
                        and os.path.isdir(abs_add_f)
                        and abs_add_f not in potential_folders_for_shape
                    ):
                        potential_folders_for_shape.append(abs_add_f)
            if not potential_folders_for_shape:
                raise RuntimeError(
                    "Aucun dossier d'entr√©e valide pour trouver une image de r√©f√©rence."
                )

            current_folder_to_scan_for_shape = None
            files_in_folder_for_shape = []
            for folder_path_iter in potential_folders_for_shape:
                try:
                    temp_files = sorted(
                        [
                            f
                            for f in os.listdir(folder_path_iter)
                            if f.lower().endswith((".fit", ".fits"))
                        ]
                    )
                    if temp_files:
                        files_in_folder_for_shape = temp_files
                        current_folder_to_scan_for_shape = folder_path_iter
                        break
                except Exception as e_listdir:
                    self.update_progress(
                        f"Avertissement: Erreur lecture dossier '{folder_path_iter}' pour r√©f: {e_listdir}",
                        "WARN",
                    )
            if not current_folder_to_scan_for_shape or not files_in_folder_for_shape:
                raise RuntimeError(
                    "Aucun fichier FITS trouv√© dans les dossiers pour servir de r√©f√©rence."
                )

            self.aligner.correct_hot_pixels = self.correct_hot_pixels
            self.aligner.hot_pixel_threshold = self.hot_pixel_threshold
            self.aligner.neighborhood_size = self.neighborhood_size
            self.aligner.bayer_pattern = self.bayer_pattern
            self.aligner.reference_image_path = reference_path_ui or None

            (
                reference_image_data_for_shape_determination,
                reference_header_for_shape_determination,
            ) = self.aligner._get_reference_image(
                current_folder_to_scan_for_shape,
                files_in_folder_for_shape,
                self.output_folder,
            )

            if (
                reference_image_data_for_shape_determination is None
                or reference_header_for_shape_determination is None
            ):
                raise RuntimeError(
                    "√âchec obtention de l'image de r√©f√©rence par self.aligner._get_reference_image."
                )

            ref_shape_initial = reference_image_data_for_shape_determination.shape
            if len(ref_shape_initial) == 2:
                ref_shape_hwc = (ref_shape_initial[0], ref_shape_initial[1], 3)
            elif len(ref_shape_initial) == 3 and ref_shape_initial[2] == 3:
                ref_shape_hwc = ref_shape_initial
            else:
                raise RuntimeError(
                    f"Shape de l'image de r√©f√©rence ({ref_shape_initial}) non support√©e."
                )

            # Store the input reference frame shape (H, W)
            self.input_reference_shape_hw = ref_shape_hwc[:2]

            self.reference_header_for_wcs = (
                reference_header_for_shape_determination.copy()
            )
            self.ref_wcs_header = self.reference_header_for_wcs
            logger.debug(
                f"DEBUG QM (start_processing): Shape de r√©f√©rence HWC d√©termin√©e: {ref_shape_hwc}"
            )

            ref_temp_processing_dir = os.path.join(
                self.output_folder, "temp_processing"
            )
            reference_image_path_for_solving = os.path.join(
                ref_temp_processing_dir, "reference_image.fit"
            )

            self.reference_wcs_object = None

            if (
                self.drizzle_active_session
                or self.is_mosaic_run
                or self.reproject_between_batches
            ):
                logger.debug(
                    "DEBUG QM (start_processing): Plate-solving de la r√©f√©rence principale requis..."
                )

                if not os.path.exists(reference_image_path_for_solving):
                    raise RuntimeError(
                        f"Fichier de r√©f√©rence '{reference_image_path_for_solving}' non trouv√© pour le solving."
                    )

                if self.astrometry_solver is None:
                    self.update_progress(
                        "‚ùå ERREUR CRITIQUE: AstrometrySolver non initialis√©.", "ERROR"
                    )
                    return False

                solver_settings_for_ref = {
                    "local_solver_preference": self.local_solver_preference,
                    "api_key": self.api_key,
                    "astap_path": self.astap_path,
                    "astap_data_dir": self.astap_data_dir,
                    "astap_search_radius": self.astap_search_radius,
                    "astap_downsample": self.astap_downsample,
                    "astap_sensitivity": self.astap_sensitivity,
                    "local_ansvr_path": self.local_ansvr_path,
                    "scale_est_arcsec_per_pix": self.reference_pixel_scale_arcsec,
                    "scale_tolerance_percent": 20,
                    "ansvr_timeout_sec": getattr(self, "ansvr_timeout_sec", 120),
                    "astap_timeout_sec": getattr(self, "astap_timeout_sec", 120),
                    "astrometry_net_timeout_sec": getattr(
                        self, "astrometry_net_timeout_sec", 300
                    ),
                }

                self.update_progress(
                    "   [StartProcRefSolve] Tentative r√©solution astrom√©trique pour r√©f√©rence globale..."
                )
                self.reference_wcs_object = self.astrometry_solver.solve(
                    image_path=reference_image_path_for_solving,
                    fits_header=self.reference_header_for_wcs,
                    settings=solver_settings_for_ref,
                    update_header_with_solution=True,
                )

                if self.reference_wcs_object and self.reference_wcs_object.is_celestial:
                    self.update_progress(
                        "   [StartProcRefSolve] R√©f√©rence globale plate-solv√©e avec succ√®s."
                    )
                    if self.reference_wcs_object.pixel_shape is None:
                        nx_ref_hdr = self.reference_header_for_wcs.get(
                            "NAXIS1", ref_shape_hwc[1]
                        )
                        ny_ref_hdr = self.reference_header_for_wcs.get(
                            "NAXIS2", ref_shape_hwc[0]
                        )
                        self.reference_wcs_object.pixel_shape = (
                            int(nx_ref_hdr),
                            int(ny_ref_hdr),
                        )
                        logger.debug(
                            f"    [StartProcRefSolve] pixel_shape ajout√©/v√©rifi√© sur WCS r√©f: {self.reference_wcs_object.pixel_shape}"
                        )

                    try:
                        scales_deg_per_pix = proj_plane_pixel_scales(
                            self.reference_wcs_object
                        )
                        avg_scale_deg_per_pix = np.mean(np.abs(scales_deg_per_pix))

                        if avg_scale_deg_per_pix > 1e-9:
                            self.reference_pixel_scale_arcsec = (
                                avg_scale_deg_per_pix * 3600.0
                            )
                            self.update_progress(
                                f"   [StartProcRefSolve] √âchelle image de r√©f√©rence estim√©e √†: {self.reference_pixel_scale_arcsec:.2f} arcsec/pix.",
                                "INFO",
                            )
                            logger.debug(
                                f"DEBUG QM: self.reference_pixel_scale_arcsec mis √† jour √† {self.reference_pixel_scale_arcsec:.3f} depuis le WCS de r√©f√©rence."
                            )
                        else:
                            self.update_progress(
                                "   [StartProcRefSolve] Avertissement: √âchelle calcul√©e depuis WCS de r√©f√©rence trop faible ou invalide.",
                                "WARN",
                            )
                    except Exception as e_scale_extract:
                        self.update_progress(
                            f"   [StartProcRefSolve] Avertissement: Impossible d'extraire l'√©chelle du WCS de r√©f√©rence: {e_scale_extract}",
                            "WARN",
                        )

                else:
                    self.update_progress(
                        "   [StartProcRefSolve] √âCHEC plate-solving r√©f. globale. Tentative WCS approximatif...",
                        "WARN",
                    )
                    _cwfh_func_startup = None
                    try:
                        from ..enhancement.drizzle_integration import (
                            _create_wcs_from_header as _cwfh_s,
                        )

                        _cwfh_func_startup = _cwfh_s
                    except ImportError:
                        self.update_progress(
                            "     -> Import _create_wcs_from_header √©chou√© pour fallback.",
                            "ERROR",
                        )

                    if _cwfh_func_startup:
                        self.reference_wcs_object = _cwfh_func_startup(
                            self.reference_header_for_wcs
                        )

                    if (
                        self.reference_wcs_object
                        and self.reference_wcs_object.is_celestial
                    ):
                        nx_ref_hdr = self.reference_header_for_wcs.get(
                            "NAXIS1", ref_shape_hwc[1]
                        )
                        ny_ref_hdr = self.reference_header_for_wcs.get(
                            "NAXIS2", ref_shape_hwc[0]
                        )
                        self.reference_wcs_object.pixel_shape = (
                            int(nx_ref_hdr),
                            int(ny_ref_hdr),
                        )
                        self.update_progress(
                            "   [StartProcRefSolve] WCS approximatif pour r√©f√©rence globale cr√©√©."
                        )
                    else:
                        self.update_progress(
                            "‚ùå ERREUR CRITIQUE: Impossible d'obtenir un WCS pour la r√©f√©rence globale. Drizzle/Mosa√Øque ne peut continuer.",
                            "ERROR",
                        )
                        return False
            else:
                logger.debug(
                    "DEBUG QM (start_processing): Plate-solving de la r√©f√©rence globale ignor√© (mode Stacking Classique sans reprojection)."
                )
                self.reference_wcs_object = None

            if reference_image_data_for_shape_determination is not None:
                del reference_image_data_for_shape_determination
            gc.collect()
            logger.debug(
                "DEBUG QM (start_processing): Fin √âtape 2 - Pr√©paration r√©f√©rence et WCS global."
            )

        except Exception as e_ref_prep:
            self.update_progress(
                f"‚ùå Erreur pr√©paration r√©f√©rence/WCS: {e_ref_prep}", "ERROR"
            )
            logger.debug(
                f"ERREUR QM (start_processing): √âchec pr√©paration r√©f√©rence/WCS : {e_ref_prep}"
            )
            traceback.print_exc(limit=2)
            return False

        logger.debug(f"DEBUG QM (start_processing): AVANT APPEL initialize():")
        logger.debug(f"  -> self.is_mosaic_run: {self.is_mosaic_run}")
        logger.debug(f"  -> self.drizzle_active_session: {self.drizzle_active_session}")
        logger.debug(f"  -> self.drizzle_mode: {self.drizzle_mode}")
        logger.debug(
            f"  -> self.reference_wcs_object IS None: {self.reference_wcs_object is None}"
        )
        if (
            self.reference_wcs_object
            and hasattr(self.reference_wcs_object, "is_celestial")
            and self.reference_wcs_object.is_celestial
        ):
            logger.debug(
                f"     WCS Ref CTYPE: {self.reference_wcs_object.wcs.ctype if hasattr(self.reference_wcs_object, 'wcs') else 'N/A'}, PixelShape: {self.reference_wcs_object.pixel_shape}"
            )
        else:
            logger.debug(f"     WCS Ref non disponible ou non c√©leste.")

        if self.reference_wcs_object and self.fixed_output_wcs is None:
            try:
                ref_hw = ref_shape_hwc[:2]
                self.fixed_output_wcs, self.fixed_output_shape = (
                    self._create_drizzle_output_wcs(
                        self.reference_wcs_object, ref_hw, self.drizzle_scale
                    )
                )
                self.drizzle_output_wcs = self.fixed_output_wcs
                self.drizzle_output_shape_hw = self.fixed_output_shape
                self.reference_shape = self.fixed_output_shape
            except Exception as e_fix:
                logger.debug(
                    f"WARN start_processing: erreur creation grille fixe: {e_fix}"
                )

        init_shape_hwc = ref_shape_hwc
        if (
            self.reproject_between_batches
            and self.fixed_output_shape is not None
            and not self.keep_input_size_for_reproject
        ):
            init_shape_hwc = (
                self.fixed_output_shape[0],
                self.fixed_output_shape[1],
                3,
            )

        logger.debug(
            f"DEBUG QM (start_processing): √âtape 3 - Appel √† self.initialize() avec output_dir='{output_dir}', shape_ref_HWC={init_shape_hwc}..."
        )
        if not self.initialize(output_dir, init_shape_hwc):
            self.processing_active = False
            logger.debug("ERREUR QM (start_processing): √âchec de self.initialize().")
            return False
        logger.debug(
            "DEBUG QM (start_processing): self.initialize() termin√© avec succ√®s."
        )

        logger.debug(
            "DEBUG QM (start_processing): √âtape 4 - Remplissage de la file d'attente..."
        )
        initial_folders_to_add_count = 0
        with self.folders_lock:
            self.additional_folders = []
            if initial_additional_folders and isinstance(
                initial_additional_folders, list
            ):
                for folder_iter in initial_additional_folders:
                    abs_folder = os.path.abspath(str(folder_iter))
                    if (
                        os.path.isdir(abs_folder)
                        and abs_folder not in self.additional_folders
                    ):
                        self.additional_folders.append(abs_folder)
                        initial_folders_to_add_count += 1
        if initial_folders_to_add_count > 0:
            self.update_progress(
                f"‚ìò {initial_folders_to_add_count} dossier(s) pr√©-ajout√©(s) en attente."
            )
        self.update_progress(f"folder_count_update:{len(self.additional_folders)}")

        # --- PRE-SCAN WCS SEULEMENT POUR LE MODE MOSA√èQUE ---
        if self.is_mosaic_run:
            # Build the list of all FITS filepaths for global reprojection grid
            self.all_input_filepaths = []
            folders_for_scan = []
            if self.current_folder:
                folders_for_scan.append(self.current_folder)
            folders_for_scan.extend(self.additional_folders)
            for folder_iter in folders_for_scan:
                if folder_iter and os.path.isdir(folder_iter):
                    try:
                        for fname in sorted(os.listdir(folder_iter)):
                            if fname.lower().endswith((".fit", ".fits")):
                                self.all_input_filepaths.append(
                                    os.path.join(folder_iter, fname)
                                )
                    except Exception as e_scan:
                        self.update_progress(
                            f"‚ö†Ô∏è Scan skip {os.path.basename(folder_iter)}: {e_scan}", "WARN"
                        )

        initial_files_added = self._add_files_to_queue(self.current_folder)
        if initial_files_added > 0:
            self._recalculate_total_batches()
            self.update_progress(
                f"üìã {initial_files_added} fichiers initiaux ajout√©s. Total lots estim√©: {self.total_batches_estimated if self.total_batches_estimated > 0 else '?'}"
            )
        elif not self.additional_folders:
            self.update_progress(
                "‚ö†Ô∏è Aucun fichier initial trouv√© dans le dossier principal et aucun dossier suppl√©mentaire en attente."
            )

        if (
            self._resume_requested
            and self.stacked_batches_count > 0
            and self.batch_size > 0
        ):
            skip_files = self.stacked_batches_count * self.batch_size
            skipped = 0
            while skipped < skip_files and not self.queue.empty():
                try:
                    self.queue.get_nowait()
                    skipped += 1
                except Empty:
                    break
            if skipped:
                self.files_in_queue = max(self.files_in_queue - skipped, 0)
                self._recalculate_total_batches()
                self.update_progress(f"Resuming: {skipped} fichiers ignor√©s.")

        if self.is_mosaic_run and self.reproject_between_batches:
            ok_grid = self._prepare_global_reprojection_grid()
            if not ok_grid:
                return False
            self.fixed_output_wcs = self.reference_wcs_object
            self.fixed_output_shape = self.reference_shape
            if self.drizzle_active_session:
                self.drizzle_output_wcs = self.reference_wcs_object
                self.drizzle_output_shape_hw = self.reference_shape

        self.aligner.reference_image_path = reference_path_ui or None

        logger.debug(
            "DEBUG QM (start_processing V_StartProcessing_SaveDtypeOption_1): D√©marrage du thread worker..."
        )  # Version Log
        self.processing_thread = threading.Thread(
            target=self._worker, name="StackerWorker"
        )
        self.processing_thread.daemon = True
        self.processing_thread.start()
        self.processing_active = True

        self.update_progress("üöÄ Thread de traitement d√©marr√©.")
        logger.debug(
            "DEBUG QM (start_processing V_StartProcessing_SaveDtypeOption_1): Fin."
        )  # Version Log
        return True

    ###############################################################################################################################################

    def _save_drizzle_input_temp(self, aligned_data, header):
        """
        Sauvegarde une image align√©e (HxWx3 float32) dans le dossier temp Drizzle,
        en transposant en CxHxW et en INJECTANT l'OBJET WCS DE R√âF√âRENCE stock√©
        dans le header sauvegard√©.

        Args:
            aligned_data (np.ndarray): Donn√©es align√©es (HxWx3 float32, 0-1).
            header (fits.Header): Header FITS ORIGINAL (pour m√©tadonn√©es non-WCS).

        Returns:
            str or None: Chemin complet du fichier sauvegard√©, ou None en cas d'erreur.
        """
        # V√©rifications initiales
        if self.drizzle_temp_dir is None:
            self.update_progress("‚ùå Erreur interne: Dossier temp Drizzle non d√©fini.")
            return None
        os.makedirs(self.drizzle_temp_dir, exist_ok=True)
        if aligned_data.ndim != 3 or aligned_data.shape[2] != 3:
            self.update_progress(
                f"‚ùå Erreur interne: _save_drizzle_input_temp attend HxWx3, re√ßu {aligned_data.shape}"
            )
            return None
        # --- V√âRIFIER SI L'OBJET WCS DE R√âF√âRENCE EST DISPONIBLE ---
        if self.reference_wcs_object is None:
            self.update_progress(
                "‚ùå Erreur interne: Objet WCS de r√©f√©rence non disponible pour sauvegarde temp."
            )
            return None
        # --- FIN V√âRIFICATION ---

        try:
            temp_filename = f"aligned_input_{self.aligned_files_count:05d}.fits"
            temp_filepath = os.path.join(self.drizzle_temp_dir, temp_filename)

            # --- Pr√©parer les donn√©es : Transposer HxWxC -> CxHxW ---
            data_to_save = np.moveaxis(aligned_data, -1, 0).astype(np.float32)

            # --- Pr√©parer le header ---
            header_to_save = header.copy() if header else fits.Header()

            # --- EFFACER l'ancien WCS potentiellement invalide ---
            keys_to_remove = [
                "PC1_1",
                "PC1_2",
                "PC2_1",
                "PC2_2",
                "CD1_1",
                "CD1_2",
                "CD2_1",
                "CD2_2",
                "CRPIX1",
                "CRPIX2",
                "CRVAL1",
                "CRVAL2",
                "CTYPE1",
                "CTYPE2",
                "CUNIT1",
                "CUNIT2",
                "CDELT1",
                "CDELT2",
                "CROTA2",
            ]
            for key in keys_to_remove:
                if key in header_to_save:
                    del header_to_save[key]

            # --- INJECTER le WCS de l'OBJET WCS de r√©f√©rence ---
            ref_wcs_header = self.reference_wcs_object.to_header(relax=True)
            header_to_save.update(ref_wcs_header)

            # --- Mettre √† jour NAXIS pour CxHxW ---
            header_to_save["NAXIS"] = 3
            header_to_save["NAXIS1"] = aligned_data.shape[1]  # Width
            header_to_save["NAXIS2"] = aligned_data.shape[0]  # Height
            header_to_save["NAXIS3"] = 3  # Channels
            if "CTYPE3" not in header_to_save:
                header_to_save["CTYPE3"] = "CHANNEL"

            # --- Sauvegarde ---
            hdu = fits.PrimaryHDU(data=data_to_save, header=header_to_save)
            hdul = fits.HDUList([hdu])
            hdul.writeto(
                temp_filepath, overwrite=True, checksum=False, output_verify="ignore"
            )
            hdul.close()

            # logger.debug(f"   -> Temp Drizzle sauvegard√© ({os.path.basename(temp_filepath)}) avec WCS Ref Obj.") # DEBUG
            return temp_filepath

        except Exception as e:
            temp_filename_for_error = (
                f"aligned_input_{self.aligned_files_count:05d}.fits"
            )
            self.update_progress(
                f"‚ùå Erreur sauvegarde fichier temp Drizzle {temp_filename_for_error}: {e}"
            )
            traceback.print_exc(limit=2)
            return None

    ################################################################################################################################################

    def _list_drizzle_temp_files(self):
        """
        Retourne la liste tri√©e des chemins complets des fichiers FITS
        pr√©sents dans le dossier temporaire Drizzle.
        """
        # V√©rifier si le dossier est d√©fini et existe
        if self.drizzle_temp_dir is None or not os.path.isdir(self.drizzle_temp_dir):
            self.update_progress("‚ö†Ô∏è Dossier temp Drizzle non trouv√© pour listage.")
            return []  # Retourner liste vide

        try:
            # Lister les fichiers correspondant au pattern attendu
            files = [
                os.path.join(self.drizzle_temp_dir, f)
                for f in os.listdir(self.drizzle_temp_dir)
                if f.lower().endswith(".fits") and f.startswith("aligned_input_")
            ]
            # Trier la liste pour un ordre coh√©rent
            files.sort()
            return files

        except Exception as e:
            # G√©rer les erreurs de listage (permissions, etc.)
            self.update_progress(f"‚ùå Erreur listage fichiers temp Drizzle: {e}")
            return []  # Retourner liste vide en cas d'erreur

    ###################################################################################################################################################

    def _cleanup_drizzle_temp_files(self):
        """Supprime le dossier temporaire Drizzle et tout son contenu."""
        if (
            self.drizzle_temp_dir is None
        ):  # self.drizzle_temp_dir d√©pend de self.output_folder
            if self.output_folder is None:
                logger.debug(
                    "WARN QM [_cleanup_drizzle_temp_files]: self.output_folder non d√©fini, nettoyage Drizzle temp annul√©."
                )
                return
        else:
            self.drizzle_temp_dir = os.path.join(
                self.output_folder, "drizzle_temp_inputs"
            )
        # V√©rifier si le dossier est d√©fini et existe
        if self.drizzle_temp_dir and os.path.isdir(self.drizzle_temp_dir):
            memmap_dir = os.path.join(self.output_folder or "", "memmap_accumulators")
            abs_temp = os.path.abspath(self.drizzle_temp_dir)
            if abs_temp.startswith(os.path.abspath(memmap_dir)):
                logger.debug(
                    "WARN QM [_cleanup_drizzle_temp_files]: tentative de suppression du dossier memmap ignor√©e."
                )
                return
            try:
                shutil.rmtree(self.drizzle_temp_dir)
                self.update_progress(
                    f"üßπ Dossier temporaire Drizzle supprim√©: {os.path.basename(self.drizzle_temp_dir)}"
                )
            except Exception as e:
                # Log l'erreur si la suppression √©choue
                self.update_progress(
                    f"‚ö†Ô∏è Erreur suppression dossier temp Drizzle ({os.path.basename(self.drizzle_temp_dir)}): {e}"
                )
        # else: # Log optionnel si le dossier n'existait pas
        # self.update_progress("‚ìò Dossier temp Drizzle non trouv√© pour nettoyage (normal si Drizzle inactif ou d√©j√† nettoy√©).")

    ################################################################################################################################################

    def stop(self):
        if not self.processing_active:
            return
        self.update_progress("‚õî Arr√™t demand√©...")
        self.user_requested_stop = True
        self.stop_processing = True
        self.aligner.stop_processing = True
        if self.autotuner:
            self.autotuner.stop()

    ################################################################################################################################################

    def is_running(self):
        """V√©rifie si le thread de traitement est actif et en cours d'ex√©cution."""
        # V√©rifier si l'attribut processing_active existe et est True
        is_processing_flag_active = getattr(self, "processing_active", False)

        # V√©rifier si l'attribut processing_thread existe
        thread_exists = hasattr(self, "processing_thread")

        # Si les deux existent, v√©rifier si le thread est non None et vivant
        is_thread_alive_and_valid = False
        if thread_exists:
            thread_obj = getattr(self, "processing_thread", None)
            if thread_obj is not None and thread_obj.is_alive():
                is_thread_alive_and_valid = True

        # logger.debug(f"DEBUG QM [is_running]: processing_active={is_processing_flag_active}, thread_exists={thread_exists}, thread_alive={is_thread_alive_and_valid}") # Debug
        return is_processing_flag_active and thread_exists and is_thread_alive_and_valid

    ######################################################################################################################################################

    def _process_and_save_drizzle_batch(
        self,
        batch_temp_filepaths_list,
        output_wcs_target,
        output_shape_target_hw,
        batch_num,
    ):
        """
        Traite un lot de fichiers FITS temporaires (contenant des images align√©es et leur WCS de r√©f√©rence)
        en utilisant Drizzle et sauvegarde les fichiers science (CxHxW) et poids (HxW x3)
        interm√©diaires pour ce lot.
        MODIFIED CRITICAL: Force ALL input data to be in [0, 65535] ADU range BEFORE Drizzle.add_image.
        Robustify weight_map handling.
        Version: V_ProcessAndSaveDrizzleBatch_DrizzleInputFix_5_ForceADUAllChannels
        """
        num_files_in_batch = len(batch_temp_filepaths_list)
        self.update_progress(
            f"üíß Traitement Drizzle du lot #{batch_num} ({num_files_in_batch} images)..."
        )
        batch_start_time = time.time()
        logger.debug(
            f"DEBUG QM [_process_and_save_drizzle_batch V_ProcessAndSaveDrizzleBatch_DrizzleInputFix_5_ForceADUAllChannels]: Lot #{batch_num} avec {num_files_in_batch} images."
        )
        logger.debug(
            f"  -> WCS de sortie cible fourni: {'Oui' if output_wcs_target else 'Non'}, Shape de sortie cible: {output_shape_target_hw}"
        )

        if not batch_temp_filepaths_list:
            self.update_progress(f"   - Warning: Lot Drizzle #{batch_num} vide.")
            return None, []
        if output_wcs_target is None or output_shape_target_hw is None:
            self.update_progress(
                f"   - ERREUR: WCS ou Shape de sortie manquant pour lot Drizzle #{batch_num}. Traitement annul√©.",
                "ERROR",
            )
            logger.debug(
                f"ERREUR QM [_process_and_save_drizzle_batch V_ProcessAndSaveDrizzleBatch_DrizzleInputFix_5_ForceADUAllChannels]: output_wcs_target ou output_shape_target_hw est None."
            )
            return None, []
        if not isinstance(output_wcs_target, WCS) or not output_wcs_target.is_celestial:
            self.update_progress(
                f"   - ERREUR: output_wcs_target invalide pour lot Drizzle #{batch_num}.",
                "ERROR",
            )
            return None, []
        if (
            not isinstance(output_shape_target_hw, tuple)
            or len(output_shape_target_hw) != 2
            or not all(
                isinstance(dim, int) and dim > 0 for dim in output_shape_target_hw
            )
        ):
            self.update_progress(
                f"   - ERREUR: output_shape_target_hw invalide pour lot Drizzle #{batch_num}.",
                "ERROR",
            )
            return None, []

        num_output_channels = 3
        channel_names = ["R", "G", "B"]
        drizzlers_batch = []
        output_images_batch = []
        output_weights_batch = []
        try:
            logger.debug(
                f"DEBUG QM [_process_and_save_drizzle_batch V_ProcessAndSaveDrizzleBatch_DrizzleInputFix_5_ForceADUAllChannels]: Initialisation Drizzle pour lot #{batch_num}. Shape Sortie CIBLE: {output_shape_target_hw}."
            )
            for _ in range(num_output_channels):
                output_images_batch.append(
                    np.zeros(output_shape_target_hw, dtype=np.float32)
                )
                output_weights_batch.append(
                    np.zeros(output_shape_target_hw, dtype=np.float32)
                )
            for i in range(num_output_channels):
                driz_ch = Drizzle(
                    out_img=output_images_batch[i],
                    out_wht=output_weights_batch[i],
                    out_shape=output_shape_target_hw,
                    kernel=self.drizzle_kernel,
                    fillval="0.0",
                )
                drizzlers_batch.append(driz_ch)
            self.update_progress(
                f"   - Objets Drizzle initialis√©s pour lot #{batch_num}."
            )
        except Exception as init_err:
            self.update_progress(
                f"   - ERREUR: √âchec init Drizzle pour lot #{batch_num}: {init_err}",
                "ERROR",
            )
            logger.debug(
                f"ERREUR QM [_process_and_save_drizzle_batch V_ProcessAndSaveDrizzleBatch_DrizzleInputFix_5_ForceADUAllChannels]: √âchec init Drizzle: {init_err}"
            )
            traceback.print_exc(limit=1)
            return None, []

        processed_in_batch_count = 0
        for i_file, temp_fits_filepath_item in enumerate(batch_temp_filepaths_list):
            if self.stop_processing:
                break
            current_filename_for_log = os.path.basename(temp_fits_filepath_item)
            logger.debug(
                f"DEBUG QM [P&SDB_Loop]: Lot #{batch_num}, Fichier {i_file+1}/{num_files_in_batch}: '{current_filename_for_log}'"
            )

            input_data_HxWxC_orig = None
            wcs_input_from_file_header = None
            input_file_header_content = None
            pixmap_for_this_file = None
            file_successfully_added_to_drizzle = False
            try:
                with fits.open(temp_fits_filepath_item, memmap=False) as hdul:
                    if not hdul or len(hdul) == 0 or hdul[0].data is None:
                        raise IOError(
                            f"FITS temp invalide/vide: {temp_fits_filepath_item}"
                        )
                    data_cxhxw = hdul[0].data.astype(np.float32)
                    if (
                        data_cxhxw.ndim != 3
                        or data_cxhxw.shape[0] != num_output_channels
                    ):
                        raise ValueError(f"Shape FITS temp {data_cxhxw.shape} != CxHxW")
                    input_data_HxWxC_orig = np.moveaxis(data_cxhxw, 0, -1)
                    input_file_header_content = hdul[0].header
                    with warnings.catch_warnings():
                        warnings.simplefilter("ignore")
                        wcs_input_from_file_header = WCS(
                            input_file_header_content, naxis=2
                        )
                    if not wcs_input_from_file_header.is_celestial:
                        raise ValueError(f"WCS non c√©leste dans FITS temp")

                current_input_shape_hw = input_data_HxWxC_orig.shape[:2]
                y_in_coords, x_in_coords = np.indices(current_input_shape_hw)
                sky_coords_ra_deg, sky_coords_dec_deg = (
                    wcs_input_from_file_header.all_pix2world(
                        x_in_coords.ravel(), y_in_coords.ravel(), 0
                    )
                )
                x_output_pixels_flat, y_output_pixels_flat = (
                    output_wcs_target.all_world2pix(
                        sky_coords_ra_deg, sky_coords_dec_deg, 0
                    )
                )
                pixmap_for_this_file = np.dstack(
                    (
                        x_output_pixels_flat.reshape(current_input_shape_hw),
                        y_output_pixels_flat.reshape(current_input_shape_hw),
                    )
                ).astype(np.float32)

                if pixmap_for_this_file is not None:
                    logger.debug(
                        f"      DEBUG PIXMAP (P&SDB) Fichier {i_file+1}: Shape={pixmap_for_this_file.shape}"
                    )
                    if np.isnan(pixmap_for_this_file).any():
                        logger.debug(
                            f"      WARN PIXMAP (P&SDB) Fichier {i_file+1}: CONTIENT DES NaN !"
                        )
                    if np.isinf(pixmap_for_this_file).any():
                        logger.debug(
                            f"      WARN PIXMAP (P&SDB) Fichier {i_file+1}: CONTIENT DES INF !"
                        )
            except Exception as load_map_err:
                self.update_progress(
                    f"      -> ERREUR P&SDB chargement/pixmap '{current_filename_for_log}': {load_map_err}",
                    "WARN",
                )
                logger.debug(
                    f"ERREUR QM [P&SDB_Loop]: √âchec chargement/pixmap '{current_filename_for_log}': {load_map_err}"
                )
                traceback.print_exc(limit=1)
                continue

            if pixmap_for_this_file is not None:
                try:
                    base_exptime = 1.0
                    if (
                        input_file_header_content
                        and "EXPTIME" in input_file_header_content
                    ):
                        try:
                            base_exptime = max(
                                1e-6, float(input_file_header_content["EXPTIME"])
                            )
                        except (ValueError, TypeError):
                            pass

                    # --- CRITICAL FIX 1: Force ALL input data to [0, 65535] ADU range BEFORE Drizzle.add_image ---
                    input_data_HxWxC_adu_scaled = input_data_HxWxC_orig.copy()

                    current_max_for_batch_adu = np.nanmax(input_data_HxWxC_adu_scaled)
                    if (
                        current_max_for_batch_adu <= 1.0 + 1e-5
                        and current_max_for_batch_adu > 0
                    ):
                        input_data_HxWxC_adu_scaled = (
                            input_data_HxWxC_adu_scaled * 65535.0
                        )
                        logger.debug(
                            f"      DEBUG: File {i_file+1} FORCED rescaled from [0,1] to [0,65535] for Drizzle input. Range: [{np.min(input_data_HxWxC_adu_scaled):.4g}, {np.max(input_data_HxWxC_adu_scaled):.4g}]"
                        )
                    else:
                        logger.debug(
                            f"      DEBUG: File {i_file+1} kept original range for Drizzle input: [{np.min(input_data_HxWxC_adu_scaled):.4g}, {np.max(input_data_HxWxC_adu_scaled):.4g}]"
                        )

                    # Clip negative values and handle NaNs/Infs
                    input_data_HxWxC_cleaned = np.nan_to_num(
                        np.clip(input_data_HxWxC_adu_scaled, 0.0, None),
                        nan=0.0,
                        posinf=0.0,
                        neginf=0.0,
                    )
                    # --- END CRITICAL FIX 1 ---

                    # --- CRITICAL FIX 2: Robustify weight_map ---
                    # For _process_and_save_drizzle_batch, the original pixel mask is not readily available from temp file.
                    # So we use a uniform weight map here. This should be improved if possible by saving/loading the mask.
                    effective_weight_map = np.ones(
                        current_input_shape_hw, dtype=np.float32
                    )
                    logger.debug(
                        f"      DEBUG: File {i_file+1}, uniform weight_map used for Drizzle.add_image. Range: [{np.min(effective_weight_map):.3f}, {np.max(effective_weight_map):.3f}]"
                    )
                    # --- END CRITICAL FIX 2 ---

                    for ch_index in range(num_output_channels):
                        channel_data_2d_clean = input_data_HxWxC_cleaned[..., ch_index]

                        drizzlers_batch[ch_index].add_image(
                            data=channel_data_2d_clean,
                            pixmap=pixmap_for_this_file,
                            exptime=base_exptime,
                            pixfrac=self.drizzle_pixfrac,
                            in_units="counts",
                            weight_map=effective_weight_map,
                        )
                    file_successfully_added_to_drizzle = True
                except Exception as drizzle_add_err:
                    self.update_progress(
                        f"      -> ERREUR P&SDB add_image pour '{current_filename_for_log}': {drizzle_add_err}",
                        "WARN",
                    )
                    logger.debug(
                        f"ERREUR QM [P&SDB_Loop]: √âchec add_image '{current_filename_for_log}': {drizzle_add_err}"
                    )
                    traceback.print_exc(limit=1)

            if file_successfully_added_to_drizzle:
                processed_in_batch_count += 1
                logger.debug(
                    f"  [P&SDB_Loop]: Fichier '{current_filename_for_log}' AJOUT√â. processed_in_batch_count = {processed_in_batch_count}"
                )
            else:
                logger.debug(
                    f"  [P&SDB_Loop]: Fichier '{current_filename_for_log}' NON ajout√© (erreur pixmap ou add_image)."
                )

            del (
                input_data_HxWxC_orig,
                input_data_HxWxC_adu_scaled,
                input_data_HxWxC_cleaned,
                wcs_input_from_file_header,
                input_file_header_content,
                pixmap_for_this_file,
            )
            gc.collect()
        logger.debug(
            f"DEBUG QM [P&SDB_Loop]: Fin boucle pour lot #{batch_num}. Total processed_in_batch_count = {processed_in_batch_count}"
        )

        if processed_in_batch_count == 0:
            self.update_progress(
                f"   - Erreur: Aucun fichier du lot Drizzle #{batch_num} n'a pu √™tre trait√© (processed_in_batch_count est 0).",
                "ERROR",
            )
            del drizzlers_batch, output_images_batch, output_weights_batch
            gc.collect()
            return None, []

        batch_output_dir = self.drizzle_batch_output_dir
        os.makedirs(batch_output_dir, exist_ok=True)
        base_out_filename = f"batch_{batch_num:04d}_s{self.drizzle_scale:.1f}p{self.drizzle_pixfrac:.1f}{self.drizzle_kernel}"
        out_filepath_sci = os.path.join(
            batch_output_dir, f"{base_out_filename}_sci.fits"
        )
        out_filepaths_wht = []

        logger.debug(
            f"DEBUG QM [P&SDB_Save]: D√©but sauvegarde pour lot #{batch_num}. SCI path: {out_filepath_sci}"
        )
        try:
            final_sci_data_batch_hwc = np.stack(output_images_batch, axis=-1).astype(
                np.float32
            )
            final_sci_data_to_save = np.moveaxis(
                final_sci_data_batch_hwc, -1, 0
            ).astype(np.float32)
            logger.debug(
                f"  [P&SDB_Save]: Donn√©es SCI pr√™tes pour √©criture. Shape CxHxW: {final_sci_data_to_save.shape}"
            )
            final_header_sci = output_wcs_target.to_header(relax=True)
            final_header_sci["NINPUTS"] = (
                processed_in_batch_count,
                f"Valid input images for Drizzle batch {batch_num}",
            )
            final_header_sci["ISCALE"] = (self.drizzle_scale, "Drizzle scale factor")
            final_header_sci["PIXFRAC"] = (self.drizzle_pixfrac, "Drizzle pixfrac")
            final_header_sci["KERNEL"] = (self.drizzle_kernel, "Drizzle kernel")
            final_header_sci["HISTORY"] = f"Drizzle Batch {batch_num}"
            final_header_sci["BUNIT"] = "Counts/s"
            final_header_sci["NAXIS"] = 3
            final_header_sci["NAXIS1"] = final_sci_data_to_save.shape[2]
            final_header_sci["NAXIS2"] = final_sci_data_to_save.shape[1]
            final_header_sci["NAXIS3"] = final_sci_data_to_save.shape[0]
            final_header_sci["CTYPE3"] = "CHANNEL"
            try:
                final_header_sci["CHNAME1"] = "R"
                final_header_sci["CHNAME2"] = "G"
                final_header_sci["CHNAME3"] = "B"
            except Exception:
                pass
            logger.debug(f"  [P&SDB_Save]: Header SCI pr√™t. Tentative d'√©criture...")
            fits.writeto(
                out_filepath_sci,
                final_sci_data_to_save,
                final_header_sci,
                overwrite=True,
                checksum=False,
                output_verify="ignore",
            )
            self.update_progress(
                f"      -> Science lot #{batch_num} sauvegard√©: {os.path.basename(out_filepath_sci)}"
            )
            logger.debug(
                f"DEBUG QM [P&SDB_Save]: Fichier SCI lot #{batch_num} sauvegard√©: {out_filepath_sci}"
            )
            del final_sci_data_batch_hwc, final_sci_data_to_save
            gc.collect()
        except Exception as e_save_sci:
            self.update_progress(
                f"   - ERREUR sauvegarde science lot #{batch_num}: {e_save_sci}",
                "ERROR",
            )
            logger.debug(f"ERREUR QM [P&SDB_Save]: √âchec sauvegarde SCI: {e_save_sci}")
            traceback.print_exc(limit=1)
            del drizzlers_batch, output_images_batch, output_weights_batch
            gc.collect()
            return None, []

        for i_ch_save in range(num_output_channels):
            ch_name = channel_names[i_ch_save]
            out_filepath_wht_ch = os.path.join(
                batch_output_dir, f"{base_out_filename}_wht_{ch_name}.fits"
            )
            out_filepaths_wht.append(out_filepath_wht_ch)
            try:
                logger.debug(
                    f"  [P&SDB_Save]: Pr√©paration WHT pour canal {ch_name} lot #{batch_num}. Path: {out_filepath_wht_ch}"
                )
                wht_data_to_save_ch = output_weights_batch[i_ch_save].astype(np.float32)
                wht_header_ch = output_wcs_target.to_header(relax=True)
                for key_clean in [
                    "NAXIS3",
                    "CTYPE3",
                    "CRPIX3",
                    "CRVAL3",
                    "CDELT3",
                    "CUNIT3",
                    "PC3_1",
                    "PC3_2",
                    "PC3_3",
                    "PC1_3",
                    "PC2_3",
                    "CHNAME1",
                    "CHNAME2",
                    "CHNAME3",
                ]:
                    if key_clean in wht_header_ch:
                        del wht_header_ch[key_clean]
                wht_header_ch["NAXIS"] = 2
                wht_header_ch["NAXIS1"] = wht_data_to_save_ch.shape[1]
                wht_header_ch["NAXIS2"] = wht_data_to_save_ch.shape[0]
                wht_header_ch["HISTORY"] = (
                    f"Drizzle Weights ({ch_name}) Batch {batch_num}"
                )
                wht_header_ch["NINPUTS"] = processed_in_batch_count
                wht_header_ch["BUNIT"] = "Weight"
                logger.debug(
                    f"    [P&SDB_Save]: Header WHT {ch_name} pr√™t. Tentative d'√©criture..."
                )
                fits.writeto(
                    out_filepath_wht_ch,
                    wht_data_to_save_ch,
                    wht_header_ch,
                    overwrite=True,
                    checksum=False,
                    output_verify="ignore",
                )
                logger.debug(
                    f"  [P&SDB_Save]: Fichier WHT lot ({ch_name}) #{batch_num} sauvegard√©."
                )
            except Exception as e_save_wht:
                self.update_progress(
                    f"   - ERREUR sauvegarde poids {ch_name} lot #{batch_num}: {e_save_wht}",
                    "ERROR",
                )
                logger.debug(
                    f"ERREUR QM [P&SDB_Save]: √âchec sauvegarde WHT {ch_name}: {e_save_wht}"
                )
                traceback.print_exc(limit=1)
                if os.path.exists(out_filepath_sci):
                    try:
                        os.remove(out_filepath_sci)
                    except Exception:
                        pass
                for wht_f_clean in out_filepaths_wht:
                    if os.path.exists(wht_f_clean):
                        try:
                            os.remove(wht_f_clean)
                        except Exception:
                            pass
                del drizzlers_batch, output_images_batch, output_weights_batch
                gc.collect()
                return None, []

        self.update_progress(
            f"   -> Sauvegarde lot Drizzle #{batch_num} termin√©e ({time.time() - batch_start_time:.2f}s)."
        )
        del drizzlers_batch, output_images_batch, output_weights_batch
        gc.collect()
        return out_filepath_sci, out_filepaths_wht

    def finish(self):
        """Export the cumulative weight map to a FITS file."""
        from astropy.io import fits

        if self.cumulative_wht_memmap is not None:
            if hasattr(self.cumulative_wht_memmap, "flush"):
                self.cumulative_wht_memmap.flush()
            fits.writeto(
                "cumulative_weights.fits",
                self.cumulative_wht_memmap,
                overwrite=True,
            )


######################################################################################################################################################
